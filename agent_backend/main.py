from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Response
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import uuid, tempfile, subprocess, os, json, time, base64
import random
import logging
import httpx
import asyncio

try:
    os.environ['DASHSCOPE_VL_MODEL'] = 'qwen-vl-max'
    print("ğŸ”§ å·²å¼ºåˆ¶è®¾ç½®è§†è§‰æ¨¡å‹: qwen-vl-max")
    from dashscope_client import DSClient, VisionDSClient
    from vision_api_coordinator import get_vision_coordinator
    test_ds = DSClient()
    vision_ds = VisionDSClient()
    print(f"âœ… DSClient initialized successfully at startup")
    print(f"âœ… VisionDSClient initialized successfully")
except Exception as e:
    print(f"âŒ DSClient initialization failed: {e}")
    DSClient = None
    VisionDSClient = None

app = FastAPI(title="MChecker Agent Backend")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')
logger = logging.getLogger("agent")

STATIC_ROOT = os.path.abspath(os.getenv("AGENT_STATIC_ROOT", os.path.join("agent_backend", "static")))
os.makedirs(STATIC_ROOT, exist_ok=True)
app.mount("/static", StaticFiles(directory=STATIC_ROOT), name="static")

PUBLIC_BASE_URL = (os.getenv("PUBLIC_BASE_URL", "").strip().rstrip('/'))

class AuditRequest(BaseModel):
    aweme_id: Optional[str] = None
    video_url: Optional[str] = None
    audio_url: Optional[str] = None
    title: Optional[str] = None
    desc: Optional[str] = None

class CommentAnalysisRequest(BaseModel):
    aweme_id: Optional[str] = None
    comments: List[Dict[str, Any]] = []

@app.get("/health")
async def health():
    return {"ok": True}

class ReasoningConfig(BaseModel):
    step_limit: int = 15  # å¢åŠ æ­¥éª¤æ•°ä»¥æ”¯æŒæ›´å…¨é¢çš„è§†é¢‘åˆ†æ
    tick_seconds: float = 2.0
    use_asr: bool = True
    temperature: Optional[float] = None
    top_p: Optional[float] = None

_REASONING_CFG = ReasoningConfig(step_limit=15, tick_seconds=2.0, use_asr=True, temperature=0.3, top_p=0.9)

@app.post("/agent/config/reasoning")
async def set_reasoning_config(cfg: ReasoningConfig):
    global _REASONING_CFG
    _REASONING_CFG = cfg
    if cfg.temperature is not None:
        os.environ['DASHSCOPE_TEMPERATURE'] = str(cfg.temperature)
    if cfg.top_p is not None:
        os.environ['DASHSCOPE_TOP_P'] = str(cfg.top_p)
    return {"ok": True, "config": _REASONING_CFG.dict()}

@app.get("/agent/config/reasoning")
async def get_reasoning_config():
    return _REASONING_CFG.dict()

@app.get("/agent/api/status")
async def get_api_status():
    """è·å–APIåè°ƒå™¨çŠ¶æ€"""
    coordinator = get_vision_coordinator()
    if coordinator:
        status = coordinator.get_status()
        status['coordinator_enabled'] = True
    else:
        status = {
            'coordinator_enabled': False,
            'message': 'æœªé…ç½®è§†è§‰APIåè°ƒå™¨ï¼Œä½¿ç”¨é»˜è®¤è½®æ¢æœºåˆ¶',
            'total_keys': 1,
            'total_concurrent_requests': 0,
            'total_available_slots': 'unlimited'
        }
    
    return status

@app.get("/api/frames/info")
async def get_frames_info():
    """è·å–å½“å‰æå–çš„å¸§ä¿¡æ¯"""
    import os
    import glob
    import re
    
    frames_dir = "agent_backend/static/extracted_frames"
    if not os.path.exists(frames_dir):
        return {"frame_count": 0, "max_frame_number": 0, "frames": []}
    
    frame_files = glob.glob(os.path.join(frames_dir, "frame_*.jpg"))
    frame_files.sort()
    
    frames = []
    max_frame_number = 0
    for frame_file in frame_files:
        filename = os.path.basename(frame_file)
        match = re.match(r'frame_(\d+)\.jpg', filename)
        if match:
            frame_number = int(match.group(1))
            max_frame_number = max(max_frame_number, frame_number)
            frames.append({
                "number": frame_number,
                "filename": filename,
                "url": f"http://127.0.0.1:8799/static/extracted_frames/{filename}"
            })
    
    return {
        "frame_count": len(frames),
        "max_frame_number": max_frame_number,
        "frames": frames
    }

@app.options("/proxy/video")
async def proxy_video_options():
    return Response(status_code=204, headers={
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "*",
        "Content-Length": "0",
    })

@app.get("/proxy/video")
async def proxy_video(url: str):
    """ä»£ç†è§†é¢‘è¯·æ±‚ï¼Œè§£å†³è·¨åŸŸé—®é¢˜"""
    if not url:
        raise HTTPException(status_code=400, detail="Missing URL parameter")
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            async with client.stream("GET", url) as response:
                if response.status_code != 200:
                    raise HTTPException(status_code=response.status_code, detail="Failed to fetch video")
                
                content_type = response.headers.get("content-type", "video/mp4")
                content_length = response.headers.get("content-length")
                
                headers = {
                    "Content-Type": content_type,
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
                    "Access-Control-Allow-Headers": "*",
                }
                if content_length:
                    headers["Content-Length"] = content_length
                
                async def generate():
                    async for chunk in response.aiter_bytes(chunk_size=8192):
                        yield chunk
                
                return StreamingResponse(generate(), headers=headers)
    except httpx.TimeoutException:
        raise HTTPException(status_code=408, detail="Request timeout")
    except Exception as e:
        logger.error(f"Video proxy error: {e}")
        raise HTTPException(status_code=500, detail=f"Proxy error: {str(e)}")

@app.post("/fix/frames")
async def fix_frame_extraction(request: dict):
    """å½»åº•ä¿®å¤å¸§æå– - ç»•è¿‡æ‰€æœ‰ç¼“å­˜"""
    video_url = request.get("video_url", "https://www.douyin.com/aweme/v1/play/?video_id=v0200fa50000bqv2ovedm15352jvv5vg&line=0&file_id=efac24de9d2548228975fc8429e5bdcb&sign=3b7c4acc3b831e92448d6909510074c0&is_play_url=1&source=PackSourceEnum_PUBLISH")
    count = request.get("count", 30)
    
    import tempfile
    import subprocess
    import os
    
    tmpdir = tempfile.mkdtemp(prefix="fix_frames_")
    outpat = os.path.join(tmpdir, "frame_%02d.jpg")
    
    cmd = ["ffmpeg", "-y", "-i", video_url, "-vf", "fps=1", "-vframes", str(count), outpat]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        frame_files = []
        for i in range(1, count + 1):
            frame_path = outpat.replace("%02d", f"{i:02d}")
            if os.path.exists(frame_path):
                frame_files.append(frame_path)
        
        frame_urls = []
        for path in frame_files:
            filename = os.path.basename(path)
            static_path = os.path.join(STATIC_ROOT, "extracted_frames", filename)
            os.makedirs(os.path.dirname(static_path), exist_ok=True)
            
            if os.path.exists(path):
                import shutil
                shutil.move(path, static_path)
                rel_url = f"/static/extracted_frames/{filename}"
                public_url = f"http://127.0.0.1:8799{rel_url}"
                frame_urls.append(public_url)
        
        return {
            "success": True,
            "frame_urls": frame_urls,
            "count": len(frame_urls),
            "debug": f"Generated {len(frame_files)} frames, moved {len(frame_urls)} to static"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "debug": f"Command failed: {' '.join(cmd)}"
        }

@app.post("/extract/frames")
async def extract_frames_from_url(request: dict):
    """ä»è§†é¢‘URLç›´æ¥æå–å¸§ï¼Œç»•è¿‡å‰ç«¯è·¨åŸŸé™åˆ¶"""
    video_url = request.get("video_url")
    if not video_url:
        raise HTTPException(status_code=400, detail="Missing video_url")
    
    try:
        logger.info(f"å¼€å§‹æå–30å¸§: {video_url}")
        frame_paths = _extract_frames(video_url, fps=0, count=30)
        logger.info(f"å®é™…æå–å¸§æ•°: {len(frame_paths)}")
        if not frame_paths:
            return {"success": False, "error": "No frames extracted"}
        
        frame_urls = []
        for path in frame_paths:
            filename = os.path.basename(path)
            static_path = os.path.join(STATIC_ROOT, "extracted_frames", filename)
            os.makedirs(os.path.dirname(static_path), exist_ok=True)
            
            if os.path.exists(path):
                import shutil
                shutil.move(path, static_path)
                
                rel_url = f"/static/extracted_frames/{filename}"
                if PUBLIC_BASE_URL:
                    public_url = f"{PUBLIC_BASE_URL}{rel_url}"
                else:
                    public_url = f"http://127.0.0.1:8799{rel_url}"
                frame_urls.append(public_url)
        
        return {
            "success": True,
            "frame_urls": frame_urls,
            "count": len(frame_urls)
        }
    except Exception as e:
        logger.error(f"Frame extraction error: {e}")
        return {"success": False, "error": str(e)}


def _extract_frames(video_url: str, fps: int = 0, count: int = 30) -> List[str]:
    """æå–è§†é¢‘å¸§ï¼Œå¼ºåˆ¶ç¡®ä¿è¿”å›æŒ‡å®šæ•°é‡çš„å¸§"""
    paths: List[str] = []
    if not video_url:
        return paths
    
    tmpdir = tempfile.mkdtemp(prefix="mchecker_frames_")
    outpat = os.path.join(tmpdir, "frame_%02d.jpg")
    
    try:
        if fps == 0:
            try:
                probe_cmd = ["ffprobe", "-v", "quiet", 
                            "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                            "-headers", "Referer: https://www.douyin.com/",
                            "-show_entries", "format=duration", "-of", "csv=p=0", video_url]
                probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
                video_duration = float(probe_result.stdout.strip()) if probe_result.returncode == 0 else 30.0
                
                interval = max(1.0, video_duration / count)
                target_fps = 1.0 / interval
                
                cmd = ["ffmpeg", "-y", 
                       "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                       "-headers", "Referer: https://www.douyin.com/",
                       "-reconnect", "1", "-reconnect_streamed", "1", "-reconnect_delay_max", "5",
                       "-timeout", "30000000",
                       "-i", video_url, "-vf", f"fps={target_fps}", "-vframes", str(count), outpat]
                print(f"ğŸ¬ è§†é¢‘æ—¶é•¿{video_duration:.1f}sï¼Œä½¿ç”¨fps={target_fps:.3f}ç­–ç•¥æå–{count}å¸§")
            except:
                cmd = ["ffmpeg", "-y", 
                       "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                       "-headers", "Referer: https://www.douyin.com/",
                       "-reconnect", "1", "-reconnect_streamed", "1", "-reconnect_delay_max", "5",
                       "-timeout", "30000000",
                       "-i", video_url, "-vf", "fps=0.2", "-vframes", str(count), outpat]
                print(f"ğŸ¬ ä½¿ç”¨å›é€€ç­–ç•¥fps=0.2æå–{count}å¸§")
        else:
            cmd = ["ffmpeg", "-y", 
                   "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                   "-headers", "Referer: https://www.douyin.com/",
                   "-reconnect", "1", "-reconnect_streamed", "1", "-reconnect_delay_max", "5",
                   "-timeout", "30000000",
                   "-i", video_url, "-vf", f"fps={fps}", "-vframes", str(count), outpat]
        
        print(f"DEBUG: Executing command for {count} frames: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"ERROR: ffmpeg failed with code {result.returncode}")
            print(f"STDERR: {result.stderr}")
            return paths
        
        for i in range(1, count + 1):
            frame_path = outpat.replace("%02d", f"{i:02d}")
            if os.path.exists(frame_path):
                paths.append(frame_path)
        
        print(f"DEBUG: Successfully extracted {len(paths)} frames out of {count} requested")
        return paths
        
    except Exception as e:
        print(f"EXCEPTION in _extract_frames: {e}")
        import traceback
        traceback.print_exc()
        return []

async def _asr(ds: DSClient, audio_url: Optional[str]) -> str:
    if not audio_url:
        return ""
    try:
        r = await ds.asr_paraformer(audio_url)
        text = r.get("output",{}).get("text") or r.get("result",{}).get("text") or ""
        return text
    except Exception:
        return ""

async def _send_trace(ws: WebSocket, role: str, text: str, stage: str, payload: Optional[Dict[str, Any]] = None, kind: Optional[str] = None):
    try:
        if hasattr(ws, 'client_state') and ws.client_state.value != 1:  # WebSocketState.CONNECTED = 1
            print(f"âš ï¸ WebSocketè¿æ¥å·²æ–­å¼€ï¼Œè·³è¿‡å‘é€trace")
            return False
            
        data = {'role': role, 'text': text, 'stage': stage, 'ts': int(time.time() * 1000)}
        if payload is not None:
            data['payload'] = payload
        if kind is not None:
            data['kind'] = kind
        await ws.send_text(json.dumps({'type': 'trace', 'data': data}, ensure_ascii=False))
        return True
    except Exception as e:
        print(f"âš ï¸ WebSocketå‘é€traceå¤±è´¥: {e}")
        return False  # ä¸å†æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ç¨‹åºå´©æºƒ


async def _send_tool(ws: WebSocket, name: str, payload: Optional[Dict[str, Any]] = None):
    try:
        await ws.send_text(json.dumps({'type': 'tool', 'name': name, 'payload': payload or {}, 'ts': int(time.time() * 1000)}, ensure_ascii=False))
    except Exception:
        pass

async def _vision_describe(ds: DSClient, buf: 'SessionBuf') -> Dict[str, Any]:
    """åˆ†æ®µè§†é¢‘åˆ†æï¼šæŒ‰æ—¶é—´çª—å£åˆ†æè§†é¢‘å¸§ï¼Œè¯†åˆ«é«˜é£é™©ç‰‡æ®µ"""
    import base64
    
    total_frames = len(buf.frames)
    if total_frames == 0:
        return {'text': '', 'segments': [], 'risk_segments': []}
    
    current_window_start = max(0, total_frames - 4)
    current_frames = buf.frames[current_window_start:]
    
    img_inputs: List[str] = []
    frame_timestamps = []
    
    for i, frame_path in enumerate(current_frames):
        timestamp = (current_window_start + i) * 0.5
        frame_timestamps.append(timestamp)
        
        if isinstance(frame_path, str) and frame_path.startswith('http://127.0.0.1:8799/static/'):
            local_path = frame_path.replace('http://127.0.0.1:8799/static/', 'agent_backend/static/')
            logger.info(f"ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡: {frame_path} -> {local_path}")
            try:
                if os.path.exists(local_path):
                    with open(local_path, 'rb') as f:
                        img_data = base64.b64encode(f.read()).decode('utf-8')
                        img_inputs.append(f"data:image/jpeg;base64,{img_data}")
                        logger.info(f"âœ… æˆåŠŸç¼–ç å›¾ç‰‡: {local_path} ({len(img_data)} chars)")
                else:
                    logger.error(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
            except Exception as e:
                logger.error(f"âŒ å›¾ç‰‡ç¼–ç å¤±è´¥ {local_path}: {e}")
                continue
        elif isinstance(frame_path, str) and frame_path.startswith(('http://', 'https://')):
            img_inputs.append(frame_path)
        elif isinstance(frame_path, str) and os.path.exists(frame_path):
            try:
                with open(frame_path, 'rb') as f:
                    img_data = base64.b64encode(f.read()).decode('utf-8')
                    img_inputs.append(f"data:image/jpeg;base64,{img_data}")
            except Exception as e:
                logger.error(f"Failed to encode local image {frame_path}: {e}")
                continue
    
    if not img_inputs:
        logger.warning(f"âš ï¸ æ— å¯ç”¨å›¾ç‰‡è¾“å…¥: frames={len(buf.frames)}, current_frames={len(current_frames)}")
        return {'text': '', 'segments': [], 'risk_segments': []}
    
    logger.info(f"ğŸ¯ å‡†å¤‡è°ƒç”¨è§†è§‰æ¨¡å‹: {len(img_inputs)}å¼ å›¾ç‰‡")
    
    enhanced_prompt = f"""
åˆ†æè¿™{len(img_inputs)}å¸§è¿ç»­è§†é¢‘ç”»é¢ï¼ˆæ—¶é—´çª—å£: {frame_timestamps[0]:.1f}s - {frame_timestamps[-1]:.1f}sï¼‰ï¼š

1. **å†…å®¹æè¿°**ï¼šç®€è¦æè¿°äººç‰©ã€åœºæ™¯ã€åŠ¨ä½œã€æ–‡å­—ã€ç‰©å“
2. **é£é™©è¯†åˆ«**ï¼šè¯†åˆ«ä»»ä½•å¯èƒ½çš„è¿è§„å†…å®¹ï¼ˆæš´åŠ›ã€è‰²æƒ…ã€æ”¿æ²»æ•æ„Ÿã€è™šå‡ä¿¡æ¯ã€è¿æ³•ç­‰ï¼‰
3. **é£é™©ç­‰çº§**ï¼šå¦‚å‘ç°é£é™©ï¼Œè¯„ä¼°ç­‰çº§ï¼ˆä½é£é™©/ä¸­é£é™©/é«˜é£é™©/è¿ç¦ï¼‰
4. **å…³é”®æ—¶åˆ»**ï¼šæ ‡æ³¨å…³é”®åŠ¨ä½œæˆ–é£é™©ç‚¹å‡ºç°çš„å…·ä½“æ—¶é—´

æ ¼å¼ï¼š[å†…å®¹æè¿°] | [é£é™©ç­‰çº§ï¼šæ— /ä½/ä¸­/é«˜/ç¦] | [å…³é”®æ—¶åˆ»ï¼šX.Xs]
    """
    
    r_vl = await ds.qwen_vl(img_inputs, prompt=enhanced_prompt)
    logger.info(f"âœ… è§†è§‰æ¨¡å‹è°ƒç”¨å®Œæˆ: æ”¶åˆ°å“åº” {type(r_vl)}")
    
    text = ''
    out = r_vl.get('output') if isinstance(r_vl, dict) else {}
    
    if isinstance(out, dict):
        if 'text' in out:
            text = out.get('text', '')
            logger.info(f"âœ… ä½¿ç”¨ç›´æ¥textç»“æ„æå–: {len(text)}å­—ç¬¦")
        
        elif 'choices' in out:
            choices = out.get('choices', [])
            if choices and isinstance(choices[0], dict):
                msg = choices[0].get('message', {})
                content = msg.get('content', [])
                if content and isinstance(content[0], dict):
                    text = content[0].get('text', '')
                    logger.info(f"âœ… ä½¿ç”¨choicesç»“æ„æå–: {len(text)}å­—ç¬¦")
    
    if not text:
        text = json.dumps(r_vl, ensure_ascii=False)[:500]
        logger.warning(f"âš ï¸ ä½¿ç”¨åŸå§‹å“åº”ä½œä¸ºæ–‡æœ¬: {len(text)}å­—ç¬¦")
    
    risk_segments = []
    segments_info = []
    
    if text and '|' in text:
        parts = text.split('|')
        if len(parts) >= 3:
            content_desc = parts[0].strip()
            risk_part = parts[1].strip()
            time_part = parts[2].strip()
            
            risk_level = 'low'
            if 'é«˜é£é™©' in risk_part or 'é«˜' in risk_part:
                risk_level = 'high'
            elif 'ä¸­é£é™©' in risk_part or 'ä¸­' in risk_part:
                risk_level = 'medium'  
            elif 'è¿ç¦' in risk_part or 'ç¦' in risk_part:
                risk_level = 'ban'
            elif 'ä½é£é™©' in risk_part or 'ä½' in risk_part:
                risk_level = 'low'
            elif 'æ— ' in risk_part:
                risk_level = 'none'
            
            import re
            time_match = re.search(r'(\d+\.?\d*)s', time_part)
            timestamp = float(time_match.group(1)) if time_match else frame_timestamps[0]
            
            segment = {
                'start_time': frame_timestamps[0],
                'end_time': frame_timestamps[-1],
                'risk_level': risk_level,
                'description': content_desc,
                'key_timestamp': timestamp,
                'frames_analyzed': len(img_inputs)
            }
            
            segments_info.append(segment)
            
            if risk_level in ['high', 'ban']:
                risk_segments.append({
                    'timestamp': timestamp,
                    'duration': frame_timestamps[-1] - frame_timestamps[0],
                    'risk_level': risk_level,
                    'description': content_desc,
                    'frames_count': len(img_inputs)
                })
    
    return {
        'text': text, 
        'segments': segments_info,
        'risk_segments': risk_segments,
        'window_start': frame_timestamps[0] if frame_timestamps else 0,
        'window_end': frame_timestamps[-1] if frame_timestamps else 0,
        'total_frames_analyzed': total_frames
    }

async def _analyze_single_segment(segment: Dict, video_duration: float, buf: 'SessionBuf', segment_index: int) -> Dict:
    """åˆ†æå•ä¸ªç‰‡æ®µ - å¹¶è¡Œè°ƒç”¨çš„ç‹¬ç«‹å‡½æ•°"""
    import time
    try:
        start_time = time.time()
        print(f"ğŸ¬ å¼€å§‹å¹¶è¡Œåˆ†æç‰‡æ®µ{segment_index}: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s (æ—¶åˆ»: {start_time:.3f})")
        segment_summary = await _generate_time_based_segment_summary(
            {}, segment, video_duration, buf
        )
        end_time = time.time()
        print(f"âœ… å¹¶è¡Œå®Œæˆç‰‡æ®µ{segment_index}åˆ†æ: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s (è€—æ—¶: {end_time - start_time:.3f}s)")
        return segment_summary
    except Exception as e:
        print(f"âŒ å¹¶è¡Œåˆ†æç‰‡æ®µ{segment_index}å¤±è´¥: {e}")
        return {
            'segment_index': segment_index,
            'time_range': f'{segment["start_time"]:.2f}s-{segment["end_time"]:.2f}s',
            'duration': f'{segment["duration"]:.2f}ç§’',
            'content': f'ç‰‡æ®µ{segment_index}åˆ†æå¤±è´¥: {str(e)}',
            'risk_level': 'low',
            'key_findings': []
        }

async def _preload_segment_analysis(time_segments: List[Dict], video_duration: float, buf: 'SessionBuf', ws: WebSocket, cache: Dict) -> None:
    """åå°é¢„åŠ è½½æ‰€æœ‰ç‰‡æ®µåˆ†æ - ä½¿ç”¨APIåè°ƒå™¨å®ç°æ™ºèƒ½å¹¶è¡Œ"""
    try:
        coordinator = get_vision_coordinator()
        
        if coordinator:
            print(f"ğŸš€ å¼€å§‹æ™ºèƒ½å¹¶è¡Œé¢„åŠ è½½ç‰‡æ®µåˆ†æ: {len(time_segments)}ä¸ªç‰‡æ®µï¼ˆä½¿ç”¨APIåè°ƒå™¨ï¼‰")
            print(f"ğŸ”§ åè°ƒå™¨çŠ¶æ€: {coordinator.get_status()}")
            
            await _send_trace(ws, 'system', 
                f'ğŸš€ å¯åŠ¨{len(time_segments)}ä¸ªç‰‡æ®µçš„æ™ºèƒ½å¹¶è¡Œåˆ†æï¼ˆæ— é”åè°ƒå™¨ï¼‰...', 
                'smart_parallel_analysis_start', {
                    'total_segments': len(time_segments),
                    'parallel_mode': True,
                    'lockless_coordinator': True,
                    'coordinator_status': coordinator.get_status()
                })
            
            max_concurrency = int(os.getenv('VL_MAX_CONCURRENCY', '6'))
            print(f"ğŸ“¡ æ™ºèƒ½å¹¶è¡Œå‘èµ·åˆ†æï¼ˆé™æµå¹¶å‘={max_concurrency}ï¼‰...")

            semaphore = asyncio.Semaphore(max_concurrency)

            async def run_with_retry(seg, idx):
                backoff = 0.5
                max_backoff = 8.0
                attempts = 0
                while True:
                    attempts += 1
                    async with semaphore:
                        try:
                            return await _analyze_single_segment(seg, video_duration, buf, idx)
                        except Exception as e:
                            msg = str(e)
                            if '429' in msg or 'Too Many Requests' in msg:
                                sleep_s = min(max_backoff, backoff * (2 ** (attempts - 1))) * (1 + 0.2 * random.random())
                                print(f"â³ ç‰‡æ®µ{idx}å‘½ä¸­é™æµ429ï¼Œé€€é¿{sleep_s:.2f}såé‡è¯•(ç¬¬{attempts}æ¬¡)")
                                await asyncio.sleep(sleep_s)
                                continue
                            else:
                                raise

            start_time = time.time()
            segment_results = []
            batch = []
            for i, segment in enumerate(time_segments):
                batch.append(run_with_retry(segment, i + 1))
                if len(batch) >= max_concurrency:
                    segment_results.extend(await asyncio.gather(*batch, return_exceptions=True))
                    batch = []
            if batch:
                segment_results.extend(await asyncio.gather(*batch, return_exceptions=True))
            end_time = time.time()

            print(f"âš¡ æ™ºèƒ½å¹¶è¡Œåˆ†æå®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’ï¼Œå®Œæˆç‰‡æ®µ={len(segment_results)}")
            
        else:
            print(f"âš ï¸ æœªé…ç½®APIåè°ƒå™¨ï¼Œå›é€€åˆ°é¡ºåºå¤„ç†: {len(time_segments)}ä¸ªç‰‡æ®µ")
            
            await _send_trace(ws, 'system', 
                f'âš ï¸ APIåè°ƒå™¨æœªé…ç½®ï¼Œå¯åŠ¨{len(time_segments)}ä¸ªç‰‡æ®µçš„é¡ºåºåˆ†æ...', 
                'fallback_sequential_analysis_start', {
                    'total_segments': len(time_segments),
                    'parallel_mode': False,
                    'reason': 'no_coordinator_configured'
                })
            
            start_time = time.time()
            segment_results = []
            
            for i, segment in enumerate(time_segments):
                try:
                    print(f"ğŸ¬ é¡ºåºåˆ†æç‰‡æ®µ{i+1}/{len(time_segments)}: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s")
                    
                    result = await _analyze_single_segment(segment, video_duration, buf, i + 1)
                    segment_results.append(result)
                    
                    print(f"âœ… ç‰‡æ®µ{i+1}åˆ†æå®Œæˆï¼Œè¿›åº¦: {((i+1)/len(time_segments)*100):.1f}%")
                    
                    try:
                        await _send_trace(ws, 'system', 
                            f'ğŸ“¹ ç‰‡æ®µ{i+1}/{len(time_segments)}åˆ†æå®Œæˆ ({((i+1)/len(time_segments)*100):.1f}%)', 
                            'segment_progress', {
                                'completed': i + 1,
                                'total': len(time_segments),
                                'progress': (i + 1) / len(time_segments) * 100
                            })
                    except:
                        pass
                    
                    if i < len(time_segments) - 1:
                        await asyncio.sleep(0.5)
                        
                except Exception as e:
                    print(f"âŒ ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {e}")
                    fallback_segment = {
                        'segment_index': i + 1,
                        'time_range': f'{segment["start_time"]:.1f}s-{segment["end_time"]:.1f}s',
                        'duration': f'{segment["duration"]:.1f}ç§’',
                        'content': f'ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {str(e)}',
                        'risk_level': 'low',
                        'key_findings': []
                    }
                    segment_results.append(fallback_segment)
            
            end_time = time.time()
            print(f"âš¡ é¡ºåºåˆ†æå®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        successful_segments = []
        failed_count = 0
        
        for i, result in enumerate(segment_results):
            if isinstance(result, Exception):
                print(f"âŒ ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {result}")
                fallback_segment = {
                    'segment_index': i + 1,
                    'time_range': f'{time_segments[i]["start_time"]:.1f}s-{time_segments[i]["end_time"]:.1f}s',
                    'duration': f'{time_segments[i]["duration"]:.1f}ç§’',
                    'content': f'ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {str(result)}',
                    'risk_level': 'low',
                    'key_findings': []
                }
                successful_segments.append(fallback_segment)
                failed_count += 1
            else:
                successful_segments.append(result)
                print(f"âœ… ç‰‡æ®µ{i+1}æ™ºèƒ½å¹¶è¡Œåˆ†ææˆåŠŸ")
                
                try:
                    await _send_trace(ws, 'assistant', 
                        f'ğŸ“¹ å¹¶è¡Œç‰‡æ®µæ€»ç»“ ({result.get("time_range", "æœªçŸ¥")}): {result.get("content", "")[:100]}...', 
                        'segment_summary', result)
                    print(f"âœ… å·²å‘é€ç‰‡æ®µ{i+1}çš„segment_summaryåˆ°å‰ç«¯")
                except Exception as send_e:
                    print(f"âš ï¸ å‘é€ç‰‡æ®µ{i+1}çš„segment_summaryå¤±è´¥: {send_e}")
        
        cache['completed_segments'] = successful_segments
        cache['analysis_complete'] = len([s for s in successful_segments if isinstance(s, dict) and s.get('content')]) > 0
        try:
            buf.segment_analysis_completed = cache['analysis_complete']
        except Exception:
            pass
        cache['analysis_progress'] = 100 if cache['analysis_complete'] else 0
        
        print(f"ğŸ å®¡æ ¸æ•°æ®å·²å…¨éƒ¨åˆ°è¾¾ï¼æˆåŠŸåˆ†æ{len(successful_segments) - failed_count}ä¸ªç‰‡æ®µï¼Œå¤±è´¥{failed_count}ä¸ªç‰‡æ®µ")
        print(f"ğŸ‰ é¡ºåºåˆ†æç»Ÿè®¡: æˆåŠŸ{len(successful_segments) - failed_count}ä¸ª, å¤±è´¥{failed_count}ä¸ª, æ€»è€—æ—¶{end_time - start_time:.2f}ç§’")
        
        if cache['analysis_complete']:
            await _send_trace(ws, 'system', 
                f'âœ… é¡ºåºåˆ†æå®Œæˆ: {len(successful_segments)}ä¸ªç‰‡æ®µ (è€—æ—¶{end_time - start_time:.2f}s)', 
                'sequential_analysis_complete', {
                    'total_segments': len(successful_segments),
                    'successful': len(successful_segments) - failed_count,
                    'failed': failed_count,
                    'duration': end_time - start_time,
                    'analysis_complete': True
                })
        else:
            await _send_trace(ws, 'system', 
                'âš ï¸ è§¦å‘é™æµï¼Œæš‚æœªè·å¾—æœ‰æ•ˆç‰‡æ®µï¼Œæ€»ç»“æœªå®Œæˆï¼›å°†ç»§ç»­é€€é¿é‡è¯•', 
                'sequential_analysis_pending', {
                    'total_segments': len(successful_segments),
                    'successful': len(successful_segments) - failed_count,
                    'failed': failed_count,
                    'analysis_complete': False
                })
            
    except Exception as e:
        print(f"âŒ å¹¶è¡Œé¢„åŠ è½½åˆ†æå¤±è´¥: {e}")
        cache['analysis_complete'] = False
        try:
            buf.segment_analysis_completed = False
        except Exception:
            pass
        completed_segments = cache.get('completed_segments', [])
        print(f"ğŸ å¼‚å¸¸ä¸­æ–­ï¼Œå·²åˆ†æ{len(completed_segments)}ä¸ªç‰‡æ®µï¼›æœªå®Œæˆï¼Œå°†ç­‰å¾…é‡è¯•")

async def _generate_time_based_segment_summary(memory: Dict, segment_info: Dict, video_duration: float, buf: 'SessionBuf' = None) -> Dict[str, Any]:
    """ç”ŸæˆåŸºäºæ—¶é—´çš„è§†é¢‘ç‰‡æ®µæ€»ç»“"""
    try:
        start_time = segment_info['start_time']
        end_time = segment_info['end_time']
        segment_index = segment_info['index']
        
        segment_content = ""
        segment_risk_level = "low"
        
        buf_frames = buf.frames if buf else []
        total_frames = len(buf_frames)
        
        if total_frames > 0 and video_duration > 0:
            start_frame_idx = int((start_time / video_duration) * total_frames)
            end_frame_idx = int((end_time / video_duration) * total_frames)
            
            start_frame_idx = max(0, min(start_frame_idx, total_frames - 1))
            end_frame_idx = max(start_frame_idx, min(end_frame_idx, total_frames - 1))
            
            segment_frames = buf_frames[start_frame_idx:end_frame_idx + 1]
            
            if not segment_frames and total_frames > 0:
                segment_frames = [buf_frames[min(start_frame_idx, total_frames - 1)]]
                
            print(f"ğŸ¬ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: é€‰æ‹©å¸§{start_frame_idx}-{end_frame_idx} (å…±{len(segment_frames)}å¸§)")
            
            if segment_frames and VisionDSClient:
                try:
                    vision_client = VisionDSClient()
                    coordinator = get_vision_coordinator()
                    
                    img_inputs = []
                    for frame_path in segment_frames:
                        if isinstance(frame_path, str) and frame_path.startswith('http://127.0.0.1:8799/static/'):
                            local_path = frame_path.replace('http://127.0.0.1:8799/static/', 'agent_backend/static/')
                            print(f"ğŸ–¼ï¸ å¤„ç†æ—¶é—´æ®µå›¾ç‰‡: {frame_path} -> {local_path}")
                            try:
                                if os.path.exists(local_path):
                                    with open(local_path, 'rb') as f:
                                        img_data = base64.b64encode(f.read()).decode('utf-8')
                                        img_inputs.append(f"data:image/jpeg;base64,{img_data}")
                                        print(f"âœ… æˆåŠŸç¼–ç æ—¶é—´æ®µå›¾ç‰‡: {local_path} ({len(img_data)} chars)")
                                else:
                                    print(f"âŒ æ—¶é—´æ®µå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
                            except Exception as e:
                                print(f"âŒ æ—¶é—´æ®µå›¾ç‰‡ç¼–ç å¤±è´¥ {local_path}: {e}")
                                continue
                        elif isinstance(frame_path, str) and os.path.exists(frame_path):
                            try:
                                with open(frame_path, 'rb') as f:
                                    img_data = base64.b64encode(f.read()).decode('utf-8')
                                    img_inputs.append(f"data:image/jpeg;base64,{img_data}")
                            except Exception as e:
                                print(f"âŒ æ—¶é—´æ®µæœ¬åœ°å›¾ç‰‡ç¼–ç å¤±è´¥ {frame_path}: {e}")
                                continue
                    
                    if not img_inputs:
                        print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: æ— å¯ç”¨å›¾ç‰‡è¾“å…¥")
                        segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šæ— å¯ç”¨å›¾ç‰‡æ•°æ®"
                    else:
                        time_prompt = f"""

- **ä¸»è¦äººç‰©/ç‰©ä½“çš„åŠ¨ä½œå’ŒçŠ¶æ€**ï¼š
- **åœºæ™¯ç¯å¢ƒçš„å˜åŒ–**ï¼š
- **ä»»ä½•å€¼å¾—æ³¨æ„çš„ç»†èŠ‚**ï¼š

è¯·ç”¨ä¸€å¥è‡ªç„¶æµç•…çš„è¯æè¿°è¿™ä¸ªæ—¶é—´æ®µçš„æ ¸å¿ƒå†…å®¹ï¼Œä¾‹å¦‚ï¼š"è§†é¢‘ä¸­å±•ç¤ºäº†ä¸€ä½å¥³æ€§åœ¨å®¤å†…ä»‹ç»äº§å“çš„åœºæ™¯"

- **äººç‰©è¡¨ç°**ï¼š
- **èƒŒæ™¯ç¯å¢ƒ**ï¼š
- **æ–‡å­—ä¿¡æ¯**ï¼š

- **é£é™©ç­‰çº§**ï¼šä½é£é™©
  - ç†ç”±ï¼šç®€è¦è¯´æ˜åˆ¤å®šä¸ºè¯¥ç­‰çº§çš„åŸå› 

å¯é€‰ç­‰çº§è¯´æ˜ï¼š
- ä½é£é™©ï¼šæ­£å¸¸å¥åº·å†…å®¹ï¼Œæ— æ˜æ˜¾è¿è§„ç‚¹
- ä¸­é£é™©ï¼šå­˜åœ¨äº‰è®®ä½†ä¸ä¸¥é‡çš„å†…å®¹
- é«˜é£é™©ï¼šæ˜ç¡®è¿åç¤¾åŒºè§„èŒƒçš„å†…å®¹
- ç¦ï¼šä¸¥é‡è¿æ³•è¿è§„ï¼Œéœ€è¦ç«‹å³å°ç¦

- ç½®ä¿¡åº¦ï¼š0.9

åœ¨è¿™{end_time - start_time:.1f}ç§’é’Ÿçš„è§†é¢‘ç‰‡æ®µä¸­ï¼Œ...
"""
                        
                        print(f"ğŸ¯ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}så‡†å¤‡è°ƒç”¨è§†è§‰æ¨¡å‹: {len(img_inputs)}å¼ å›¾ç‰‡")
                        
                        if coordinator:
                            vl_result = await vision_client.qwen_vl_with_coordinator(
                                img_inputs, time_prompt, coordinator
                            )
                        else:
                            ds = DSClient()
                            vl_result = await ds.qwen_vl(img_inputs, prompt=time_prompt)
                    
                    print(f"ğŸ” æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s DashScopeè¿”å›ç»“æœè°ƒè¯•:")
                    print(f"   vl_resultå­˜åœ¨: {vl_result is not None}")
                    if vl_result:
                        print(f"   vl_resultç±»å‹: {type(vl_result)}")
                        print(f"   vl_resulté”®: {list(vl_result.keys()) if isinstance(vl_result, dict) else 'not dict'}")
                        if 'output' in vl_result:
                            output = vl_result['output']
                            print(f"   outputç±»å‹: {type(output)}")
                            print(f"   outputé”®: {list(output.keys()) if isinstance(output, dict) else 'not dict'}")
                            
                            if isinstance(output, dict):
                                if 'text' in output:
                                    text_content = output.get('text', '')
                                    print(f"   ç›´æ¥texté•¿åº¦: {len(text_content)}")
                                    print(f"   ç›´æ¥textå‰100å­—ç¬¦: {repr(text_content[:100])}")
                                
                                if 'choices' in output:
                                    choices = output.get('choices', [])
                                    print(f"   choicesé•¿åº¦: {len(choices)}")
                                    if choices:
                                        print(f"   choices[0]é”®: {list(choices[0].keys()) if isinstance(choices[0], dict) else 'not dict'}")
                                        if isinstance(choices[0], dict):
                                            message = choices[0].get('message', {})
                                            print(f"   messageé”®: {list(message.keys()) if isinstance(message, dict) else 'not dict'}")
                        
                        print(f"   å®Œæ•´ç»“æœå‰500å­—ç¬¦: {str(vl_result)[:500]}")
                    else:
                        print(f"   vl_resultä¸ºNoneæˆ–False")
                    
                    if vl_result and vl_result.get('output'):
                        try:
                            output = vl_result['output']
                            output_text = ''
                            
                            if isinstance(output, dict) and 'text' in output:
                                output_text = output.get('text', '')
                                print(f"âœ… ä½¿ç”¨ç›´æ¥textç»“æ„è·å–: {len(output_text)}å­—ç¬¦")
                            
                            elif isinstance(output, dict) and 'choices' in output:
                                choices = output.get('choices', [])
                                if choices and len(choices) > 0:
                                    message = choices[0].get('message', {})
                                    content_list = message.get('content', [])
                                    if content_list and len(content_list) > 0:
                                        output_text = content_list[0].get('text', '')
                                        print(f"âœ… ä½¿ç”¨choicesç»“æ„è·å–: {len(output_text)}å­—ç¬¦")
                            
                            elif isinstance(output, str):
                                output_text = output
                                print(f"âœ… ä½¿ç”¨å­—ç¬¦ä¸²ç»“æ„è·å–: {len(output_text)}å­—ç¬¦")
                            
                            if not output_text and isinstance(output, dict):
                                def find_text_in_dict(d, path=""):
                                    if isinstance(d, dict):
                                        for k, v in d.items():
                                            current_path = f"{path}.{k}" if path else k
                                            if k == 'text' and isinstance(v, str) and v.strip():
                                                return v, current_path
                                            elif isinstance(v, (dict, list)):
                                                result = find_text_in_dict(v, current_path)
                                                if result[0]:
                                                    return result
                                    elif isinstance(d, list):
                                        for i, item in enumerate(d):
                                            current_path = f"{path}[{i}]" if path else f"[{i}]"
                                            result = find_text_in_dict(item, current_path)
                                            if result[0]:
                                                return result
                                    return '', ''
                                
                                found_text, found_path = find_text_in_dict(output)
                                if found_text:
                                    output_text = found_text
                                    print(f"âœ… åœ¨è·¯å¾„ {found_path} æ‰¾åˆ°text: {len(output_text)}å­—ç¬¦")
                            
                            if output_text:
                                segment_content = output_text[:800]  # å¢åŠ é•¿åº¦é™åˆ¶
                                
                                segment_risk_level = "low"  # é»˜è®¤ä½é£é™©
                                
                                risk_patterns = [
                                    (['ç¦', 'è¿ç¦', 'ban'], 'ban'),
                                    (['é«˜é£é™©', 'é«˜', 'high', 'ä¸¥é‡', 'è¿è§„'], 'high'),  
                                    (['ä¸­é£é™©', 'ä¸­', 'medium', 'è­¦å‘Š', 'æ³¨æ„'], 'medium'),
                                    (['ä½é£é™©', 'ä½', 'low'], 'low'),
                                    (['æ— é£é™©', 'æ— ', 'none', 'æ­£å¸¸'], 'low')
                                ]
                                
                                risk_section = ""
                                if "é£é™©ç­‰çº§" in output_text:
                                    risk_start = output_text.find("é£é™©ç­‰çº§")
                                    if risk_start != -1:
                                        risk_section = output_text[risk_start:risk_start+50].lower()
                                elif "risk" in output_text.lower():
                                    risk_start = output_text.lower().find("risk")
                                    if risk_start != -1:
                                        risk_section = output_text[risk_start:risk_start+50].lower()
                                
                                if not risk_section:
                                    risk_section = output_text.lower()
                                
                                for keywords, level in risk_patterns:
                                    if any(keyword in risk_section for keyword in keywords):
                                        segment_risk_level = level
                                        break
                                    
                                segment_confidence = None
                                try:
                                    import re
                                    m = re.search(r"ç½®ä¿¡åº¦[ï¼š: ]\s*([0-9]+(?:\.[0-9]+)?)%?", output_text)
                                    if m:
                                        val = float(m.group(1))
                                        segment_confidence = val/100.0 if val > 1 else val
                                except Exception:
                                    segment_confidence = None

                                print(f"âœ… æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}sè§†è§‰åˆ†æå®Œæˆ: {len(segment_content)}å­—ç¬¦ï¼Œconfidence={segment_confidence}")
                                print(f"ğŸ“ åˆ†æå†…å®¹é¢„è§ˆ: {segment_content[:200]}...")
                            else:
                                print(f"âš ï¸ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: æ‰€æœ‰è§£ææ–¹æ³•éƒ½æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹")
                                print(f"   outputç»“æ„: {type(output)}")
                                print(f"   outputå†…å®¹é¢„è§ˆ: {str(output)[:200]}")
                                segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šå“åº”è§£æå¤±è´¥"
                        except Exception as parse_error:
                            print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: å“åº”è§£æé”™è¯¯: {parse_error}")
                            segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šè§£æé”™è¯¯"
                    else:
                        print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: DashScopeè¿”å›ç»“æ„å¼‚å¸¸")
                        segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æå¤±è´¥ï¼šDashScopeè¿”å›å¼‚å¸¸"
                        
                except Exception as e:
                    error_message = str(e) if str(e) else f"{type(e).__name__}: {repr(e)}"
                    print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}sè§†è§‰åˆ†æå¤±è´¥: {error_message}")
                    if '429' in error_message or 'Too Many Requests' in error_message:
                        raise
                    segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æå¤±è´¥: {error_message}"
            else:
                segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šå¸§æ•°æ®ä¸å¯ç”¨"
        else:
            segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šè§†é¢‘æ•°æ®ä¸å¯ç”¨"
        
        time_based_segment = {
            'segment_index': segment_index,
            'time_range': f'{start_time:.2f}s-{end_time:.2f}s',
            'duration': f'{end_time - start_time:.2f}ç§’',
            'progress_range': f'{(start_time/video_duration)*100:.1f}%-{(end_time/video_duration)*100:.1f}%' if video_duration > 0 else f'ç‰‡æ®µ{segment_index}',
            'content': segment_content,
            'risk_level': segment_risk_level,
            'confidence': segment_confidence if 'segment_confidence' in locals() else None,
            'key_findings': [f"æ—¶é—´{start_time:.2f}s-{end_time:.2f}s: åŸºäºå®é™…å¸§å†…å®¹çš„åˆ†æç»“æœ"]
        }
        
        return time_based_segment
        
    except Exception as e:
        print(f"ç”Ÿæˆæ—¶é—´ç‰‡æ®µæ€»ç»“å¤±è´¥: {e}")
        return None

async def _generate_segment_summary(memory: Dict, segment_start: int, segment_end: int, 
                                   progress_start: float, progress_end: float) -> Dict[str, Any]:
    """ç”Ÿæˆè§†é¢‘ç‰‡æ®µæ€»ç»“"""
    try:
        recent_vision = memory.get('vision', '')[-500:] if memory.get('vision') else ''
        recent_annotations = memory.get('stream_annotations', [])[-3:] if memory.get('stream_annotations') else []
        
        segment_info = {
            'time_range': f'{progress_start:.1f}%-{progress_end:.1f}%',
            'frame_range': f'{segment_start}-{segment_end}å¸§',
            'content': recent_vision[:200] if recent_vision else 'æš‚æ— è§†è§‰å†…å®¹',
            'risk_level': 'low',
            'key_findings': []
        }
        
        for ann in recent_annotations:
            if ann.get('content'):
                content = ann.get('content', '')[:100]
                if any(keyword in content.lower() for keyword in ['é£é™©', 'risk', 'è¿è§„', 'å¼‚å¸¸']):
                    segment_info['risk_level'] = 'medium'
                    segment_info['key_findings'].append(content)
        
        if recent_vision:
            if 'é£é™©' in recent_vision or 'è¿è§„' in recent_vision:
                segment_info['risk_level'] = 'high'
            summary = recent_vision.split('ã€‚')[0][:100] + '...' if len(recent_vision) > 100 else recent_vision
            segment_info['content'] = summary
        
        return segment_info
        
    except Exception as e:
        return {
            'time_range': f'{progress_start:.1f}%-{progress_end:.1f}%',
            'frame_range': f'{segment_start}-{segment_end}å¸§',
            'content': f'ç‰‡æ®µåˆ†æå®Œæˆ (å¸§{segment_start}-{segment_end})',
            'risk_level': 'low',
            'key_findings': []
        }

async def _asr_transcribe(ds: DSClient, buf: 'SessionBuf') -> Dict[str, Any]:
    """Transcribe last audio chunk if present; returns {'text': str, 'audio': url_or_path}"""
    if not buf.audios:
        return {'text': '', 'audio': ''}
    last = buf.audios[-1]
    url = last if last.startswith(('http://','https://')) else buf.public_url(last)
    text = await _asr(ds, url)
    return {'text': text, 'audio': url}

async def _assess_accumulated_risk(stream_annotations: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åŸºäºæµå¼æ ‡æ³¨è¯„ä¼°ç´¯ç§¯é£é™©"""
    if not stream_annotations:
        return {'level': 'low', 'score': 0.1, 'reasoning': 'æ— è¶³å¤Ÿæ•°æ®'}
    
    risk_indicators = []
    total_confidence = 0.0
    
    for annotation in stream_annotations:
        content = annotation.get('content', '')
        if annotation.get('type') == 'vision':
            if any(word in content for word in ['è£¸éœ²', 'æš´åŠ›', 'è¡€è…¥', 'æ­¦å™¨']):
                risk_indicators.append(('high', 0.8, 'è§†è§‰è¿è§„å†…å®¹'))
            elif any(word in content for word in ['äº‰è®®', 'æ”¿æ²»', 'æ•æ„Ÿ']):
                risk_indicators.append(('medium', 0.6, 'æ•æ„Ÿè§†è§‰å†…å®¹'))
        elif annotation.get('type') == 'audio':
            if any(word in content for word in ['éª‚äºº', 'è¯ˆéª—', 'èµŒåš', 'å¨èƒ']):
                risk_indicators.append(('high', 0.9, 'éŸ³é¢‘è¿è§„å†…å®¹'))
            elif any(word in content for word in ['å¹¿å‘Š', 'æ¨é”€', 'è”ç³»æ–¹å¼']):
                risk_indicators.append(('medium', 0.5, 'å•†ä¸šå¯¼æµå†…å®¹'))
    
    if not risk_indicators:
        return {'level': 'low', 'score': 0.2, 'reasoning': 'æœªå‘ç°æ˜æ˜¾é£é™©'}
    
    high_count = sum(1 for r in risk_indicators if r[0] == 'high')
    medium_count = sum(1 for r in risk_indicators if r[0] == 'medium')
    
    if high_count > 0:
        level = 'high'
        score = min(0.95, 0.7 + high_count * 0.1)
    elif medium_count >= 2:
        level = 'medium'
        score = min(0.8, 0.4 + medium_count * 0.15)
    else:
        level = 'low'
        score = min(0.6, 0.2 + medium_count * 0.1)
    
    reasoning = f"å‘ç°{len(risk_indicators)}ä¸ªé£é™©æŒ‡æ ‡: " + "; ".join([r[2] for r in risk_indicators[:3]])
    
    return {'level': level, 'score': score, 'reasoning': reasoning}

def _rules_retrieve(vision_text: str, asr_text: str) -> List[Dict[str, Any]]:
    """Heuristic rules retrieval based on keywords; returns list of rules."""
    rules: List[Dict[str, Any]] = []
    def hit(name: str, weight: float):
        rules.append({'name': name, 'weight': weight})
    vt = (vision_text or '').lower()
    at = (asr_text or '').lower()
    if any(k in vt for k in ['è¡€', 'æš´åŠ›', 'æ­¦å™¨', 'knife', 'gun']):
        hit('æš´åŠ›/è¡€è…¥-å›¾åƒ', 0.9)
    if any(k in vt for k in ['è£¸', 'æ•æ„Ÿéƒ¨ä½', 'è‰²æƒ…']):
        hit('ä½ä¿—/æ“¦è¾¹-å›¾åƒ', 0.8)
    if any(k in at for k in ['èµŒ', 'åšå½©', 'ä¸‹æ³¨', 'è¯ˆéª—', 'æ”¶æ¬¾', 'åŠ ç¾¤']):
        hit('èµŒåš/è¯ˆéª—-è¯­éŸ³', 1.0)
    if any(k in at for k in ['è”ç³»æ–¹å¼', 'vx', 'å¨ä¿¡', 'åŠ æˆ‘']):
        hit('å¯¼æµ-è”ç³»æ–¹å¼-è¯­éŸ³', 0.7)
    return rules[:6]

async def run_cot_react(ds: DSClient, buf: 'SessionBuf', ws: WebSocket) -> Dict[str, Any]:
    """Enhanced streaming CoT+ReAct: è¾¹çœ‹è§†é¢‘è¾¹åšæ•°æ®æ ‡æ³¨è¾¹åšäººå·¥å®¡æ‰¹"""
    memory: Dict[str, Any] = {
        'vision': '', 
        'asr': '', 
        'rules': [],
        'stream_annotations': [],  # æµå¼æ ‡æ³¨è®°å½•
        'approval_signals': [],    # å®¡æ‰¹ä¿¡å·ç´¯ç§¯
        'watch_progress': 0        # è§‚çœ‹è¿›åº¦æ¨¡æ‹Ÿ
    }
    step_limit = int(getattr(_REASONING_CFG, 'step_limit', 15) or 15)
    tick_seconds = float(getattr(_REASONING_CFG, 'tick_seconds', 2.0) or 2.0)
    use_asr = bool(getattr(_REASONING_CFG, 'use_asr', False))
    
    await _send_trace(ws, 'assistant', 'å¼€å§‹æµå¼CoT+ReActï¼šè¾¹çœ‹è¾¹æ ‡æ³¨è¾¹å®¡æ‰¹', 'reasoning', {
        'step_limit': step_limit, 
        'streaming_mode': True,
        'tick_seconds': tick_seconds,
        'use_asr': use_asr
    }, 'start')
    
    segment_summaries = []
    
    if not getattr(buf, 'segment_analysis_cache', None):
        buf.segment_analysis_cache = {
            'completed_segments': [],
            'total_segments_expected': 0,
            'analysis_complete': False,
            'analysis_progress': 0,
            'analysis_started': False,
        }
    segment_analysis_cache = buf.segment_analysis_cache
    
    video_duration = float(buf.meta.get('duration', 0))  # è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
    segment_duration = 5.0  # æ¯ä¸ªç‰‡æ®µ5ç§’
    total_segments = max(1, int(video_duration / segment_duration)) if video_duration > 0 else 6
    
    segment_analysis_cache['total_segments_expected'] = total_segments
    
    print(f"ğŸ¬ è§†é¢‘ç‰‡æ®µåˆ†æé…ç½®: æ€»æ—¶é•¿={video_duration:.1f}s, ç‰‡æ®µæ—¶é•¿={segment_duration}s, æ€»ç‰‡æ®µæ•°={total_segments}")
    
    time_segments = []
    for i in range(total_segments):
        start_time = i * segment_duration
        end_time = min((i + 1) * segment_duration, video_duration)
        time_segments.append({
            'index': i + 1,
            'start_time': start_time,
            'end_time': end_time,
            'duration': end_time - start_time
        })
    
    current_segment_index = 0
    
    print(f"ğŸ¬ ç‰‡æ®µåˆ†æç­‰å¾…å¸§æ•°æ®å‡†å¤‡ï¼Œæ€»å…±éœ€è¦åˆ†æ{len(time_segments)}ä¸ªç‰‡æ®µ")
    
    for step in range(1, step_limit+1):
        print(f"ğŸ” Step {step}: buf.frames={len(buf.frames)}, buf.audios={len(buf.audios)}")
        
        try:
            if 'watch_progress' in buf.meta and isinstance(buf.meta.get('watch_progress'), (int, float)):
                memory['watch_progress'] = max(0.0, min(100.0, float(buf.meta.get('watch_progress') or 0.0)))
            else:
                total_frames_expected = 30.0
                frames_analyzed = float(len(buf.frames))
                memory['watch_progress'] = min(100.0, (frames_analyzed / total_frames_expected) * 100.0)
        except Exception:
            memory['watch_progress'] = 0.0
        observations = {
            'frames_cnt': len(buf.frames),
            'audio_cnt': len(buf.audios),
            'have_vision': bool(memory['vision']),
            'have_asr': bool(memory['asr']),
            'rules_cnt': len(memory['rules']),
            'watch_progress': memory['watch_progress'],
            'stream_annotations_cnt': len(memory['stream_annotations']),
            'approval_signals_cnt': len(memory['approval_signals'])
        }
        sys_prompt = (
            f'ä½ æ˜¯æµå¼å®¡æ ¸æ™ºèƒ½ä½“ï¼Œæ­£åœ¨è¾¹çœ‹è§†é¢‘è¾¹æ ‡æ³¨è¾¹å®¡æ‰¹ï¼ˆå½“å‰è§‚çœ‹è¿›åº¦: {memory["watch_progress"]:.0f}%ï¼‰ã€‚\n'
            'é‡‡ç”¨CoT+ReActæµç¨‹ï¼šThought â†’ Action â†’ Observationï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†å¤šä¸ªä»»åŠ¡ã€‚\n'
            'å·¥å…·ï¼ˆå¯å¹¶è¡Œä½¿ç”¨ï¼‰: \n'
            '- vision_describe: åˆ†æå½“å‰å¸§å†…å®¹ï¼ˆå®æ—¶è§†è§‰ç†è§£ï¼‰ï¼Œargs={}\n'
            '- asr_transcribe: è½¬å½•å½“å‰éŸ³é¢‘ç‰‡æ®µï¼ˆå®æ—¶éŸ³é¢‘ç†è§£ï¼‰ï¼Œargs={}\n'
            '- rules_retrieve: æ£€ç´¢ç›¸å…³å®¡æ ¸è§„åˆ™ï¼Œargs={}\n'
            '- annotation.update: å®æ—¶æ›´æ–°æ ‡æ³¨ï¼ˆåŸºäºå½“å‰å‘ç°ï¼‰ï¼Œargs={{"category":"string","severity":"low|medium|high|ban","progress":0-100,"evidence":"string","timestamp":number}}\n'
            '- ui.highlight: é«˜äº®å…³æ³¨åŒºåŸŸï¼Œargs={{"selector":"CSSé€‰æ‹©å™¨","reason":"é«˜äº®åŸå› "}}\n'
            '- approval.suggest: åŸºäºç´¯ç§¯è¯æ®ç»™å‡ºå®¡æ‰¹å»ºè®®ï¼Œargs={{"recommendation":"approve|reject|review","confidence":0-100,"reasoning":"åŸå› "}}\n'
            'æµå¼ç­–ç•¥ï¼š\n'
            '- æ—©æœŸæ­¥éª¤ï¼šä¸“æ³¨vision_describeå’Œasr_transcribeæ”¶é›†ä¿¡æ¯\n'
            '- ä¸­æœŸæ­¥éª¤ï¼šå¼€å§‹annotation.updateå¡«å……æ ‡æ³¨\n'
            '- åæœŸæ­¥éª¤ï¼šapproval.suggestç»™å‡ºå®¡æ‰¹å»ºè®®\n'
            '- å¯ä»¥åœ¨åŒä¸€æ­¥éª¤æ‰§è¡Œå¤šä¸ªç›¸å…³å·¥å…·\n'
            'è¾“å‡ºæ ¼å¼(JSON)ï¼š\n'
            '{{"type":"Thought","text":"åŸºäºå½“å‰åˆ†æé˜¶æ®µï¼Œæˆ‘ç°åœ¨åº”è¯¥..."}} æˆ–\n'
            '{{"type":"Action","tool":"å·¥å…·å","args":{{...}}}} æˆ–\n'
            '{{"type":"Final","result":{{"risk_level":"low|medium|high|ban","counters":{{"low":n,"medium":n,"high":n,"ban":n}},"summary":"åŸºäºæµå¼åˆ†æçš„ç»¼åˆæ€»ç»“"}}}}\n'
            'ä»…è¾“å‡ºä¸€ä¸ªJSONï¼Œæ€è€ƒç®€æ´ã€‚'
        )
        user_ctx = {
            'observations': observations,
            'vision_excerpt': memory['vision'][-200:] if memory['vision'] else '',  # æœ€æ–°è§†è§‰ä¿¡æ¯
            'asr_excerpt': memory['asr'][-200:] if memory['asr'] else '',          # æœ€æ–°éŸ³é¢‘ä¿¡æ¯  
            'rules': memory['rules'][:4],
            'recent_annotations': memory['stream_annotations'][-2:],               # æœ€è¿‘æ ‡æ³¨
            'recent_approvals': memory['approval_signals'][-2:]                   # æœ€è¿‘å®¡æ‰¹ä¿¡å·
        }
        try:
            resp = await ds.qwen_text(sys_prompt + "\nä¸Šä¸‹æ–‡:" + json.dumps(user_ctx, ensure_ascii=False))
            out = resp.get('output') if isinstance(resp, dict) else {}
            action_obj: Dict[str, Any] = {}
            if isinstance(out, dict) and out:
                action_obj = out
            else:
                text = out.get('text') or resp.get('output_text') or json.dumps(out, ensure_ascii=False)
                try:
                    import re
                    m = re.search(r"\{[\s\S]*\}", text)
                    action_obj = json.loads(m.group(0)) if m else {}
                except Exception:
                    action_obj = {}
        except Exception as e:
            print(f"ğŸ” Step {step} è§„åˆ’å¼‚å¸¸: {e}")
            await _send_trace(ws, 'system', f'è§„åˆ’å¤±è´¥: {e}', 'reasoning', None, 'error')
            break

        typ = (action_obj.get('type') or '').lower()
        print(f"ğŸ” Step {step} AIè¿”å›ç±»å‹: {typ}, å†…å®¹: {str(action_obj)[:200]}")
        if typ == 'thought':
            thought_text = action_obj.get('text','')
            await _send_trace(ws, 'assistant', f'ğŸ¤” [{memory["watch_progress"]:.0f}%] {thought_text}', 'reasoning', {
                'step': step, 
                'progress': memory['watch_progress'],
                'streaming_mode': True
            }, 'thought')
            continue
        if typ == 'action':
            tool = (action_obj.get('tool') or '').lower()
            args = action_obj.get('args') or {}
            await _send_trace(ws, 'assistant', f'[{memory["watch_progress"]:.0f}%] æ‰§è¡Œ: {tool}', 'reasoning', {
                'step': step, 
                'tool': tool,
                'args': args,
                'progress': memory['watch_progress']
            }, 'action')
            if tool == 'vision_describe':
                obs = await _vision_describe(ds, buf)
                vision_result = obs.get('text','')
                memory['vision'] = (memory['vision'] + '\n' + vision_result).strip()
                
                risk_segments = obs.get('risk_segments', [])
                segments_info = obs.get('segments', [])
                
                memory['stream_annotations'].append({
                    'type': 'vision',
                    'progress': memory['watch_progress'], 
                    'content': vision_result,
                    'timestamp': step,
                    'segments': segments_info,
                    'risk_segments': risk_segments,
                    'window_analyzed': f"{obs.get('window_start', 0):.1f}s-{obs.get('window_end', 0):.1f}s"
                })
                
                observation_msg = f'è§†è§‰å‘ç°: {vision_result[:200]}'
                if risk_segments:
                    risk_count = len(risk_segments)
                    high_risk = len([r for r in risk_segments if r.get('risk_level') in ['high', 'ban']])
                    observation_msg += f' | å‘ç°{risk_count}ä¸ªé£é™©ç‰‡æ®µ({high_risk}ä¸ªé«˜é£é™©)'
                
                await _send_trace(ws, 'assistant', observation_msg, 'reasoning', {
                    'images': obs.get('images',[]),
                    'progress': memory['watch_progress'],
                    'risk_segments': risk_segments,
                    'total_frames_analyzed': obs.get('total_frames_analyzed', 0)
                }, 'observation')
            elif tool == 'asr_transcribe' and use_asr:
                obs = await _asr_transcribe(ds, buf)
                asr_result = obs.get('text','')
                memory['asr'] = (memory['asr'] + '\n' + asr_result).strip()
                memory['stream_annotations'].append({
                    'type': 'audio',
                    'progress': memory['watch_progress'],
                    'content': asr_result,
                    'timestamp': step
                })
                await _send_trace(ws, 'assistant', f'ğŸµ éŸ³é¢‘å†…å®¹: {asr_result[:200]}', 'reasoning', {
                    'audio': obs.get('audio',''),
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'rules_retrieve':
                rules = _rules_retrieve(memory['vision'], memory['asr'])
                memory['rules'] = rules
                await _send_trace(ws, 'assistant', f"ğŸ“‹ æ£€ç´¢åˆ°{len(rules)}æ¡æ½œåœ¨è§„åˆ™", 'reasoning', {
                    'rules': rules,
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'annotation.update':
                enhanced_args = {
                    **args,
                    'streaming_progress': memory['watch_progress'],
                    'evidence_count': len(memory['stream_annotations']),
                    'timestamp': step
                }
                memory['stream_annotations'].append({
                    'type': 'annotation',
                    'progress': memory['watch_progress'],
                    'data': enhanced_args,
                    'timestamp': step
                })
                await _send_tool(ws, 'annotation.update', enhanced_args)
                await _send_trace(ws, 'assistant', f'æ ‡æ³¨æ›´æ–°: åŸºäº{memory["watch_progress"]:.0f}%è¿›åº¦', 'reasoning', {
                    'fields': list(args.keys()),
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'ui.highlight':
                enhanced_args = {
                    **args,
                    'progress': memory['watch_progress'],
                    'context': f'{memory["watch_progress"]:.0f}%è§‚çœ‹è¿›åº¦'
                }
                await _send_tool(ws, 'ui.highlight', enhanced_args)
                await _send_trace(ws, 'assistant', f'ç•Œé¢é«˜äº®: {args.get("selector","")}', 'reasoning', {
                    'target': args.get('selector',''),
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'approval.suggest':
                enhanced_args = {
                    **args,
                    'evidence_count': len(memory['stream_annotations']),
                    'watch_progress': memory['watch_progress'],
                    'vision_analyzed': bool(memory['vision']),
                    'audio_analyzed': bool(memory['asr']),
                    'rules_checked': len(memory['rules']) > 0
                }
                memory['approval_signals'].append({
                    'progress': memory['watch_progress'],
                    'recommendation': args.get('recommendation',''),
                    'confidence': args.get('confidence', 0),
                    'reasoning': args.get('reasoning',''),
                    'timestamp': step
                })
                await _send_tool(ws, 'approval.suggest', enhanced_args)
                await _send_trace(ws, 'assistant', f'å®¡æ‰¹å»ºè®®: {args.get("recommendation","")} (ç½®ä¿¡åº¦: {args.get("confidence",0)}%)', 'reasoning', {
                    'recommendation': enhanced_args,
                    'progress': memory['watch_progress']
                }, 'observation')
            else:
                await _send_trace(ws, 'assistant', f'æœªçŸ¥å·¥å…·ï¼š{tool}', 'reasoning', {'tool': tool}, 'error')
            
            await asyncio.sleep(tick_seconds)
            continue
        if typ == 'final':
            print(f"ğŸ” Step {step} AIæå‰è¿”å›finalç»“æœ: {action_obj}")
            res = action_obj.get('result') or {}
            if {'risk_level','counters','summary'} <= set(res.keys()):
                print(f"ğŸ” Finalç»“æœå®Œæ•´ï¼Œç›´æ¥è¿”å›")
                return res
            print(f"ğŸ” Finalç»“æœä¸å®Œæ•´ï¼Œfallbackåˆ°é»˜è®¤åˆ¤å®š")
            break
        print(f"ğŸ” Step {step} æ£€æŸ¥å¼ºåˆ¶æ‰§è¡Œ: vision={bool(memory['vision'])}, frames={len(buf.frames)}")
        if not memory['vision'] and len(buf.frames) > 0:
            await _send_trace(ws, 'assistant', f'[æ­¥éª¤{step}] å¼ºåˆ¶æ‰§è¡Œ: vision_describe (LLMæœªä¸»åŠ¨è°ƒç”¨)', 'reasoning', {
                'step': step, 
                'tool': 'vision_describe',
                'args': {},
                'progress': memory['watch_progress']
            }, 'action')
            
            print(f"ğŸ” Step {step} å¼€å§‹å¼ºåˆ¶æ‰§è¡Œvision_describe")
            obs = await _vision_describe(ds, buf)
            vision_result = obs.get('text','')
            memory['vision'] = (memory['vision'] + '\n' + vision_result).strip()
            print(f"ğŸ” Step {step} å¼ºåˆ¶æ‰§è¡Œvision_describeå®Œæˆ: {len(vision_result)}å­—ç¬¦")
            
            risk_segments = obs.get('risk_segments', [])
            segments_info = obs.get('segments', [])
            
            memory['stream_annotations'].append({
                'type': 'vision',
                'progress': memory['watch_progress'], 
                'content': vision_result,
                'timestamp': step,
                'segments': segments_info,
                'risk_segments': risk_segments,
                'window_analyzed': f"{obs.get('window_start', 0):.1f}s-{obs.get('window_end', 0):.1f}s"
            })
            
            observation_msg = f'ğŸ“º è§†è§‰å‘ç°: {vision_result[:200]}'
            if risk_segments:
                risk_count = len(risk_segments)
                high_risk = len([r for r in risk_segments if r.get('risk_level') in ['high', 'ban']])
                observation_msg += f' | âš ï¸ å‘ç°{risk_count}ä¸ªé£é™©ç‰‡æ®µ({high_risk}ä¸ªé«˜é£é™©)'
            
            await _send_trace(ws, 'assistant', observation_msg, 'reasoning', {
                'images': obs.get('images',[]),
                'progress': memory['watch_progress'],
                'risk_segments': risk_segments,
                'total_frames_analyzed': obs.get('total_frames_analyzed', 0)
            }, 'observation')
            
            min_frames_needed = 1
            analysis_started = segment_analysis_cache.get('analysis_started', False)
            frames_count = len(buf.frames)
            
            print(f"ğŸ” é˜ˆå€¼æ£€æŸ¥: frames={frames_count}, é˜ˆå€¼={min_frames_needed}, å·²å¯åŠ¨={analysis_started}, æ€»ç‰‡æ®µ={total_segments}")
            
            if (not getattr(buf, 'segment_analysis_started', False)) and (not analysis_started) and frames_count >= min_frames_needed:
                print(f"ğŸš€ å¸§æ•°æ®å‡†å¤‡å……è¶³({frames_count}å¸§ï¼Œé˜ˆå€¼{min_frames_needed})ï¼Œç°åœ¨å¯åŠ¨æ™ºèƒ½å¹¶è¡Œç‰‡æ®µåˆ†æï¼ˆAPIåè°ƒå™¨ç®¡ç†ï¼‰")
                segment_analysis_cache['analysis_started'] = True
                buf.segment_analysis_started = True
                if not getattr(buf, 'segment_analysis_task', None) or buf.segment_analysis_task.done():
                    buf.segment_analysis_task = asyncio.create_task(
                        _preload_segment_analysis(time_segments, video_duration, buf, ws, segment_analysis_cache)
                    )
            
            if current_segment_index < len(time_segments):
                current_segment = time_segments[current_segment_index]
                segment_progress_threshold = (current_segment['end_time'] / video_duration) * 100 if video_duration > 0 else (current_segment_index + 1) * (100 / total_segments)
                
                if memory['watch_progress'] >= segment_progress_threshold - 5:  # ç•™5%ç¼“å†²
                    completed_segments = len(segment_analysis_cache.get('completed_segments', []))
                    await _send_trace(ws, 'system', 
                        f'ğŸ“Š å½“å‰æ’­æ”¾åˆ°ç‰‡æ®µ{current_segment_index + 1}ï¼Œåå°åˆ†æè¿›åº¦: {completed_segments}/{total_segments}', 
                        'playback_progress', {
                            'current_playback_segment': current_segment_index + 1,
                            'analysis_completed': completed_segments,
                            'total_segments': total_segments
                        })
                    
                    current_segment_index += 1
            
            continue
        if getattr(_REASONING_CFG, 'use_asr', False) and (not memory['asr']) and len(buf.audios) > 0:
            obs = await _asr_transcribe(ds, buf)
            memory['asr'] = obs.get('text','')
            await _send_trace(ws, 'assistant', obs.get('text','')[:300], 'reasoning', {'audio': obs.get('audio','')}, 'observation')
            continue
        
        print(f"ğŸ” å¾ªç¯æ£€æŸ¥: use_asr={getattr(_REASONING_CFG, 'use_asr', False)}, has_asr={bool(memory['asr'])}, audio_count={len(buf.audios)}")
        
        analysis_started = segment_analysis_cache.get('analysis_started', False)
        frames_available = len(buf.frames)
        
        if analysis_started or getattr(buf, 'segment_analysis_started', False):
            print(f"ğŸ” å¹¶è¡Œåˆ†æå·²å¯åŠ¨ï¼Œå¯ä»¥ç»“æŸå¾ªç¯")
            break
        elif step >= 5 and frames_available == 0:
            print(f"ğŸ” ç­‰å¾…5æ­¥ä»æ— å¸§æ•°æ®ï¼Œç»“æŸå¾ªç¯")
            break
        elif step < step_limit:
            print(f"ğŸ” ç»§ç»­ç­‰å¾…å¸§æ•°æ®æˆ–è§¦å‘å¹¶è¡Œåˆ†æ (step {step}/{step_limit})")
            continue
        else:
            print(f"ğŸ” è¾¾åˆ°æ­¥æ•°é™åˆ¶ï¼Œç»“æŸå¾ªç¯")
            break
        
    if not (segment_analysis_cache.get('analysis_started', False) or getattr(buf, 'segment_analysis_started', False)):
        print(f"ğŸ¬ å¹¶è¡Œåˆ†ææœªå¯åŠ¨ï¼Œå›é€€åˆ°é€ä¸ªç‰‡æ®µåˆ†ææ¨¡å¼")
        while current_segment_index < len(time_segments):
            remaining_segment = time_segments[current_segment_index]
            
            segment_summary = await _generate_time_based_segment_summary(
                memory, remaining_segment, video_duration, buf
            )
            
            if segment_summary:
                segment_summaries.append(segment_summary)
                await _send_trace(ws, 'assistant', 
                    f'ğŸ“¹ æœ€ç»ˆç‰‡æ®µæ€»ç»“ ({remaining_segment["start_time"]:.1f}s-{remaining_segment["end_time"]:.1f}s): {segment_summary["content"][:100]}...', 
                    'segment_summary', segment_summary)
            
            current_segment_index += 1
    else:
        print(f"ğŸ¬ å¹¶è¡Œåˆ†æå·²å¯åŠ¨ï¼Œè·³è¿‡é€ä¸ªç‰‡æ®µåˆ†æï¼Œç­‰å¾…å¹¶è¡Œç»“æœ")
    
    print(f"ğŸ¬ å®Œæˆæ‰€æœ‰ç‰‡æ®µåˆ†æï¼Œæ€»å…±ç”Ÿæˆ {len(segment_summaries)} ä¸ªæ—¶é—´æ®µæ€»ç»“")

    risk_assessment = await _assess_accumulated_risk(memory['stream_annotations'])
    
    context = {
        'streaming_analysis': {
            'total_annotations': len(memory['stream_annotations']),
            'approval_signals': len(memory['approval_signals']),
            'risk_assessment': risk_assessment,
            'segment_summaries': segment_summaries  # æ·»åŠ ç‰‡æ®µæ€»ç»“
        },
        'content_analysis': {
            'vision': memory['vision'][-500:] if memory['vision'] else '',  # æœ€æ–°è§†è§‰åˆ†æ
            'transcript': memory['asr'][-500:] if memory['asr'] else '',    # æœ€æ–°éŸ³é¢‘è½¬å½•
            'rules_triggered': memory['rules'][:5]                          # è§¦å‘çš„è§„åˆ™
        },
        'evidence_timeline': [
            {
                'progress': ann.get('progress', 0),
                'type': ann.get('type', ''),
                'content': ann.get('content', '')[:100]  # æˆªå–å…³é”®å†…å®¹
            } for ann in memory['stream_annotations'][-5:]  # æœ€è¿‘5ä¸ªå‘ç°
        ]
    }
    
    judge_prompt = (
        'ä½ æ˜¯æµå¼å†…å®¹å®¡æ ¸æ™ºèƒ½ä½“ï¼ŒåŸºäºè¾¹çœ‹è¾¹æ ‡æ³¨è¾¹å®¡æ‰¹çš„å®Œæ•´åˆ†æè¿‡ç¨‹ï¼Œç»™å‡ºæœ€ç»ˆå®¡æ ¸ç»“è®ºã€‚\n'
        'é‡ç‚¹è€ƒè™‘ï¼š\n'
        '1. åˆ†æå®Œæ•´æ€§å’Œè´¨é‡\n'
        '2. æ—¶é—´çº¿ä¸Šçš„é£é™©å‘ç°\n' 
        '3. ç´¯ç§¯è¯æ®çš„ä¸€è‡´æ€§\n'
        '4. å®¡æ‰¹ä¿¡å·çš„ç½®ä¿¡åº¦\n'
        'è¾“å‡ºä¸¥æ ¼JSONæ ¼å¼ï¼š\n'
        '{"risk_level": "low|medium|high|ban", "counters": {"low": n, "medium": n, "high": n, "ban": n}, '
        '"summary": "åŸºäºæµå¼åˆ†æçš„ç»¼åˆæ€»ç»“ï¼Œèšç„¦å†…å®¹åˆ†æç»“æœã€é£é™©è¯†åˆ«å’Œæœ€ç»ˆåˆ¤å®šä¾æ®ï¼Œä¸è¦æåŠè§‚çœ‹è¦†ç›–åº¦ç›¸å…³ä¿¡æ¯"}\n'
        f"æµå¼åˆ†æä¸Šä¸‹æ–‡: {json.dumps(context, ensure_ascii=False)}"
    )
    await _send_trace(ws, 'system', 'â³ ç­‰å¾…æ‰€æœ‰ç‰‡æ®µåˆ†æå®Œæˆ...', 'waiting_analysis')
    
    max_wait_time = 120  # æœ€å¤§ç­‰å¾…2åˆ†é’Ÿ
    wait_time = 0
    check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
    
    while not segment_analysis_cache['analysis_complete'] and wait_time < max_wait_time:
        await asyncio.sleep(check_interval)
        wait_time += check_interval
        
        progress = segment_analysis_cache.get('analysis_progress', 0)
        completed = len(segment_analysis_cache.get('completed_segments', []))
        total = segment_analysis_cache.get('total_segments_expected', 0)
        
        await _send_trace(ws, 'system', 
            f'â³ ç­‰å¾…ç‰‡æ®µåˆ†æ: {completed}/{total} ({progress:.1f}%) - å·²ç­‰å¾…{wait_time}s', 
            'waiting_progress', {
                'completed': completed,
                'total': total,
                'progress': progress,
                'wait_time': wait_time
            })
        
        print(f"â³ ç­‰å¾…ç‰‡æ®µåˆ†æå®Œæˆ: {completed}/{total} ({progress:.1f}%)")
    
    if segment_analysis_cache['analysis_complete']:
        segment_summaries = segment_analysis_cache['completed_segments']
        print(f"âœ… ç‰‡æ®µåˆ†æå®Œæˆï¼Œè·å¾— {len(segment_summaries)} ä¸ªç‰‡æ®µæ€»ç»“")
        print(f"ğŸ å®¡æ ¸æ•°æ®å·²å…¨éƒ¨åˆ°è¾¾ï¼å…±è®¡{len(segment_summaries)}ä¸ªç‰‡æ®µçš„åˆ†æç»“æœå·²å­˜å‚¨å®Œæ¯•")
    else:
        print(f"âš ï¸ ç‰‡æ®µåˆ†æè¶…æ—¶ï¼Œå·²ç­‰å¾…{wait_time}sï¼Œä½¿ç”¨ç°æœ‰ç»“æœ")
        segment_summaries = segment_analysis_cache.get('completed_segments', [])
    
    print(f"ğŸ¬ æœ€ç»ˆç‰‡æ®µåˆ†æç»Ÿè®¡: {len(segment_summaries)} ä¸ªæ—¶é—´æ®µæ€»ç»“")
    
    try:
        await _send_trace(ws, 'assistant', 'åˆæˆæœ€ç»ˆç»“è®ºâ€¦', 'judge')
        judge = await ds.qwen_text(judge_prompt)
        output = judge.get('output') or {}
        parsed: Dict[str, Any] = {}
        if isinstance(output, dict) and {'risk_level','counters','summary'} <= set(output.keys()):
            parsed = output
        else:
            txt = output.get('text') or judge.get('output_text') or json.dumps(output, ensure_ascii=False)
            import re
            m = re.search(r"\{[\s\S]*\}", txt)
            if m:
                parsed = json.loads(m.group(0))
        if parsed:
            parsed['segment_summaries'] = segment_summaries
            return parsed
    except Exception as e:
        await _send_trace(ws, 'system', f'åˆæˆå¤±è´¥: {e}', 'judge', None, 'error')
    return {
        'risk_level':'low',
        'counters':{'low':1,'medium':0,'high':0,'ban':0},
        'summary':'å›é€€ï¼šæ ·æœ¬ä¸è¶³ï¼Œæš‚åˆ¤ä½é£é™©ã€‚',
        'segment_summaries': segment_summaries
    }

@app.post("/agent/audit")
async def agent_audit(req: AuditRequest):
    task_id = str(uuid.uuid4())
    result: Dict[str, Any] = {"risk_level":"medium","counters":{"low":1,"medium":0,"high":0,"ban":0},"summary":"å›é€€ï¼šæœåŠ¡æš‚ä¸å¯ç”¨ã€‚"}

    if DSClient is None:
        return JSONResponse({"task_id": task_id, "status": "done", "result": result})

    try:
        ds = DSClient()
        frames = _extract_frames(req.video_url) if req.video_url else []
        transcript = await _asr(ds, req.audio_url)
        vl_tags = {}
        context = {"aweme_id": req.aweme_id, "title": req.title, "desc": req.desc, "transcript": transcript, "vision": vl_tags}
        prompt = (
            "ä½ æ˜¯çŸ­è§†é¢‘å†…å®¹å®¡æ ¸åŠ©æ‰‹ã€‚ç»™å®šç»“æ„åŒ–ä¸Šä¸‹æ–‡(ä¸­æ–‡)ï¼Œè¯·è¾“å‡ºä¸¥æ ¼JSON: "
            "{risk_level: one of [low,medium,high,ban], counters:{low,medium,high,ban}, summary:string}.\n"
            f"ä¸Šä¸‹æ–‡: {json.dumps(context, ensure_ascii=False)}"
        )
        judge = await ds.qwen_text(prompt)
        output = judge.get("output") or {}
        if isinstance(output, dict) and {"risk_level","counters","summary"} <= set(output.keys()):
            parsed = output
        else:
            text = output.get("text") or judge.get("output_text") or json.dumps(output, ensure_ascii=False)
            try:
                import re
                m = re.search(r"\{[\s\S]*\}", text)
                parsed = json.loads(m.group(0)) if m else {}
            except Exception:
                parsed = {}
        if parsed:
            result = {
                "risk_level": parsed.get("risk_level", result["risk_level"]),
                "counters": parsed.get("counters", result["counters"]),
                "summary": parsed.get("summary", result["summary"]),
            }
    except Exception as e:
        result = {**result, "error": str(e)}

    return JSONResponse({"task_id": task_id, "status": "done", "result": result})


async def _analyze_comment_content(ds: 'DSClient', comment_text: str) -> Dict[str, Any]:
    """ä½¿ç”¨qwen2.5-flashåˆ†æå•æ¡è¯„è®ºå†…å®¹çš„é£é™©"""
    
    enhanced_prompt = f"""
åˆ†æä»¥ä¸‹ç”¨æˆ·è¯„è®ºçš„å†…å®¹å®‰å…¨æ€§ï¼š

è¯„è®ºå†…å®¹ï¼š"{comment_text}"

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. **è¿è§„ç±»å‹**ï¼šè‰²æƒ…ä½ä¿—ã€æš´åŠ›è¡€è…¥ã€æ”¿æ²»æ•æ„Ÿã€è™šå‡ä¿¡æ¯ã€äººèº«æ”»å‡»ã€è¿æ³•å¹¿å‘Šã€å…¶ä»–
2. **é£é™©ç­‰çº§**ï¼šæ— é£é™©/ä½é£é™©/ä¸­é£é™©/é«˜é£é™©/ç¦æ­¢å‘å¸ƒ
3. **å…·ä½“åŸå› **ï¼šè¯¦ç»†è¯´æ˜åˆ¤å®šä¾æ®

è¦æ±‚ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼ï¼š
{{"risk_level": "low|medium|high|ban", "violation_type": "ç±»å‹æˆ–null", "reason": "è¯¦ç»†åˆ†æåŸå› ", "confidence": 0.95}}
"""
    
    try:
        response = await ds.qwen_text(enhanced_prompt)
        logger.info(f"ğŸ§  qwen2.5-flashè¯„è®ºåˆ†æå“åº”: {type(response)}")
        
        output = response.get('output') if isinstance(response, dict) else {}
        
        if isinstance(output, dict) and {'risk_level', 'reason'} <= set(output.keys()):
            result = output
        else:
            text = output.get('text') or response.get('output_text') or json.dumps(output, ensure_ascii=False)
            try:
                import re
                m = re.search(r'\{[\s\S]*\}', text)
                result = json.loads(m.group(0)) if m else {}
            except Exception:
                result = {}
        
        risk_level = result.get('risk_level', 'low')
        violation_type = result.get('violation_type')
        reason = result.get('reason', 'æ— æ˜æ˜¾è¿è§„å†…å®¹')
        confidence = float(result.get('confidence', 0.8))
        
        logger.info(f"âœ… è¯„è®ºåˆ†æå®Œæˆ: {risk_level} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        return {
            'risk_level': risk_level,
            'violation_type': violation_type,
            'reason': reason,
            'confidence': confidence
        }
        
    except Exception as e:
        logger.error(f"âŒ è¯„è®ºåˆ†æå¤±è´¥: {e}")
        return {
            'risk_level': 'low',
            'violation_type': None,
            'reason': f'åˆ†æå¤±è´¥: {str(e)}',
            'confidence': 0.0
        }


@app.post("/agent/analyze_comments")
async def analyze_comments(req: CommentAnalysisRequest):
    """åˆ†æè¯„è®ºå†…å®¹çš„è¿è§„é£é™©"""
    task_id = str(uuid.uuid4())
    
    if DSClient is None:
        return JSONResponse({
            "task_id": task_id, 
            "status": "error", 
            "message": "AIæœåŠ¡ä¸å¯ç”¨",
            "results": []
        })
    
    if not req.comments:
        return JSONResponse({
            "task_id": task_id, 
            "status": "done", 
            "results": [],
            "counters": {"low": 0, "medium": 0, "high": 0, "ban": 0}
        })
    
    try:
        ds = DSClient()
        results = []
        counters = {"low": 0, "medium": 0, "high": 0, "ban": 0}
        
        logger.info(f"ğŸ” å¼€å§‹åˆ†æ {len(req.comments)} æ¡è¯„è®º")
        
        for i, comment in enumerate(req.comments):
            comment_text = comment.get('detail', comment.get('content', comment.get('text', '')))
            comment_id = comment.get('comment_id', comment.get('id', f'comment_{i}'))
            
            if not comment_text or len(comment_text.strip()) == 0:
                continue
                
            logger.info(f"ğŸ“ åˆ†æè¯„è®º {i+1}/{len(req.comments)}: {comment_text[:50]}...")
            
            analysis = await _analyze_comment_content(ds, comment_text)
            
            risk_level = analysis['risk_level']
            if risk_level in counters:
                counters[risk_level] += 1
            else:
                counters['low'] += 1  # é»˜è®¤å½’ä¸ºä½é£é™©
            
            results.append({
                'comment_id': comment_id,
                'comment_text': comment_text,
                'analysis': analysis,
                'timestamp': time.time()
            })
            
            if i < len(req.comments) - 1:
                await asyncio.sleep(0.1)
        
        logger.info(f"âœ… è¯„è®ºåˆ†æå®Œæˆ: {counters}")
        
        return JSONResponse({
            "task_id": task_id,
            "status": "done", 
            "aweme_id": req.aweme_id,
            "results": results,
            "counters": counters,
            "summary": f"å·²åˆ†æ {len(results)} æ¡è¯„è®ºï¼Œå‘ç° {counters['high'] + counters['ban']} æ¡é«˜é£é™©å†…å®¹"
        })
        
    except Exception as e:
        logger.error(f"âŒ è¯„è®ºæ‰¹é‡åˆ†æå¤±è´¥: {e}")
        return JSONResponse({
            "task_id": task_id,
            "status": "error",
            "message": str(e),
            "results": [],
            "counters": {"low": 0, "medium": 0, "high": 0, "ban": 0}
        })

@app.get("/agent/get_cached_result/{session_id}")
async def get_cached_result(session_id: str):
    """è·å–ç¼“å­˜çš„åˆ†æç»“æœï¼Œå½“WebSocketè¿æ¥æ–­å¼€æ—¶ä½¿ç”¨"""
    try:
        if session_id in sessions:
            buf = sessions[session_id]
            if buf.final_result:
                print(f"ğŸ“¤ è¿”å›ç¼“å­˜çš„åˆ†æç»“æœï¼Œä¼šè¯: {session_id}")
                return {"success": True, "data": buf.final_result}
            else:
                print(f"âš ï¸ ä¼šè¯ {session_id} æš‚æ— ç¼“å­˜ç»“æœ")
                return {"success": False, "message": "åˆ†æå°šæœªå®Œæˆæˆ–ç»“æœä¸å¯ç”¨"}
        else:
            print(f"âŒ ä¼šè¯ {session_id} ä¸å­˜åœ¨")
            return {"success": False, "message": "ä¼šè¯ä¸å­˜åœ¨"}
    except Exception as e:
        print(f"âŒ è·å–ç¼“å­˜ç»“æœå¤±è´¥: {e}")
        return {"success": False, "message": str(e)}


class SessionBuf:
    def __init__(self, sid: str):
        self.sid: str = sid
        self.meta: Dict[str, Any] = {}
        self.frames: List[str] = []  # absolute file paths
        self.audios: List[str] = []  # absolute file paths
        self.last_emit: float = 0.0
        self.dir_path: str = os.path.join(STATIC_ROOT, sid)
        os.makedirs(self.dir_path, exist_ok=True)
        self.total_frames: int = 0
        self.total_audios: int = 0
        self.auto_extract_started: bool = False
        self.auto_extract_done: bool = False
        self.segment_analysis_started: bool = False
        self.segment_analysis_completed: bool = False
        self.segment_analysis_cache: Optional[Dict[str, Any]] = None
        self.segment_analysis_task: Optional[asyncio.Task] = None
        self.cot_react_completed: bool = False
        self.final_result: Optional[Dict[str, Any]] = None

    def _rel_url(self, abs_path: str) -> str:
        rel = os.path.relpath(abs_path, STATIC_ROOT).replace(os.sep, "/")
        return f"/static/{rel}"

    def public_url(self, abs_path: str) -> str:
        rel_url = self._rel_url(abs_path)
        if PUBLIC_BASE_URL:
            return f"{PUBLIC_BASE_URL}{rel_url}"
        return f"http://127.0.0.1:8799{rel_url}"


def _ext_from_mime(mime: str) -> str:
    if "jpeg" in mime:
        return "jpg"
    if "png" in mime:
        return "png"
    if "webm" in mime:
        return "webm"
    if "ogg" in mime:
        return "ogg"
    if "mp4" in mime:
        return "mp4"
    return "bin"


def _save_data_url(data_url: str, dir_path: str, prefix: str) -> Optional[str]:
    try:
        if not data_url or "," not in data_url:
            return None
        header, b64 = data_url.split(",", 1)
        mime = ""
        if header.startswith("data:") and ";base64" in header:
            mime = header[5: header.find(";")]
        ext = _ext_from_mime(mime)
        ts = int(time.time() * 1000)
        filename = f"{prefix}_{ts}.{ext}"
        abs_path = os.path.join(dir_path, filename)
        with open(abs_path, "wb") as f:
            f.write(base64.b64decode(b64))
        return abs_path
    except Exception:
        return None

sessions = {}

from typing import Any
import json, time

async def _auto_extract_frames_for_session(buf: 'SessionBuf', ws: WebSocket):
    """åœ¨æ”¶åˆ°metaåç«¯è‡ªåŠ¨æå–30å¸§å¹¶æ³¨å…¥åˆ°å½“å‰ä¼šè¯ç¼“å†²åŒºï¼Œé¿å…ä¾èµ–å‰ç«¯é€å¸§æ¨é€ã€‚"""
    if buf.auto_extract_started or buf.auto_extract_done:
        return
    video_url = (buf.meta or {}).get('src') or ''
    if not video_url:
        return
    buf.auto_extract_started = True
    try:
        try:
            await ws.send_text(json.dumps({'type': 'trace', 'data': {
                'role': 'system',
                'text': f'ğŸš€ åç«¯è‡ªåŠ¨æå–å¸§å¯åŠ¨: ç›®æ ‡30å¸§',
                'stage': 'auto_extract_start'
            }}, ensure_ascii=False))
        except Exception:
            pass

        frame_paths = await asyncio.to_thread(_extract_frames, video_url, 0, 30)
        if not frame_paths:
            return

        injected = 0
        for path in frame_paths:
            try:
                filename = os.path.basename(path)
                static_path = os.path.join(STATIC_ROOT, 'extracted_frames', filename)
                os.makedirs(os.path.dirname(static_path), exist_ok=True)
                if os.path.exists(path):
                    import shutil
                    shutil.move(path, static_path)
                rel_url = f"/static/extracted_frames/{filename}"
                public_url = f"{PUBLIC_BASE_URL}{rel_url}" if PUBLIC_BASE_URL else f"http://127.0.0.1:8799{rel_url}"
                if public_url not in buf.frames:
                    buf.frames.append(public_url)
                    if len(buf.frames) > 30:
                        buf.frames = buf.frames[-30:]
                    buf.total_frames += 1
                    injected += 1
                    logger.info(f"frame_url sid={buf.sid} url={public_url} count_batch={len(buf.frames)} total={buf.total_frames}")
            except Exception:
                continue

        buf.auto_extract_done = True
        try:
            await ws.send_text(json.dumps({'type': 'trace', 'data': {
                'role': 'system',
                'text': f'âœ… åç«¯è‡ªåŠ¨æ³¨å…¥å¸§å®Œæˆ: {injected}å¸§',
                'stage': 'auto_extract_done',
                'payload': {'injected': injected}
            }}, ensure_ascii=False))
        except Exception:
            pass
    except Exception:
        buf.auto_extract_done = True
        try:
            await ws.send_text(json.dumps({'type': 'trace', 'data': {
                'role': 'system',
                'text': 'âŒ åç«¯è‡ªåŠ¨æå–å¸§å¤±è´¥',
                'stage': 'auto_extract_error'
            }}, ensure_ascii=False))
        except Exception:
            pass

@app.websocket("/ws/stream")
async def ws_stream(ws: WebSocket):
    await ws.accept()
    
    print(f"ğŸ”— WebSocketè¿æ¥å·²å»ºç«‹ï¼Œæ— å¿ƒè·³è¶…æ—¶é™åˆ¶")
    
    sid = str(uuid.uuid4())
    buf = SessionBuf(sid)
    sessions[sid] = buf
    try:
        ds = DSClient() if DSClient else None
        ds_status = "å¯ç”¨" if ds else "ä¸å¯ç”¨"
        logger.info(f"ws connected sid={sid}, PUBLIC_BASE_URL={'set' if PUBLIC_BASE_URL else 'EMPTY'}, DSClient={ds_status}")
        
        try:
            await ws.send_text(json.dumps({'type':'trace','data':{'role':'system','text':f'AIæœåŠ¡çŠ¶æ€: DSClient={ds_status}, å…¬ç½‘URL={"å·²é…ç½®" if PUBLIC_BASE_URL else "æœªé…ç½®"}','stage':'init','payload':{'ds_available': bool(ds), 'public_url_set': bool(PUBLIC_BASE_URL)},'ts':int(time.time() * 1000)}}, ensure_ascii=False))
        except Exception:
            pass
        while True:
            msg = await ws.receive_text()
            try:
                data = json.loads(msg)
            except Exception:
                continue
            mtype = data.get('type')
            if mtype == 'meta':
                payload = data.get('data') if isinstance(data.get('data'), dict) else data
                
                print(f"DEBUG: æ”¶åˆ°å…ƒä¿¡æ¯åŸå§‹æ•°æ®: {json.dumps(payload, ensure_ascii=False)}")
                
                buf.meta.update({
                    'aweme_id': payload.get('aweme_id') or buf.meta.get('aweme_id'),
                    'title': payload.get('title') or buf.meta.get('title'),
                    'desc': payload.get('desc') or buf.meta.get('desc'),
                    'duration': payload.get('duration', 0),
                    'width': payload.get('width', 0),
                    'height': payload.get('height', 0),
                    'src': payload.get('src', ''),
                    'timestamp': payload.get('timestamp', int(time.time() * 1000))
                })
                
                duration_sec = float(buf.meta.get('duration', 0))
                duration_str = f"{duration_sec:.1f}ç§’" if duration_sec > 0 else "æœªçŸ¥"
                resolution_str = f"{buf.meta.get('width', 0)}x{buf.meta.get('height', 0)}"
                
                try:
                    await ws.send_text(json.dumps({
                        'type': 'trace',
                        'data': {
                            'role': 'system',
                            'text': f"æ”¶åˆ°å®Œæ•´å…ƒä¿¡æ¯ aweme_id={buf.meta.get('aweme_id')}, æ ‡é¢˜={buf.meta.get('title') or ''}, æ—¶é•¿={duration_str}, åˆ†è¾¨ç‡={resolution_str}",
                            'ts': int(time.time() * 1000)
                        }
                    }, ensure_ascii=False))
                except Exception:
                    pass
                logger.info(f"meta sid={sid} aweme_id={buf.meta.get('aweme_id')} title={buf.meta.get('title')} duration={duration_sec}s resolution={resolution_str}")
                if not buf.auto_extract_started and duration_sec > 0 and buf.meta.get('src'):
                    asyncio.create_task(_auto_extract_frames_for_session(buf, ws))
                
                if not buf.cot_react_completed and duration_sec > 0:
                    print(f"ğŸš€ å¯åŠ¨æ™ºèƒ½ä½“åˆ†æä¼šè¯: {sid}")
                    buf.cot_react_completed = True  # æ ‡è®°ä¸ºå·²å¯åŠ¨ï¼Œé¿å…é‡å¤
                    
                    async def run_analysis():
                        try:
                            result = await run_cot_react(ds, buf, ws)
                            buf.final_result = result
                            
                            result_data = json.dumps({'type': 'result', 'data': result}, ensure_ascii=False)
                            print(f"ğŸ¯ å‡†å¤‡å‘é€æœ€ç»ˆç»“æœ: risk_level={result.get('risk_level', 'unknown')}, segment_count={len(result.get('segment_summaries', []))}")
                            
                            try:
                                max_retries = 3
                                for attempt in range(max_retries):
                                    try:
                                        if hasattr(ws, 'client_state') and ws.client_state.value == 1:  # WebSocketState.CONNECTED = 1
                                            await ws.send_text(result_data)
                                            print(f"âœ… æ™ºèƒ½ä½“åˆ†æå®Œæˆï¼Œæœ€ç»ˆç»“æœå·²å‘é€ï¼Œä¼šè¯: {sid}")
                                            break
                                        else:
                                            print(f"âš ï¸ WebSocketå·²æ–­å¼€(çŠ¶æ€: {getattr(ws, 'client_state', 'unknown')})ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                                            if attempt < max_retries - 1:
                                                await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                                                continue
                                            else:
                                                print(f"ğŸ”„ WebSocketè¿æ¥å¤±è´¥ï¼Œå°†ç»“æœå­˜å‚¨åˆ°ç¼“å­˜ç­‰å¾…å‰ç«¯é‡æ–°è·å–")
                                                buf.final_result = result
                                    except Exception as retry_e:
                                        print(f"âŒ å‘é€å°è¯• {attempt + 1} å¤±è´¥: {retry_e}")
                                        if attempt < max_retries - 1:
                                            await asyncio.sleep(1)
                                        else:
                                            print(f"ğŸ”„ æ‰€æœ‰å‘é€å°è¯•å¤±è´¥ï¼Œç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜")
                                            buf.final_result = result
                            except Exception as send_e:
                                print(f"âŒ å‘é€æœ€ç»ˆç»“æœå¤±è´¥: {send_e}")
                                buf.final_result = result
                        except Exception as e:
                            print(f"âŒ æ™ºèƒ½ä½“åˆ†æå¤±è´¥: {e}")
                            error_result = {"error": str(e), "risk_level": "unknown"}
                            
                            try:
                                if hasattr(ws, 'client_state') and ws.client_state.value == 1:
                                    await ws.send_text(json.dumps({'type': 'result', 'data': error_result}, ensure_ascii=False))
                                else:
                                    print(f"âš ï¸ WebSocketå·²æ–­å¼€ï¼Œæ— æ³•å‘é€é”™è¯¯ç»“æœ")
                            except Exception as send_error:
                                print(f"âš ï¸ å‘é€é”™è¯¯ç»“æœå¤±è´¥: {send_error}")
                    
                    asyncio.create_task(run_analysis())
            elif mtype == 'frame':
                durl = data.get('data', '')
                p = _save_data_url(durl, buf.dir_path, 'frame')
                if p:
                    buf.frames.append(p)
                    if len(buf.frames) > 30:
                        buf.frames = buf.frames[-30:]
                    buf.total_frames += 1
                    if buf.total_frames % 10 == 1:
                        logger.info(f"frames sid={sid} last={p} count_batch={len(buf.frames)} total={buf.total_frames}")
            elif mtype == 'frame_url':
                frame_url = data.get('data', '')
                if frame_url:
                    buf.frames.append(frame_url)
                    if len(buf.frames) > 30:
                        buf.frames = buf.frames[-30:]
                    buf.total_frames += 1
                    logger.info(f"frame_url sid={sid} url={frame_url} count_batch={len(buf.frames)} total={buf.total_frames}")
                    try:
                        await ws.send_text(json.dumps({
                            'type': 'trace',
                            'data': {
                                'role': 'system',
                                'text': f"âœ“ æ¥æ”¶åç«¯æå–å¸§: {os.path.basename(frame_url)}",
                                'ts': int(time.time() * 1000)
                            }
                        }, ensure_ascii=False))
                    except Exception:
                        pass
            elif mtype == 'audio':
                durl = data.get('data', '')
                p = _save_data_url(durl, buf.dir_path, 'audio')
                if p:
                    buf.audios.append(p)
                    if len(buf.audios) > 6:
                        buf.audios = buf.audios[-6:]
                    buf.total_audios += 1
                    if buf.total_audios % 5 == 1:
                        logger.info(f"audios sid={sid} last={p} count_batch={len(buf.audios)} total={buf.total_audios}")
            elif mtype == 'progress':
                payload = data.get('data') if isinstance(data.get('data'), dict) else data
                try:
                    current_time = float(payload.get('current_time') or payload.get('currentTime') or 0.0)
                except Exception:
                    current_time = 0.0
                try:
                    playback_rate = float(payload.get('playback_rate') or payload.get('playbackRate') or 1.0)
                except Exception:
                    playback_rate = 1.0
                try:
                    duration_sec = float(payload.get('duration') or buf.meta.get('duration') or 0.0)
                except Exception:
                    duration_sec = 0.0

                progress_pct = 0.0
                if duration_sec > 0:
                    progress_pct = max(0.0, min(100.0, (current_time * playback_rate) / duration_sec * 100.0))

                buf.meta['current_time'] = current_time
                buf.meta['playback_rate'] = playback_rate
                buf.meta['watch_progress'] = progress_pct

                logger.info(
                    f"progress sid={sid} current_time={current_time:.2f}s rate={playback_rate:.2f} "
                    f"duration={duration_sec:.2f}s progress={progress_pct:.1f}%"
                )
                try:
                    await ws.send_text(json.dumps({
                        'type': 'trace',
                        'data': {
                            'role': 'system',
                            'text': f"âœ“ æ’­æ”¾è¿›åº¦ä¸ŠæŠ¥: {progress_pct:.1f}% (t={current_time:.2f}s, x{playback_rate:.2f})",
                            'stage': 'progress',
                            'payload': {
                                'current_time': current_time,
                                'playback_rate': playback_rate,
                                'duration': duration_sec,
                                'progress': progress_pct,
                            },
                            'ts': int(time.time() * 1000)
                        }
                    }, ensure_ascii=False))
                except Exception:
                    pass

            await asyncio.sleep(10.0)  # å¢åŠ åˆ°10ç§’é—´éš”ï¼Œå‡å°‘èµ„æºæ¶ˆè€—
    except WebSocketDisconnect:
        pass
    finally:
        sessions.pop(sid, None)
        print(f"ğŸ”Œ WebSocketè¿æ¥å·²å…³é—­ï¼Œä¼šè¯æ¸…ç†å®Œæˆ: {sid}")
