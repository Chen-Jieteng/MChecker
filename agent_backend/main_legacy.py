from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Response
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import uuid, tempfile, subprocess, os, json, time, base64
import logging
import httpx
import asyncio
from enum import Enum
from dataclasses import dataclass, field
from datetime import datetime

try:
    # å¼ºåˆ¶åˆ‡æ¢è§†è§‰æ¨¡å‹åˆ° qwen-vl-plusï¼ˆè¦†ç›–ç¯å¢ƒå˜é‡ï¼‰
    os.environ['DASHSCOPE_VL_MODEL'] = 'qwen-vl-plus'
    print("ğŸ”§ å·²å¼ºåˆ¶è®¾ç½®è§†è§‰æ¨¡å‹: qwen-vl-plus")
    from dashscope_client import DSClient, VisionDSClient
    from vision_api_coordinator import get_vision_coordinator
    # Test DSClient initialization at startup
    test_ds = DSClient()
    vision_ds = VisionDSClient()
    print(f"âœ… DSClient initialized successfully at startup")
    print(f"âœ… VisionDSClient initialized successfully")
except Exception as e:
    print(f"âŒ DSClient initialization failed: {e}")
    DSClient = None
    VisionDSClient = None

app = FastAPI(title="MChecker Agent Backend")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')
logger = logging.getLogger("agent")

# Static serving for saved frames/audio chunks
STATIC_ROOT = os.path.abspath(os.getenv("AGENT_STATIC_ROOT", os.path.join("agent_backend", "static")))
os.makedirs(STATIC_ROOT, exist_ok=True)
app.mount("/static", StaticFiles(directory=STATIC_ROOT), name="static")

PUBLIC_BASE_URL = (os.getenv("PUBLIC_BASE_URL", "").strip().rstrip('/'))

# ========== äº‹ä»¶é©±åŠ¨çŠ¶æ€æœº ==========

class TaskType(Enum):
    VIDEO_ANALYSIS = "video_analysis"
    AUDIO_ANALYSIS = "audio_analysis" 
    COMMENT_ANALYSIS = "comment_analysis"
    FORM_FILLING = "form_filling"

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"

@dataclass
class AnalysisTask:
    id: str
    type: TaskType
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Dict[Any, Any]] = None
    error: Optional[str] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    timeout_seconds: int = 60

@dataclass 
class WorkflowSession:
    session_id: str
    aweme_id: Optional[str] = None
    tasks: Dict[str, AnalysisTask] = field(default_factory=dict)
    websocket: Optional[WebSocket] = None
    created_at: datetime = field(default_factory=datetime.now)

# å…¨å±€çŠ¶æ€å­˜å‚¨ (ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨Redis)
workflow_sessions: Dict[str, WorkflowSession] = {}

# äº‹ä»¶å‘é€å™¨
async def emit_event(session_id: str, event_type: str, data: Dict[Any, Any]):
    """å‘å‰ç«¯å‘é€äº‹ä»¶"""
    session = workflow_sessions.get(session_id)
    if session and session.websocket:
        try:
            event = {
                'type': event_type,
                'session_id': session_id,
                'timestamp': int(time.time() * 1000),
                'data': data
            }
            await session.websocket.send_text(json.dumps(event, ensure_ascii=False))
            logger.info(f"ğŸ“¡ Event sent: {event_type} to session {session_id}")
        except Exception as e:
            logger.error(f"âŒ Failed to send event {event_type}: {e}")

# ä»»åŠ¡ç®¡ç†å™¨
class TaskManager:
    @staticmethod
    async def start_task(session_id: str, task_type: TaskType, **kwargs) -> str:
        """å¯åŠ¨ä¸€ä¸ªåˆ†æä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        task = AnalysisTask(
            id=task_id,
            type=task_type,
            status=TaskStatus.RUNNING,
            started_at=datetime.now()
        )
        
        session = workflow_sessions.get(session_id)
        if session:
            session.tasks[task_id] = task
            
        # å‘é€ä»»åŠ¡å¼€å§‹äº‹ä»¶
        await emit_event(session_id, 'task_started', {
            'task_id': task_id,
            'task_type': task_type.value,
            'status': task.status.value
        })
        
        # å¼‚æ­¥æ‰§è¡Œä»»åŠ¡
        asyncio.create_task(TaskManager._execute_task(session_id, task_id, **kwargs))
        return task_id
    
    @staticmethod
    async def _execute_task(session_id: str, task_id: str, **kwargs):
        """æ‰§è¡Œå…·ä½“çš„åˆ†æä»»åŠ¡"""
        session = workflow_sessions.get(session_id)
        if not session:
            return
            
        task = session.tasks.get(task_id)
        if not task:
            return
            
        try:
            # æ ¹æ®ä»»åŠ¡ç±»å‹æ‰§è¡Œä¸åŒçš„åˆ†æ
            if task.type == TaskType.VIDEO_ANALYSIS:
                result = await TaskManager._execute_video_analysis(session_id, **kwargs)
            elif task.type == TaskType.AUDIO_ANALYSIS:
                result = await TaskManager._execute_audio_analysis(session_id, **kwargs)
            elif task.type == TaskType.COMMENT_ANALYSIS:
                result = await TaskManager._execute_comment_analysis(session_id, **kwargs)
            else:
                raise ValueError(f"Unknown task type: {task.type}")
            
            # ä»»åŠ¡å®Œæˆ
            task.status = TaskStatus.COMPLETED
            task.result = result
            task.completed_at = datetime.now()
            
            # å‘é€å®Œæˆäº‹ä»¶
            await emit_event(session_id, 'task_completed', {
                'task_id': task_id,
                'task_type': task.type.value,
                'status': task.status.value,
                'result': result
            })
            
        except Exception as e:
            # ä»»åŠ¡å¤±è´¥
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.completed_at = datetime.now()
            
            logger.error(f"âŒ Task {task_id} failed: {e}")
            await emit_event(session_id, 'task_failed', {
                'task_id': task_id,
                'task_type': task.type.value,
                'status': task.status.value,
                'error': str(e)
            })
    
    @staticmethod
    async def _execute_video_analysis(session_id: str, **kwargs) -> Dict[Any, Any]:
        """æ‰§è¡Œè§†é¢‘åˆ†æ"""
        aweme_id = kwargs.get('aweme_id')
        
        # æ¨¡æ‹Ÿè§†é¢‘åˆ†æè¿‡ç¨‹
        await emit_event(session_id, 'step_ready', {
            'step': 'video_extraction',
            'message': 'æ­£åœ¨æå–è§†é¢‘å¸§...'
        })
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿæå–æ—¶é—´
        
        await emit_event(session_id, 'step_ready', {
            'step': 'video_ai_analysis', 
            'message': 'æ­£åœ¨è¿›è¡ŒAIè§†è§‰åˆ†æ...'
        })
        await asyncio.sleep(3)  # æ¨¡æ‹ŸAIåˆ†ææ—¶é—´
        
        # è¿”å›æ¨¡æ‹Ÿç»“æœ
        return {
            'video_id': aweme_id,
            'frames_extracted': 12,
            'analysis_result': {
                'category': 'å¨±ä¹',
                'tags': ['éŸ³ä¹', 'èˆè¹ˆ', 'ç”Ÿæ´»'],
                'risk_level': 'low',
                'confidence': 0.85
            }
        }
    
    @staticmethod
    async def _execute_audio_analysis(session_id: str, **kwargs) -> Dict[Any, Any]:
        """æ‰§è¡ŒéŸ³é¢‘åˆ†æ"""
        await emit_event(session_id, 'step_ready', {
            'step': 'audio_extraction',
            'message': 'æ­£åœ¨æå–éŸ³é¢‘...'
        })
        await asyncio.sleep(1)
        
        await emit_event(session_id, 'step_ready', {
            'step': 'speech_recognition',
            'message': 'æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...'
        })
        await asyncio.sleep(2)
        
        return {
            'transcript': 'è¿™æ˜¯ä¸€æ®µå¾ˆæœ‰è¶£çš„è§†é¢‘å†…å®¹',
            'keywords': ['æœ‰è¶£', 'å†…å®¹', 'è§†é¢‘'],
            'sentiment': 'positive'
        }
    
    @staticmethod
    async def _execute_comment_analysis(session_id: str, **kwargs) -> Dict[Any, Any]:
        """æ‰§è¡Œè¯„è®ºåˆ†æ"""
        comments = kwargs.get('comments', [])
        
        await emit_event(session_id, 'step_ready', {
            'step': 'comment_processing',
            'message': f'æ­£åœ¨åˆ†æ{len(comments)}æ¡è¯„è®º...'
        })
        await asyncio.sleep(1)
        
        return {
            'total_comments': len(comments),
            'risk_distribution': {
                'low': len(comments) * 0.7,
                'medium': len(comments) * 0.2,
                'high': len(comments) * 0.1
            },
            'summary': 'è¯„è®ºæ•´ä½“ç§¯æå‘ä¸Š'
        }

class AuditRequest(BaseModel):
    aweme_id: Optional[str] = None
    video_url: Optional[str] = None
    audio_url: Optional[str] = None
    title: Optional[str] = None
    desc: Optional[str] = None

class CommentAnalysisRequest(BaseModel):
    aweme_id: Optional[str] = None
    comments: List[Dict[str, Any]] = []

@app.get("/health")
async def health():
    return {"ok": True}

class ReasoningConfig(BaseModel):
    step_limit: int = 15  # å¢åŠ æ­¥éª¤æ•°ä»¥æ”¯æŒæ›´å…¨é¢çš„è§†é¢‘åˆ†æ
    tick_seconds: float = 2.0
    use_asr: bool = True
    temperature: Optional[float] = None
    top_p: Optional[float] = None

_REASONING_CFG = ReasoningConfig(step_limit=15, tick_seconds=2.0, use_asr=True, temperature=0.3, top_p=0.9)

@app.post("/agent/config/reasoning")
async def set_reasoning_config(cfg: ReasoningConfig):
    global _REASONING_CFG
    _REASONING_CFG = cfg
    # also reflect to DSClient default params via env for simplicity
    if cfg.temperature is not None:
        os.environ['DASHSCOPE_TEMPERATURE'] = str(cfg.temperature)
    if cfg.top_p is not None:
        os.environ['DASHSCOPE_TOP_P'] = str(cfg.top_p)
    return {"ok": True, "config": _REASONING_CFG.dict()}

@app.get("/agent/config/reasoning")
async def get_reasoning_config():
    return _REASONING_CFG.dict()

@app.get("/agent/api/status")
async def get_api_status():
    """è·å–APIåè°ƒå™¨çŠ¶æ€"""
    coordinator = get_vision_coordinator()
    if coordinator:
        status = coordinator.get_status()
        status['coordinator_enabled'] = True
    else:
        status = {
            'coordinator_enabled': False,
            'message': 'æœªé…ç½®è§†è§‰APIåè°ƒå™¨ï¼Œä½¿ç”¨é»˜è®¤è½®æ¢æœºåˆ¶',
            'total_keys': 1,
            'total_concurrent_requests': 0,
            'total_available_slots': 'unlimited'
        }
    
    return status

@app.get("/api/frames/info")
async def get_frames_info():
    """è·å–å½“å‰æå–çš„å¸§ä¿¡æ¯"""
    import os
    import glob
    import re
    
    frames_dir = "agent_backend/static/extracted_frames"
    if not os.path.exists(frames_dir):
        return {"frame_count": 0, "max_frame_number": 0, "frames": []}
    
    # è·å–æ‰€æœ‰å¸§æ–‡ä»¶
    frame_files = glob.glob(os.path.join(frames_dir, "frame_*.jpg"))
    frame_files.sort()
    
    # æå–å¸§ç¼–å·
    frames = []
    max_frame_number = 0
    for frame_file in frame_files:
        filename = os.path.basename(frame_file)
        match = re.match(r'frame_(\d+)\.jpg', filename)
        if match:
            frame_number = int(match.group(1))
            max_frame_number = max(max_frame_number, frame_number)
            frames.append({
                "number": frame_number,
                "filename": filename,
                "url": f"http://127.0.0.1:8799/static/extracted_frames/{filename}"
            })
    
    return {
        "frame_count": len(frames),
        "max_frame_number": max_frame_number,
        "frames": frames
    }

@app.options("/proxy/video")
async def proxy_video_options():
    # å…è®¸CORSé¢„æ£€ï¼Œé¿å…å‰ç«¯è·¨åŸŸå—é˜»
    return Response(status_code=204, headers={
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "*",
        "Content-Length": "0",
    })

@app.get("/proxy/video")
async def proxy_video(url: str):
    """ä»£ç†è§†é¢‘è¯·æ±‚ï¼Œè§£å†³è·¨åŸŸé—®é¢˜"""
    if not url:
        raise HTTPException(status_code=400, detail="Missing URL parameter")
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            async with client.stream("GET", url) as response:
                if response.status_code != 200:
                    raise HTTPException(status_code=response.status_code, detail="Failed to fetch video")
                
                # Get content type and length
                content_type = response.headers.get("content-type", "video/mp4")
                content_length = response.headers.get("content-length")
                
                # Set response headers
                headers = {
                    "Content-Type": content_type,
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
                    "Access-Control-Allow-Headers": "*",
                }
                if content_length:
                    headers["Content-Length"] = content_length
                
                async def generate():
                    async for chunk in response.aiter_bytes(chunk_size=8192):
                        yield chunk
                
                return StreamingResponse(generate(), headers=headers)
    except httpx.TimeoutException:
        raise HTTPException(status_code=408, detail="Request timeout")
    except Exception as e:
        logger.error(f"Video proxy error: {e}")
        raise HTTPException(status_code=500, detail=f"Proxy error: {str(e)}")

@app.post("/fix/frames")
async def fix_frame_extraction(request: dict):
    """å½»åº•ä¿®å¤å¸§æå– - ç»•è¿‡æ‰€æœ‰ç¼“å­˜"""
    video_url = request.get("video_url", "https://www.douyin.com/aweme/v1/play/?video_id=v0200fa50000bqv2ovedm15352jvv5vg&line=0&file_id=efac24de9d2548228975fc8429e5bdcb&sign=3b7c4acc3b831e92448d6909510074c0&is_play_url=1&source=PackSourceEnum_PUBLISH")
    count = request.get("count", 30)
    
    # å†…è”ffmpegå‘½ä»¤ï¼Œç»•è¿‡å‡½æ•°ç¼“å­˜
    import tempfile
    import subprocess
    import os
    
    tmpdir = tempfile.mkdtemp(prefix="fix_frames_")
    outpat = os.path.join(tmpdir, "frame_%02d.jpg")
    
    # ç›´æ¥æ‰§è¡Œffmpegå‘½ä»¤
    cmd = ["ffmpeg", "-y", "-i", video_url, "-vf", "fps=1", "-vframes", str(count), outpat]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶
        frame_files = []
        for i in range(1, count + 1):
            frame_path = outpat.replace("%02d", f"{i:02d}")
            if os.path.exists(frame_path):
                frame_files.append(frame_path)
        
        # è½¬æ¢ä¸ºURL
        frame_urls = []
        for path in frame_files:
            filename = os.path.basename(path)
            static_path = os.path.join(STATIC_ROOT, "extracted_frames", filename)
            os.makedirs(os.path.dirname(static_path), exist_ok=True)
            
            if os.path.exists(path):
                import shutil
                shutil.move(path, static_path)
                rel_url = f"/static/extracted_frames/{filename}"
                public_url = f"http://127.0.0.1:8799{rel_url}"
                frame_urls.append(public_url)
        
        return {
            "success": True,
            "frame_urls": frame_urls,
            "count": len(frame_urls),
            "debug": f"Generated {len(frame_files)} frames, moved {len(frame_urls)} to static"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "debug": f"Command failed: {' '.join(cmd)}"
        }

@app.post("/extract/frames")
async def extract_frames_from_url(request: dict):
    """ä»è§†é¢‘URLç›´æ¥æå–å¸§ï¼Œç»•è¿‡å‰ç«¯è·¨åŸŸé™åˆ¶"""
    video_url = request.get("video_url")
    if not video_url:
        raise HTTPException(status_code=400, detail="Missing video_url")
    
    try:
        # å¼ºåˆ¶æå–30å¸§ä»¥è¦†ç›–å®Œæ•´è§†é¢‘
        logger.info(f"å¼€å§‹æå–30å¸§: {video_url}")
        frame_paths = _extract_frames(video_url, fps=0, count=30)
        logger.info(f"å®é™…æå–å¸§æ•°: {len(frame_paths)}")
        if not frame_paths:
            return {"success": False, "error": "No frames extracted"}
        
        # å°†å¸§è·¯å¾„è½¬æ¢ä¸ºå…¬ç½‘URL
        frame_urls = []
        for path in frame_paths:
            # ç§»åŠ¨æ–‡ä»¶åˆ°é™æ€ç›®å½•
            filename = os.path.basename(path)
            static_path = os.path.join(STATIC_ROOT, "extracted_frames", filename)
            os.makedirs(os.path.dirname(static_path), exist_ok=True)
            
            if os.path.exists(path):
                import shutil
                shutil.move(path, static_path)
                
                # ç”Ÿæˆå…¬ç½‘URL
                rel_url = f"/static/extracted_frames/{filename}"
                if PUBLIC_BASE_URL:
                    public_url = f"{PUBLIC_BASE_URL}{rel_url}"
                else:
                    public_url = f"http://127.0.0.1:8799{rel_url}"
                frame_urls.append(public_url)
        
        return {
            "success": True,
            "frame_urls": frame_urls,
            "count": len(frame_urls)
        }
    except Exception as e:
        logger.error(f"Frame extraction error: {e}")
        return {"success": False, "error": str(e)}

# ---- helpers ----

def _extract_frames(video_url: str, fps: int = 0, count: int = 30) -> List[str]:
    """æå–è§†é¢‘å¸§ï¼Œå¼ºåˆ¶ç¡®ä¿è¿”å›æŒ‡å®šæ•°é‡çš„å¸§"""
    paths: List[str] = []
    if not video_url:
        return paths
    
    tmpdir = tempfile.mkdtemp(prefix="mchecker_frames_")
    outpat = os.path.join(tmpdir, "frame_%02d.jpg")
    
    try:
        # ğŸ”¥ ä¿®å¤ï¼šè®©30å¸§å‡åŒ€åˆ†å¸ƒåœ¨æ•´ä¸ªè§†é¢‘æ—¶é•¿å†…
        if fps == 0:
            # æ–¹æ¡ˆ1ï¼šå°è¯•è·å–è§†é¢‘ä¿¡æ¯å¹¶è®¡ç®—é—´éš”
            try:
                # è·å–è§†é¢‘æ—¶é•¿
                probe_cmd = ["ffprobe", "-v", "quiet", 
                            "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                            "-headers", "Referer: https://www.douyin.com/",
                            "-show_entries", "format=duration", "-of", "csv=p=0", video_url]
                probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
                video_duration = float(probe_result.stdout.strip()) if probe_result.returncode == 0 else 30.0
                
                # è®¡ç®—å‡åŒ€é—´éš”ï¼šæ¯éš” duration/count ç§’å–ä¸€å¸§
                interval = max(1.0, video_duration / count)
                target_fps = 1.0 / interval
                
                cmd = ["ffmpeg", "-y", 
                       "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                       "-headers", "Referer: https://www.douyin.com/",
                       "-reconnect", "1", "-reconnect_streamed", "1", "-reconnect_delay_max", "5",
                       "-timeout", "30000000",
                       "-i", video_url, "-vf", f"fps={target_fps}", "-vframes", str(count), outpat]
                print(f"ğŸ¬ è§†é¢‘æ—¶é•¿{video_duration:.1f}sï¼Œä½¿ç”¨fps={target_fps:.3f}ç­–ç•¥æå–{count}å¸§")
            except:
                # å›é€€æ–¹æ¡ˆï¼šå¦‚æœæ— æ³•è·å–æ—¶é•¿ï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥
                cmd = ["ffmpeg", "-y", 
                       "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                       "-headers", "Referer: https://www.douyin.com/",
                       "-reconnect", "1", "-reconnect_streamed", "1", "-reconnect_delay_max", "5",
                       "-timeout", "30000000",
                       "-i", video_url, "-vf", "fps=0.2", "-vframes", str(count), outpat]
                print(f"ğŸ¬ ä½¿ç”¨å›é€€ç­–ç•¥fps=0.2æå–{count}å¸§")
        else:
            cmd = ["ffmpeg", "-y", 
                   "-user_agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                   "-headers", "Referer: https://www.douyin.com/",
                   "-reconnect", "1", "-reconnect_streamed", "1", "-reconnect_delay_max", "5",
                   "-timeout", "30000000",
                   "-i", video_url, "-vf", f"fps={fps}", "-vframes", str(count), outpat]
        
        print(f"DEBUG: Executing command for {count} frames: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"ERROR: ffmpeg failed with code {result.returncode}")
            print(f"STDERR: {result.stderr}")
            return paths
        
        # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„å¸§æ–‡ä»¶
        for i in range(1, count + 1):
            frame_path = outpat.replace("%02d", f"{i:02d}")
            if os.path.exists(frame_path):
                paths.append(frame_path)
        
        print(f"DEBUG: Successfully extracted {len(paths)} frames out of {count} requested")
        return paths
        
    except Exception as e:
        print(f"EXCEPTION in _extract_frames: {e}")
        import traceback
        traceback.print_exc()
        return []

async def _asr(ds: DSClient, audio_url: Optional[str]) -> str:
    if not audio_url:
        return ""
    try:
        r = await ds.asr_paraformer(audio_url)
        text = r.get("output",{}).get("text") or r.get("result",{}).get("text") or ""
        return text
    except Exception:
        return ""

# ---- reasoning helpers (CoT + ReAct) ----
async def _send_trace(ws: WebSocket, role: str, text: str, stage: str, payload: Optional[Dict[str, Any]] = None, kind: Optional[str] = None):
    try:
        # æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€
        if hasattr(ws, 'client_state') and ws.client_state.value != 1:  # WebSocketState.CONNECTED = 1
            print(f"âš ï¸ WebSocketè¿æ¥å·²æ–­å¼€ï¼Œè·³è¿‡å‘é€trace")
            return False
            
        data = {'role': role, 'text': text, 'stage': stage, 'ts': int(time.time() * 1000)}
        if payload is not None:
            data['payload'] = payload
        if kind is not None:
            data['kind'] = kind
        await ws.send_text(json.dumps({'type': 'trace', 'data': data}, ensure_ascii=False))
        return True
    except Exception as e:
        print(f"âš ï¸ WebSocketå‘é€traceå¤±è´¥: {e}")
        return False  # ä¸å†æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ç¨‹åºå´©æºƒ

async def _send_heartbeat(ws: WebSocket):
    """å‘é€å¿ƒè·³åŒ…ä¿æŒè¿æ¥æ´»è·ƒ"""
    try:
        # æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€
        if hasattr(ws, 'client_state') and ws.client_state.value != 1:  # WebSocketState.CONNECTED = 1
            print(f"ğŸ’” WebSocketè¿æ¥å·²æ–­å¼€ï¼Œè·³è¿‡å¿ƒè·³å‘é€")
            return False
            
        await ws.send_text(json.dumps({'type': 'heartbeat', 'ts': int(time.time() * 1000)}, ensure_ascii=False))
        return True
    except Exception as e:
        print(f"ğŸ’” å¿ƒè·³å‘é€å¤±è´¥ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€: {e}")
        return False

async def _send_tool(ws: WebSocket, name: str, payload: Optional[Dict[str, Any]] = None):
    try:
        await ws.send_text(json.dumps({'type': 'tool', 'name': name, 'payload': payload or {}, 'ts': int(time.time() * 1000)}, ensure_ascii=False))
    except Exception:
        pass

async def _vision_describe(ds: DSClient, buf: 'SessionBuf') -> Dict[str, Any]:
    """åˆ†æ®µè§†é¢‘åˆ†æï¼šæŒ‰æ—¶é—´çª—å£åˆ†æè§†é¢‘å¸§ï¼Œè¯†åˆ«é«˜é£é™©ç‰‡æ®µ"""
    import base64
    
    # åˆ†æ®µåˆ†æç­–ç•¥ï¼šæ¯æ¬¡åˆ†æè¿ç»­çš„4å¸§ä½œä¸ºä¸€ä¸ªæ—¶é—´çª—å£
    total_frames = len(buf.frames)
    if total_frames == 0:
        return {'text': '', 'segments': [], 'risk_segments': []}
    
    # è®¡ç®—å½“å‰åˆ†æçš„æ—¶é—´çª—å£ï¼ˆæœ€æ–°4å¸§ï¼‰
    current_window_start = max(0, total_frames - 4)
    current_frames = buf.frames[current_window_start:]
    
    # å‡†å¤‡å½“å‰çª—å£çš„å›¾ç‰‡è¾“å…¥ï¼ˆè½¬Base64ï¼‰
    img_inputs: List[str] = []
    frame_timestamps = []
    
    for i, frame_path in enumerate(current_frames):
        # è®¡ç®—å¸§çš„æ—¶é—´æˆ³ï¼ˆå‡è®¾æ¯å¸§é—´éš”0.5ç§’ï¼‰
        timestamp = (current_window_start + i) * 0.5
        frame_timestamps.append(timestamp)
        
        if isinstance(frame_path, str) and frame_path.startswith('http://127.0.0.1:8799/static/'):
            # æœ¬åœ°æ–‡ä»¶è½¬Base64ç»™DashScope (ä»é¡¹ç›®æ ¹ç›®å½•)
            local_path = frame_path.replace('http://127.0.0.1:8799/static/', 'agent_backend/static/')
            logger.info(f"ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡: {frame_path} -> {local_path}")
            try:
                if os.path.exists(local_path):
                    with open(local_path, 'rb') as f:
                        img_data = base64.b64encode(f.read()).decode('utf-8')
                        img_inputs.append(f"data:image/jpeg;base64,{img_data}")
                        logger.info(f"âœ… æˆåŠŸç¼–ç å›¾ç‰‡: {local_path} ({len(img_data)} chars)")
                else:
                    logger.error(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
            except Exception as e:
                logger.error(f"âŒ å›¾ç‰‡ç¼–ç å¤±è´¥ {local_path}: {e}")
                continue
        elif isinstance(frame_path, str) and frame_path.startswith(('http://', 'https://')):
            img_inputs.append(frame_path)
        elif isinstance(frame_path, str) and os.path.exists(frame_path):
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬Base64
            try:
                with open(frame_path, 'rb') as f:
                    img_data = base64.b64encode(f.read()).decode('utf-8')
                    img_inputs.append(f"data:image/jpeg;base64,{img_data}")
            except Exception as e:
                logger.error(f"Failed to encode local image {frame_path}: {e}")
                continue
    
    if not img_inputs:
        logger.warning(f"âš ï¸ æ— å¯ç”¨å›¾ç‰‡è¾“å…¥: frames={len(buf.frames)}, current_frames={len(current_frames)}")
        return {'text': '', 'segments': [], 'risk_segments': []}
    
    logger.info(f"ğŸ¯ å‡†å¤‡è°ƒç”¨è§†è§‰æ¨¡å‹: {len(img_inputs)}å¼ å›¾ç‰‡")
    
    # å¢å¼ºçš„åˆ†ææç¤ºï¼Œè¦æ±‚è¯†åˆ«é£é™©ç‚¹å’Œæ—¶é—´å®šä½
    enhanced_prompt = f"""
åˆ†æè¿™{len(img_inputs)}å¸§è¿ç»­è§†é¢‘ç”»é¢ï¼ˆæ—¶é—´çª—å£: {frame_timestamps[0]:.1f}s - {frame_timestamps[-1]:.1f}sï¼‰ï¼š

1. **å†…å®¹æè¿°**ï¼šç®€è¦æè¿°äººç‰©ã€åœºæ™¯ã€åŠ¨ä½œã€æ–‡å­—ã€ç‰©å“
2. **é£é™©è¯†åˆ«**ï¼šè¯†åˆ«ä»»ä½•å¯èƒ½çš„è¿è§„å†…å®¹ï¼ˆæš´åŠ›ã€è‰²æƒ…ã€æ”¿æ²»æ•æ„Ÿã€è™šå‡ä¿¡æ¯ã€è¿æ³•ç­‰ï¼‰
3. **é£é™©ç­‰çº§**ï¼šå¦‚å‘ç°é£é™©ï¼Œè¯„ä¼°ç­‰çº§ï¼ˆä½é£é™©/ä¸­é£é™©/é«˜é£é™©/è¿ç¦ï¼‰
4. **å…³é”®æ—¶åˆ»**ï¼šæ ‡æ³¨å…³é”®åŠ¨ä½œæˆ–é£é™©ç‚¹å‡ºç°çš„å…·ä½“æ—¶é—´

æ ¼å¼ï¼š[å†…å®¹æè¿°] | [é£é™©ç­‰çº§ï¼šæ— /ä½/ä¸­/é«˜/ç¦] | [å…³é”®æ—¶åˆ»ï¼šX.Xs]
    """
    
    r_vl = await ds.qwen_vl(img_inputs, prompt=enhanced_prompt)
    logger.info(f"âœ… è§†è§‰æ¨¡å‹è°ƒç”¨å®Œæˆ: æ”¶åˆ°å“åº” {type(r_vl)}")
    
    # Try to extract plain text
    text = ''
    out = r_vl.get('output') if isinstance(r_vl, dict) else {}
    if isinstance(out, dict):
        choices = out.get('choices', [])
        if choices and isinstance(choices[0], dict):
            msg = choices[0].get('message', {})
            content = msg.get('content', [])
            if content and isinstance(content[0], dict):
                text = content[0].get('text', '')
    if not text:
        text = json.dumps(r_vl, ensure_ascii=False)[:500]
    
    # è§£æé«˜é£é™©ç‰‡æ®µä¿¡æ¯
    risk_segments = []
    segments_info = []
    
    if text and '|' in text:
        # è§£æç»“æ„åŒ–è¾“å‡ºï¼š[å†…å®¹æè¿°] | [é£é™©ç­‰çº§ï¼šX] | [å…³é”®æ—¶åˆ»ï¼šX.Xs]
        parts = text.split('|')
        if len(parts) >= 3:
            content_desc = parts[0].strip()
            risk_part = parts[1].strip()
            time_part = parts[2].strip()
            
            # æå–é£é™©ç­‰çº§
            risk_level = 'low'
            if 'é«˜é£é™©' in risk_part or 'é«˜' in risk_part:
                risk_level = 'high'
            elif 'ä¸­é£é™©' in risk_part or 'ä¸­' in risk_part:
                risk_level = 'medium'  
            elif 'è¿ç¦' in risk_part or 'ç¦' in risk_part:
                risk_level = 'ban'
            elif 'ä½é£é™©' in risk_part or 'ä½' in risk_part:
                risk_level = 'low'
            elif 'æ— ' in risk_part:
                risk_level = 'none'
            
            # æå–æ—¶é—´æˆ³
            import re
            time_match = re.search(r'(\d+\.?\d*)s', time_part)
            timestamp = float(time_match.group(1)) if time_match else frame_timestamps[0]
            
            # æ„å»ºç‰‡æ®µä¿¡æ¯
            segment = {
                'start_time': frame_timestamps[0],
                'end_time': frame_timestamps[-1],
                'risk_level': risk_level,
                'description': content_desc,
                'key_timestamp': timestamp,
                'frames_analyzed': len(img_inputs)
            }
            
            segments_info.append(segment)
            
            # å¦‚æœæ˜¯é«˜é£é™©æˆ–è¿ç¦ï¼ŒåŠ å…¥é£é™©ç‰‡æ®µåˆ—è¡¨
            if risk_level in ['high', 'ban']:
                risk_segments.append({
                    'timestamp': timestamp,
                    'duration': frame_timestamps[-1] - frame_timestamps[0],
                    'risk_level': risk_level,
                    'description': content_desc,
                    'frames_count': len(img_inputs)
                })
    
    return {
        'text': text, 
        'segments': segments_info,
        'risk_segments': risk_segments,
        'window_start': frame_timestamps[0] if frame_timestamps else 0,
        'window_end': frame_timestamps[-1] if frame_timestamps else 0,
        'total_frames_analyzed': total_frames
    }

async def _analyze_single_segment(segment: Dict, video_duration: float, buf: 'SessionBuf', segment_index: int) -> Dict:
    """åˆ†æå•ä¸ªç‰‡æ®µ - å¹¶è¡Œè°ƒç”¨çš„ç‹¬ç«‹å‡½æ•°"""
    import time
    try:
        start_time = time.time()
        print(f"ğŸ¬ å¼€å§‹å¹¶è¡Œåˆ†æç‰‡æ®µ{segment_index}: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s (æ—¶åˆ»: {start_time:.3f})")
        segment_summary = await _generate_time_based_segment_summary(
            {}, segment, video_duration, buf
        )
        end_time = time.time()
        print(f"âœ… å¹¶è¡Œå®Œæˆç‰‡æ®µ{segment_index}åˆ†æ: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s (è€—æ—¶: {end_time - start_time:.3f}s)")
        return segment_summary
    except Exception as e:
        print(f"âŒ å¹¶è¡Œåˆ†æç‰‡æ®µ{segment_index}å¤±è´¥: {e}")
        # è¿”å›å¤±è´¥çš„å ä½ç¬¦
        return {
            'segment_index': segment_index,
            'time_range': f'{segment["start_time"]:.2f}s-{segment["end_time"]:.2f}s',
            'duration': f'{segment["duration"]:.2f}ç§’',
            'content': f'ç‰‡æ®µ{segment_index}åˆ†æå¤±è´¥: {str(e)}',
            'risk_level': 'low',
            'key_findings': []
        }

async def _preload_segment_analysis(time_segments: List[Dict], video_duration: float, buf: 'SessionBuf', ws: WebSocket, cache: Dict) -> None:
    """åå°é¢„åŠ è½½æ‰€æœ‰ç‰‡æ®µåˆ†æ - ä½¿ç”¨APIåè°ƒå™¨å®ç°æ™ºèƒ½å¹¶è¡Œ"""
    try:
        coordinator = get_vision_coordinator()
        
        if coordinator:
            print(f"ğŸš€ å¼€å§‹æ™ºèƒ½å¹¶è¡Œé¢„åŠ è½½ç‰‡æ®µåˆ†æ: {len(time_segments)}ä¸ªç‰‡æ®µï¼ˆä½¿ç”¨APIåè°ƒå™¨ï¼‰")
            print(f"ğŸ”§ åè°ƒå™¨çŠ¶æ€: {coordinator.get_status()}")
            
            await _send_trace(ws, 'system', 
                f'ğŸš€ å¯åŠ¨{len(time_segments)}ä¸ªç‰‡æ®µçš„æ™ºèƒ½å¹¶è¡Œåˆ†æï¼ˆæ— é”åè°ƒå™¨ï¼‰...', 
                'smart_parallel_analysis_start', {
                    'total_segments': len(time_segments),
                    'parallel_mode': True,
                    'lockless_coordinator': True,
                    'coordinator_status': coordinator.get_status()
                })
            
            # ğŸ¯ å…³é”®æ”¹è¿›ï¼šä½¿ç”¨APIåè°ƒå™¨ç®¡ç†çš„å¹¶è¡Œå¤„ç†
            print(f"ğŸ“¡ æ™ºèƒ½å¹¶è¡Œå‘é˜¿é‡Œç™¾ç‚¼å‘èµ·{len(time_segments)}ä¸ªè¯·æ±‚ï¼ˆåè°ƒå™¨è‡ªåŠ¨åˆ†é…API KEYï¼‰...")
            
            # åˆ›å»ºæ‰€æœ‰åˆ†æä»»åŠ¡
            analysis_tasks = [
                _analyze_single_segment(segment, video_duration, buf, i + 1)
                for i, segment in enumerate(time_segments)
            ]
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æï¼Œåè°ƒå™¨è‡ªåŠ¨ç®¡ç†API KEYåˆ†é…
            start_time = time.time()
            segment_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            end_time = time.time()
            
            print(f"âš¡ æ™ºèƒ½å¹¶è¡Œåˆ†æå®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")
            
        else:
            # å›é€€åˆ°é¡ºåºå¤„ç†
            print(f"âš ï¸ æœªé…ç½®APIåè°ƒå™¨ï¼Œå›é€€åˆ°é¡ºåºå¤„ç†: {len(time_segments)}ä¸ªç‰‡æ®µ")
            
            await _send_trace(ws, 'system', 
                f'âš ï¸ APIåè°ƒå™¨æœªé…ç½®ï¼Œå¯åŠ¨{len(time_segments)}ä¸ªç‰‡æ®µçš„é¡ºåºåˆ†æ...', 
                'fallback_sequential_analysis_start', {
                    'total_segments': len(time_segments),
                    'parallel_mode': False,
                    'reason': 'no_coordinator_configured'
                })
            
            # é¡ºåºæ‰§è¡Œæ‰€æœ‰åˆ†æ
            start_time = time.time()
            segment_results = []
            
            for i, segment in enumerate(time_segments):
                try:
                    print(f"ğŸ¬ é¡ºåºåˆ†æç‰‡æ®µ{i+1}/{len(time_segments)}: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s")
                    
                    result = await _analyze_single_segment(segment, video_duration, buf, i + 1)
                    segment_results.append(result)
                    
                    print(f"âœ… ç‰‡æ®µ{i+1}åˆ†æå®Œæˆï¼Œè¿›åº¦: {((i+1)/len(time_segments)*100):.1f}%")
                    
                    # å‘é€è¿›åº¦æ›´æ–°
                    try:
                        await _send_trace(ws, 'system', 
                            f'ğŸ“¹ ç‰‡æ®µ{i+1}/{len(time_segments)}åˆ†æå®Œæˆ ({((i+1)/len(time_segments)*100):.1f}%)', 
                            'segment_progress', {
                                'completed': i + 1,
                                'total': len(time_segments),
                                'progress': (i + 1) / len(time_segments) * 100
                            })
                    except:
                        pass
                    
                    # æ·»åŠ å°å»¶è¿Ÿé¿å…APIé™åˆ¶
                    if i < len(time_segments) - 1:
                        await asyncio.sleep(0.5)
                        
                except Exception as e:
                    print(f"âŒ ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {e}")
                    fallback_segment = {
                        'segment_index': i + 1,
                        'time_range': f'{segment["start_time"]:.1f}s-{segment["end_time"]:.1f}s',
                        'duration': f'{segment["duration"]:.1f}ç§’',
                        'content': f'ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {str(e)}',
                        'risk_level': 'low',
                        'key_findings': []
                    }
                    segment_results.append(fallback_segment)
            
            end_time = time.time()
            print(f"âš¡ é¡ºåºåˆ†æå®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        # å¤„ç†ç»“æœ
        successful_segments = []
        failed_count = 0
        
        for i, result in enumerate(segment_results):
            if isinstance(result, Exception):
                print(f"âŒ ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {result}")
                # åˆ›å»ºå¤±è´¥çš„å ä½ç¬¦
                fallback_segment = {
                    'segment_index': i + 1,
                    'time_range': f'{time_segments[i]["start_time"]:.1f}s-{time_segments[i]["end_time"]:.1f}s',
                    'duration': f'{time_segments[i]["duration"]:.1f}ç§’',
                    'content': f'ç‰‡æ®µ{i+1}åˆ†æå¼‚å¸¸: {str(result)}',
                    'risk_level': 'low',
                    'key_findings': []
                }
                successful_segments.append(fallback_segment)
                failed_count += 1
            else:
                successful_segments.append(result)
                print(f"âœ… ç‰‡æ®µ{i+1}æ™ºèƒ½å¹¶è¡Œåˆ†ææˆåŠŸ")
        
        # æ›´æ–°ç¼“å­˜
        cache['completed_segments'] = successful_segments
        cache['analysis_complete'] = True
        # ä¼šè¯çº§å®Œæˆæ ‡å¿—
        try:
            buf.segment_analysis_completed = True
        except Exception:
            pass
        cache['analysis_progress'] = 100
        
        # ğŸ¯ ç”¨æˆ·è¯·æ±‚çš„å…³é”®æ—¥å¿—ï¼šæ‰€æœ‰å®¡æ ¸æ•°æ®åˆ°è¾¾æç¤º
        print(f"ğŸ å®¡æ ¸æ•°æ®å·²å…¨éƒ¨åˆ°è¾¾ï¼æˆåŠŸåˆ†æ{len(successful_segments) - failed_count}ä¸ªç‰‡æ®µï¼Œå¤±è´¥{failed_count}ä¸ªç‰‡æ®µ")
        print(f"ğŸ‰ é¡ºåºåˆ†æç»Ÿè®¡: æˆåŠŸ{len(successful_segments) - failed_count}ä¸ª, å¤±è´¥{failed_count}ä¸ª, æ€»è€—æ—¶{end_time - start_time:.2f}ç§’")
        
        await _send_trace(ws, 'system', 
            f'âœ… é¡ºåºåˆ†æå®Œæˆ: {len(successful_segments)}ä¸ªç‰‡æ®µ (è€—æ—¶{end_time - start_time:.2f}s)', 
            'sequential_analysis_complete', {
                'total_segments': len(successful_segments),
                'successful': len(successful_segments) - failed_count,
                'failed': failed_count,
                'duration': end_time - start_time,
                'analysis_complete': True
            })
            
    except Exception as e:
        print(f"âŒ å¹¶è¡Œé¢„åŠ è½½åˆ†æå¤±è´¥: {e}")
        cache['analysis_complete'] = True  # å³ä½¿å¤±è´¥ä¹Ÿæ ‡è®°å®Œæˆï¼Œé¿å…æ— é™ç­‰å¾…
        try:
            buf.segment_analysis_completed = True
        except Exception:
            pass
        # ğŸ¯ å³ä½¿å¼‚å¸¸ä¹Ÿè¦é€šçŸ¥æ•°æ®åˆ°è¾¾çŠ¶æ€ï¼ˆè™½ç„¶å¯èƒ½ä¸å®Œæ•´ï¼‰
        completed_segments = cache.get('completed_segments', [])
        print(f"ğŸ å®¡æ ¸æ•°æ®å·²å…¨éƒ¨åˆ°è¾¾ï¼ï¼ˆå¼‚å¸¸ä¸­æ–­ï¼‰æˆåŠŸåˆ†æ{len(completed_segments)}ä¸ªç‰‡æ®µ")

async def _generate_time_based_segment_summary(memory: Dict, segment_info: Dict, video_duration: float, buf: 'SessionBuf' = None) -> Dict[str, Any]:
    """ç”ŸæˆåŸºäºæ—¶é—´çš„è§†é¢‘ç‰‡æ®µæ€»ç»“"""
    try:
        start_time = segment_info['start_time']
        end_time = segment_info['end_time']
        segment_index = segment_info['index']
        
        # æ ¹æ®æ—¶é—´æ®µé€‰æ‹©å¯¹åº”çš„å¸§è¿›è¡Œåˆ†æ
        segment_content = ""
        segment_risk_level = "low"
        
        # ä»ç¼“å†²åŒºè·å–æ‰€æœ‰å¸§
        buf_frames = buf.frames if buf else []
        total_frames = len(buf_frames)
        
        if total_frames > 0 and video_duration > 0:
            # è®¡ç®—è¯¥æ—¶é—´æ®µå¯¹åº”çš„å¸§ç´¢å¼•èŒƒå›´
            start_frame_idx = int((start_time / video_duration) * total_frames)
            end_frame_idx = int((end_time / video_duration) * total_frames)
            
            # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
            start_frame_idx = max(0, min(start_frame_idx, total_frames - 1))
            end_frame_idx = max(start_frame_idx, min(end_frame_idx, total_frames - 1))
            
            # é€‰æ‹©è¯¥æ—¶é—´æ®µçš„å¸§è¿›è¡Œåˆ†æ
            segment_frames = buf_frames[start_frame_idx:end_frame_idx + 1]
            
            # å¦‚æœæ²¡æœ‰é€‰ä¸­å¸§ï¼Œè‡³å°‘é€‰æ‹©ä¸€å¸§
            if not segment_frames and total_frames > 0:
                segment_frames = [buf_frames[min(start_frame_idx, total_frames - 1)]]
                
            print(f"ğŸ¬ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: é€‰æ‹©å¸§{start_frame_idx}-{end_frame_idx} (å…±{len(segment_frames)}å¸§)")
            
            # å¯¹é€‰ä¸­çš„å¸§è¿›è¡Œè§†è§‰åˆ†æ - ä½¿ç”¨åè°ƒå™¨
            if segment_frames and VisionDSClient:
                try:
                    vision_client = VisionDSClient()
                    coordinator = get_vision_coordinator()
                    
                    # å°†å¸§URLè½¬æ¢ä¸ºbase64æ ¼å¼
                    img_inputs = []
                    for frame_path in segment_frames:
                        if isinstance(frame_path, str) and frame_path.startswith('http://127.0.0.1:8799/static/'):
                            local_path = frame_path.replace('http://127.0.0.1:8799/static/', 'agent_backend/static/')
                            print(f"ğŸ–¼ï¸ å¤„ç†æ—¶é—´æ®µå›¾ç‰‡: {frame_path} -> {local_path}")
                            try:
                                if os.path.exists(local_path):
                                    with open(local_path, 'rb') as f:
                                        img_data = base64.b64encode(f.read()).decode('utf-8')
                                        img_inputs.append(f"data:image/jpeg;base64,{img_data}")
                                        print(f"âœ… æˆåŠŸç¼–ç æ—¶é—´æ®µå›¾ç‰‡: {local_path} ({len(img_data)} chars)")
                                else:
                                    print(f"âŒ æ—¶é—´æ®µå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
                            except Exception as e:
                                print(f"âŒ æ—¶é—´æ®µå›¾ç‰‡ç¼–ç å¤±è´¥ {local_path}: {e}")
                                continue
                        elif isinstance(frame_path, str) and os.path.exists(frame_path):
                            # æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬Base64
                            try:
                                with open(frame_path, 'rb') as f:
                                    img_data = base64.b64encode(f.read()).decode('utf-8')
                                    img_inputs.append(f"data:image/jpeg;base64,{img_data}")
                            except Exception as e:
                                print(f"âŒ æ—¶é—´æ®µæœ¬åœ°å›¾ç‰‡ç¼–ç å¤±è´¥ {frame_path}: {e}")
                                continue
                    
                    if not img_inputs:
                        print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: æ— å¯ç”¨å›¾ç‰‡è¾“å…¥")
                        segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šæ— å¯ç”¨å›¾ç‰‡æ•°æ®"
                    else:
                        # æ„å»ºé’ˆå¯¹æ—¶é—´æ®µçš„æç¤ºè¯
                        time_prompt = f"""
### æ—¶é—´æ®µ {start_time:.1f}ç§’-{end_time:.1f}ç§’ çš„å†…å®¹åˆ†æ

#### [å†…å®¹æè¿°]ï¼šå…·ä½“æè¿°ç”»é¢å†…å®¹
- **ä¸»è¦äººç‰©/ç‰©ä½“çš„åŠ¨ä½œå’ŒçŠ¶æ€**ï¼š
- **åœºæ™¯ç¯å¢ƒçš„å˜åŒ–**ï¼š
- **ä»»ä½•å€¼å¾—æ³¨æ„çš„ç»†èŠ‚**ï¼š

#### [é£é™©è¯†åˆ«]ï¼šåˆ†ææ˜¯å¦å­˜åœ¨é£é™©å†…å®¹
- **äººç‰©è¡¨ç°**ï¼š
- **èƒŒæ™¯ç¯å¢ƒ**ï¼š
- **æ–‡å­—ä¿¡æ¯**ï¼š

#### [é£é™©ç­‰çº§]ï¼šæ— /ä½/ä¸­/é«˜/ç¦
- **é£é™©ç­‰çº§**ï¼š
  - ç†ç”±ï¼š

### æ€»ç»“
åœ¨è¿™{end_time - start_time:.1f}ç§’é’Ÿçš„è§†é¢‘ç‰‡æ®µä¸­ï¼Œ...
"""
                        
                        print(f"ğŸ¯ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}så‡†å¤‡è°ƒç”¨è§†è§‰æ¨¡å‹: {len(img_inputs)}å¼ å›¾ç‰‡")
                        
                        # ä½¿ç”¨åè°ƒå™¨è°ƒç”¨è§†è§‰æ¨¡å‹åˆ†æè¯¥æ—¶é—´æ®µçš„å¸§
                        if coordinator:
                            vl_result = await vision_client.qwen_vl_with_coordinator(
                                img_inputs, time_prompt, coordinator
                            )
                        else:
                            # å›é€€åˆ°æ™®é€šDSClient
                            ds = DSClient()
                            vl_result = await ds.qwen_vl(img_inputs, prompt=time_prompt)
                    
                    # è¯¦ç»†è°ƒè¯•DashScopeè¿”å›ç»“æœ
                    print(f"ğŸ” æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s DashScopeè¿”å›ç»“æœè°ƒè¯•:")
                    print(f"   vl_resultå­˜åœ¨: {vl_result is not None}")
                    if vl_result:
                        print(f"   vl_resultç±»å‹: {type(vl_result)}")
                        print(f"   vl_resulté”®: {list(vl_result.keys()) if isinstance(vl_result, dict) else 'not dict'}")
                        if 'output' in vl_result:
                            output = vl_result['output']
                            print(f"   outputç±»å‹: {type(output)}")
                            print(f"   outputé”®: {list(output.keys()) if isinstance(output, dict) else 'not dict'}")
                            if isinstance(output, dict) and 'text' in output:
                                text_content = output.get('text', '')
                                print(f"   texté•¿åº¦: {len(text_content)}")
                                print(f"   textå‰100å­—ç¬¦: {repr(text_content[:100])}")
                        print(f"   å®Œæ•´ç»“æœ: {vl_result}")
                    
                    if vl_result and vl_result.get('output'):
                        # ä¿®å¤DashScopeå“åº”è§£æè·¯å¾„
                        try:
                            choices = vl_result['output'].get('choices', [])
                            if choices and len(choices) > 0:
                                message = choices[0].get('message', {})
                                content_list = message.get('content', [])
                                if content_list and len(content_list) > 0:
                                    output_text = content_list[0].get('text', '')
                                else:
                                    output_text = ''
                            else:
                                output_text = ''
                            
                            if output_text:
                                segment_content = output_text[:800]  # å¢åŠ é•¿åº¦é™åˆ¶
                                
                                # æ”¹è¿›çš„é£é™©ç­‰çº§æå–
                                segment_risk_level = "low"  # é»˜è®¤ä½é£é™©
                                
                                # æ›´ç²¾ç¡®çš„é£é™©ç­‰çº§è¯†åˆ«
                                risk_patterns = [
                                    (['ç¦', 'è¿ç¦', 'ban'], 'ban'),
                                    (['é«˜é£é™©', 'é«˜', 'high', 'ä¸¥é‡', 'è¿è§„'], 'high'),  
                                    (['ä¸­é£é™©', 'ä¸­', 'medium', 'è­¦å‘Š', 'æ³¨æ„'], 'medium'),
                                    (['ä½é£é™©', 'ä½', 'low'], 'low'),
                                    (['æ— é£é™©', 'æ— ', 'none', 'æ­£å¸¸'], 'low')
                                ]
                                
                                # æ£€æŸ¥é£é™©ç­‰çº§éƒ¨åˆ†ï¼ˆé€šå¸¸åœ¨ç‰¹å®šæ ‡è¯†ä¹‹åï¼‰
                                risk_section = ""
                                if "é£é™©ç­‰çº§" in output_text:
                                    # æå–é£é™©ç­‰çº§éƒ¨åˆ†
                                    risk_start = output_text.find("é£é™©ç­‰çº§")
                                    if risk_start != -1:
                                        risk_section = output_text[risk_start:risk_start+50].lower()
                                elif "risk" in output_text.lower():
                                    risk_start = output_text.lower().find("risk")
                                    if risk_start != -1:
                                        risk_section = output_text[risk_start:risk_start+50].lower()
                                
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸“é—¨çš„é£é™©ç­‰çº§éƒ¨åˆ†ï¼Œä½¿ç”¨å…¨æ–‡
                                if not risk_section:
                                    risk_section = output_text.lower()
                                
                                # ä»é«˜åˆ°ä½æ£€æŸ¥é£é™©ç­‰çº§
                                for keywords, level in risk_patterns:
                                    if any(keyword in risk_section for keyword in keywords):
                                        segment_risk_level = level
                                        break
                                    
                                print(f"âœ… æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}sè§†è§‰åˆ†æå®Œæˆ: {len(segment_content)}å­—ç¬¦")
                                print(f"ğŸ“ åˆ†æå†…å®¹é¢„è§ˆ: {segment_content[:200]}...")
                            else:
                                print(f"âš ï¸ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: DashScopeå“åº”ä¸­æ‰¾ä¸åˆ°æ–‡æœ¬å†…å®¹")
                                segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šå“åº”è§£æå¤±è´¥"
                        except Exception as parse_error:
                            print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: å“åº”è§£æé”™è¯¯: {parse_error}")
                            segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šè§£æé”™è¯¯"
                    else:
                        print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}s: DashScopeè¿”å›ç»“æ„å¼‚å¸¸")
                        segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æå¤±è´¥ï¼šDashScopeè¿”å›å¼‚å¸¸"
                        
                except Exception as e:
                    error_message = str(e) if str(e) else f"{type(e).__name__}: {repr(e)}"
                    print(f"âŒ æ—¶é—´æ®µ{start_time:.1f}s-{end_time:.1f}sè§†è§‰åˆ†æå¤±è´¥: {error_message}")
                    segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æå¤±è´¥: {error_message}"
            else:
                segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šå¸§æ•°æ®ä¸å¯ç”¨"
        else:
            segment_content = f"ç¬¬{segment_index}ä¸ªæ—¶é—´æ®µ({start_time:.1f}s-{end_time:.1f}s)çš„è§†è§‰å†…å®¹åˆ†æï¼šè§†é¢‘æ•°æ®ä¸å¯ç”¨"
        
        # æ„å»ºåŸºäºæ—¶é—´çš„ç‰‡æ®µä¿¡æ¯
        time_based_segment = {
            'segment_index': segment_index,
            'time_range': f'{start_time:.2f}s-{end_time:.2f}s',
            'duration': f'{end_time - start_time:.2f}ç§’',
            'progress_range': f'{(start_time/video_duration)*100:.1f}%-{(end_time/video_duration)*100:.1f}%' if video_duration > 0 else f'ç‰‡æ®µ{segment_index}',
            'content': segment_content,
            'risk_level': segment_risk_level,
            'key_findings': [f"æ—¶é—´{start_time:.2f}s-{end_time:.2f}s: åŸºäºå®é™…å¸§å†…å®¹çš„åˆ†æç»“æœ"]
        }
        
        return time_based_segment
        
    except Exception as e:
        print(f"ç”Ÿæˆæ—¶é—´ç‰‡æ®µæ€»ç»“å¤±è´¥: {e}")
        return None

async def _generate_segment_summary(memory: Dict, segment_start: int, segment_end: int, 
                                   progress_start: float, progress_end: float) -> Dict[str, Any]:
    """ç”Ÿæˆè§†é¢‘ç‰‡æ®µæ€»ç»“"""
    try:
        # æå–å½“å‰ç‰‡æ®µçš„è§†è§‰åˆ†æå†…å®¹
        recent_vision = memory.get('vision', '')[-500:] if memory.get('vision') else ''
        recent_annotations = memory.get('stream_annotations', [])[-3:] if memory.get('stream_annotations') else []
        
        # æ„å»ºç‰‡æ®µä¿¡æ¯
        segment_info = {
            'time_range': f'{progress_start:.1f}%-{progress_end:.1f}%',
            'frame_range': f'{segment_start}-{segment_end}å¸§',
            'content': recent_vision[:200] if recent_vision else 'æš‚æ— è§†è§‰å†…å®¹',
            'risk_level': 'low',
            'key_findings': []
        }
        
        # åˆ†ææœ€è¿‘çš„æ ‡æ³¨å¯»æ‰¾é£é™©ç‚¹
        for ann in recent_annotations:
            if ann.get('content'):
                content = ann.get('content', '')[:100]
                if any(keyword in content.lower() for keyword in ['é£é™©', 'risk', 'è¿è§„', 'å¼‚å¸¸']):
                    segment_info['risk_level'] = 'medium'
                    segment_info['key_findings'].append(content)
        
        # ç”Ÿæˆç®€è¦æ€»ç»“
        if recent_vision:
            if 'é£é™©' in recent_vision or 'è¿è§„' in recent_vision:
                segment_info['risk_level'] = 'high'
            summary = recent_vision.split('ã€‚')[0][:100] + '...' if len(recent_vision) > 100 else recent_vision
            segment_info['content'] = summary
        
        return segment_info
        
    except Exception as e:
        # è¿”å›åŸºç¡€ç‰‡æ®µä¿¡æ¯
        return {
            'time_range': f'{progress_start:.1f}%-{progress_end:.1f}%',
            'frame_range': f'{segment_start}-{segment_end}å¸§',
            'content': f'ç‰‡æ®µåˆ†æå®Œæˆ (å¸§{segment_start}-{segment_end})',
            'risk_level': 'low',
            'key_findings': []
        }

async def _asr_transcribe(ds: DSClient, buf: 'SessionBuf') -> Dict[str, Any]:
    """Transcribe last audio chunk if present; returns {'text': str, 'audio': url_or_path}"""
    if not buf.audios:
        return {'text': '', 'audio': ''}
    last = buf.audios[-1]
    url = last if last.startswith(('http://','https://')) else buf.public_url(last)
    text = await _asr(ds, url)
    return {'text': text, 'audio': url}

async def _assess_accumulated_risk(stream_annotations: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åŸºäºæµå¼æ ‡æ³¨è¯„ä¼°ç´¯ç§¯é£é™©"""
    if not stream_annotations:
        return {'level': 'low', 'score': 0.1, 'reasoning': 'æ— è¶³å¤Ÿæ•°æ®'}
    
    risk_indicators = []
    total_confidence = 0.0
    
    for annotation in stream_annotations:
        content = annotation.get('content', '')
        if annotation.get('type') == 'vision':
            # è§†è§‰é£é™©æŒ‡æ ‡
            if any(word in content for word in ['è£¸éœ²', 'æš´åŠ›', 'è¡€è…¥', 'æ­¦å™¨']):
                risk_indicators.append(('high', 0.8, 'è§†è§‰è¿è§„å†…å®¹'))
            elif any(word in content for word in ['äº‰è®®', 'æ”¿æ²»', 'æ•æ„Ÿ']):
                risk_indicators.append(('medium', 0.6, 'æ•æ„Ÿè§†è§‰å†…å®¹'))
        elif annotation.get('type') == 'audio':
            # éŸ³é¢‘é£é™©æŒ‡æ ‡
            if any(word in content for word in ['éª‚äºº', 'è¯ˆéª—', 'èµŒåš', 'å¨èƒ']):
                risk_indicators.append(('high', 0.9, 'éŸ³é¢‘è¿è§„å†…å®¹'))
            elif any(word in content for word in ['å¹¿å‘Š', 'æ¨é”€', 'è”ç³»æ–¹å¼']):
                risk_indicators.append(('medium', 0.5, 'å•†ä¸šå¯¼æµå†…å®¹'))
    
    if not risk_indicators:
        return {'level': 'low', 'score': 0.2, 'reasoning': 'æœªå‘ç°æ˜æ˜¾é£é™©'}
    
    # è®¡ç®—ç»¼åˆé£é™©ç­‰çº§
    high_count = sum(1 for r in risk_indicators if r[0] == 'high')
    medium_count = sum(1 for r in risk_indicators if r[0] == 'medium')
    
    if high_count > 0:
        level = 'high'
        score = min(0.95, 0.7 + high_count * 0.1)
    elif medium_count >= 2:
        level = 'medium'
        score = min(0.8, 0.4 + medium_count * 0.15)
    else:
        level = 'low'
        score = min(0.6, 0.2 + medium_count * 0.1)
    
    reasoning = f"å‘ç°{len(risk_indicators)}ä¸ªé£é™©æŒ‡æ ‡: " + "; ".join([r[2] for r in risk_indicators[:3]])
    
    return {'level': level, 'score': score, 'reasoning': reasoning}

def _rules_retrieve(vision_text: str, asr_text: str) -> List[Dict[str, Any]]:
    """Heuristic rules retrieval based on keywords; returns list of rules."""
    rules: List[Dict[str, Any]] = []
    def hit(name: str, weight: float):
        rules.append({'name': name, 'weight': weight})
    vt = (vision_text or '').lower()
    at = (asr_text or '').lower()
    if any(k in vt for k in ['è¡€', 'æš´åŠ›', 'æ­¦å™¨', 'knife', 'gun']):
        hit('æš´åŠ›/è¡€è…¥-å›¾åƒ', 0.9)
    if any(k in vt for k in ['è£¸', 'æ•æ„Ÿéƒ¨ä½', 'è‰²æƒ…']):
        hit('ä½ä¿—/æ“¦è¾¹-å›¾åƒ', 0.8)
    if any(k in at for k in ['èµŒ', 'åšå½©', 'ä¸‹æ³¨', 'è¯ˆéª—', 'æ”¶æ¬¾', 'åŠ ç¾¤']):
        hit('èµŒåš/è¯ˆéª—-è¯­éŸ³', 1.0)
    if any(k in at for k in ['è”ç³»æ–¹å¼', 'vx', 'å¨ä¿¡', 'åŠ æˆ‘']):
        hit('å¯¼æµ-è”ç³»æ–¹å¼-è¯­éŸ³', 0.7)
    return rules[:6]

async def run_cot_react(ds: DSClient, buf: 'SessionBuf', ws: WebSocket) -> Dict[str, Any]:
    """Enhanced streaming CoT+ReAct: è¾¹çœ‹è§†é¢‘è¾¹åšæ•°æ®æ ‡æ³¨è¾¹åšäººå·¥å®¡æ‰¹"""
    memory: Dict[str, Any] = {
        'vision': '', 
        'asr': '', 
        'rules': [],
        'stream_annotations': [],  # æµå¼æ ‡æ³¨è®°å½•
        'approval_signals': [],    # å®¡æ‰¹ä¿¡å·ç´¯ç§¯
        'watch_progress': 0        # è§‚çœ‹è¿›åº¦æ¨¡æ‹Ÿ
    }
    step_limit = int(getattr(_REASONING_CFG, 'step_limit', 15) or 15)
    tick_seconds = float(getattr(_REASONING_CFG, 'tick_seconds', 2.0) or 2.0)
    use_asr = bool(getattr(_REASONING_CFG, 'use_asr', False))
    
    await _send_trace(ws, 'assistant', 'å¼€å§‹æµå¼CoT+ReActï¼šè¾¹çœ‹è¾¹æ ‡æ³¨è¾¹å®¡æ‰¹', 'reasoning', {
        'step_limit': step_limit, 
        'streaming_mode': True,
        'tick_seconds': tick_seconds,
        'use_asr': use_asr
    }, 'start')
    
    # ğŸš¨ ä¿®å¤ï¼šåˆå§‹åŒ–ç‰‡æ®µæ€»ç»“åˆ—è¡¨ï¼Œé¿å…æœªå®šä¹‰é”™è¯¯
    segment_summaries = []
    
    # ç‰‡æ®µåˆ†æç¼“å­˜åŒº - ç¡®ä¿æ‰€æœ‰ç‰‡æ®µåˆ†æå®Œæˆåæ‰è¿”å›ç»“æœ
    # å¤ç”¨ä¼šè¯çº§ç¼“å­˜ï¼Œç¡®ä¿åŒä¸€ä¼šè¯ä»…å¯åŠ¨ä¸€æ¬¡å¹¶è¡Œåˆ†æ
    if not getattr(buf, 'segment_analysis_cache', None):
        buf.segment_analysis_cache = {
            'completed_segments': [],
            'total_segments_expected': 0,
            'analysis_complete': False,
            'analysis_progress': 0,
            'analysis_started': False,
        }
    segment_analysis_cache = buf.segment_analysis_cache
    
    # åŸºäºè§†é¢‘å®é™…æ—¶é•¿çš„ç‰‡æ®µåˆ†æé…ç½®
    video_duration = float(buf.meta.get('duration', 0))  # è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
    segment_duration = 5.0  # æ¯ä¸ªç‰‡æ®µ5ç§’
    total_segments = max(1, int(video_duration / segment_duration)) if video_duration > 0 else 6
    
    # åˆå§‹åŒ–ç¼“å­˜åŒº
    segment_analysis_cache['total_segments_expected'] = total_segments
    
    print(f"ğŸ¬ è§†é¢‘ç‰‡æ®µåˆ†æé…ç½®: æ€»æ—¶é•¿={video_duration:.1f}s, ç‰‡æ®µæ—¶é•¿={segment_duration}s, æ€»ç‰‡æ®µæ•°={total_segments}")
    
    # é¢„è®¡ç®—æ‰€æœ‰æ—¶é—´æ®µ
    time_segments = []
    for i in range(total_segments):
        start_time = i * segment_duration
        end_time = min((i + 1) * segment_duration, video_duration)
        time_segments.append({
            'index': i + 1,
            'start_time': start_time,
            'end_time': end_time,
            'duration': end_time - start_time
        })
    
    current_segment_index = 0
    
    # æš‚ä¸å¯åŠ¨ç‰‡æ®µåˆ†æ - ç­‰å¾…å¸§æ•°æ®å‡†å¤‡å®Œæˆ
    print(f"ğŸ¬ ç‰‡æ®µåˆ†æç­‰å¾…å¸§æ•°æ®å‡†å¤‡ï¼Œæ€»å…±éœ€è¦åˆ†æ{len(time_segments)}ä¸ªç‰‡æ®µ")
    
    for step in range(1, step_limit+1):
        # ğŸ” å¾ªç¯è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” Step {step}: buf.frames={len(buf.frames)}, buf.audios={len(buf.audios)}")
        
        # ä¼˜å…ˆä½¿ç”¨å‰ç«¯å®æ—¶æ’­æ”¾æ•°æ®ï¼šprogress = currentTime * playbackRate / duration * 100
        # è‹¥å‰ç«¯æœªä¸ŠæŠ¥ï¼Œåˆ™å›é€€åˆ°â€œå¸§è¦†ç›–åº¦è¿‘ä¼¼â€
        try:
            if 'watch_progress' in buf.meta and isinstance(buf.meta.get('watch_progress'), (int, float)):
                memory['watch_progress'] = max(0.0, min(100.0, float(buf.meta.get('watch_progress') or 0.0)))
            else:
                total_frames_expected = 30.0
                frames_analyzed = float(len(buf.frames))
                memory['watch_progress'] = min(100.0, (frames_analyzed / total_frames_expected) * 100.0)
        except Exception:
            memory['watch_progress'] = 0.0
        observations = {
            'frames_cnt': len(buf.frames),
            'audio_cnt': len(buf.audios),
            'have_vision': bool(memory['vision']),
            'have_asr': bool(memory['asr']),
            'rules_cnt': len(memory['rules']),
            'watch_progress': memory['watch_progress'],
            'stream_annotations_cnt': len(memory['stream_annotations']),
            'approval_signals_cnt': len(memory['approval_signals'])
        }
        sys_prompt = (
            f'ä½ æ˜¯æµå¼å®¡æ ¸æ™ºèƒ½ä½“ï¼Œæ­£åœ¨è¾¹çœ‹è§†é¢‘è¾¹æ ‡æ³¨è¾¹å®¡æ‰¹ï¼ˆå½“å‰è§‚çœ‹è¿›åº¦: {memory["watch_progress"]:.0f}%ï¼‰ã€‚\n'
            'é‡‡ç”¨CoT+ReActæµç¨‹ï¼šThought â†’ Action â†’ Observationï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†å¤šä¸ªä»»åŠ¡ã€‚\n'
            'å·¥å…·ï¼ˆå¯å¹¶è¡Œä½¿ç”¨ï¼‰: \n'
            '- vision_describe: åˆ†æå½“å‰å¸§å†…å®¹ï¼ˆå®æ—¶è§†è§‰ç†è§£ï¼‰ï¼Œargs={}\n'
            '- asr_transcribe: è½¬å½•å½“å‰éŸ³é¢‘ç‰‡æ®µï¼ˆå®æ—¶éŸ³é¢‘ç†è§£ï¼‰ï¼Œargs={}\n'
            '- rules_retrieve: æ£€ç´¢ç›¸å…³å®¡æ ¸è§„åˆ™ï¼Œargs={}\n'
            '- annotation.update: å®æ—¶æ›´æ–°æ ‡æ³¨ï¼ˆåŸºäºå½“å‰å‘ç°ï¼‰ï¼Œargs={{"category":"string","severity":"low|medium|high|ban","progress":0-100,"evidence":"string","timestamp":number}}\n'
            '- ui.highlight: é«˜äº®å…³æ³¨åŒºåŸŸï¼Œargs={{"selector":"CSSé€‰æ‹©å™¨","reason":"é«˜äº®åŸå› "}}\n'
            '- approval.suggest: åŸºäºç´¯ç§¯è¯æ®ç»™å‡ºå®¡æ‰¹å»ºè®®ï¼Œargs={{"recommendation":"approve|reject|review","confidence":0-100,"reasoning":"åŸå› "}}\n'
            'æµå¼ç­–ç•¥ï¼š\n'
            '- æ—©æœŸæ­¥éª¤ï¼šä¸“æ³¨vision_describeå’Œasr_transcribeæ”¶é›†ä¿¡æ¯\n'
            '- ä¸­æœŸæ­¥éª¤ï¼šå¼€å§‹annotation.updateå¡«å……æ ‡æ³¨\n'
            '- åæœŸæ­¥éª¤ï¼šapproval.suggestç»™å‡ºå®¡æ‰¹å»ºè®®\n'
            '- å¯ä»¥åœ¨åŒä¸€æ­¥éª¤æ‰§è¡Œå¤šä¸ªç›¸å…³å·¥å…·\n'
            'è¾“å‡ºæ ¼å¼(JSON)ï¼š\n'
            '{{"type":"Thought","text":"åŸºäºå½“å‰åˆ†æé˜¶æ®µï¼Œæˆ‘ç°åœ¨åº”è¯¥..."}} æˆ–\n'
            '{{"type":"Action","tool":"å·¥å…·å","args":{{...}}}} æˆ–\n'
            '{{"type":"Final","result":{{"risk_level":"low|medium|high|ban","counters":{{"low":n,"medium":n,"high":n,"ban":n}},"summary":"åŸºäºæµå¼åˆ†æçš„ç»¼åˆæ€»ç»“"}}}}\n'
            'ä»…è¾“å‡ºä¸€ä¸ªJSONï¼Œæ€è€ƒç®€æ´ã€‚'
        )
        user_ctx = {
            'observations': observations,
            'vision_excerpt': memory['vision'][-200:] if memory['vision'] else '',  # æœ€æ–°è§†è§‰ä¿¡æ¯
            'asr_excerpt': memory['asr'][-200:] if memory['asr'] else '',          # æœ€æ–°éŸ³é¢‘ä¿¡æ¯  
            'rules': memory['rules'][:4],
            'recent_annotations': memory['stream_annotations'][-2:],               # æœ€è¿‘æ ‡æ³¨
            'recent_approvals': memory['approval_signals'][-2:]                   # æœ€è¿‘å®¡æ‰¹ä¿¡å·
        }
        try:
            resp = await ds.qwen_text(sys_prompt + "\nä¸Šä¸‹æ–‡:" + json.dumps(user_ctx, ensure_ascii=False))
            out = resp.get('output') if isinstance(resp, dict) else {}
            # Prefer structured output
            action_obj: Dict[str, Any] = {}
            if isinstance(out, dict) and out:
                action_obj = out
            else:
                text = out.get('text') or resp.get('output_text') or json.dumps(out, ensure_ascii=False)
                try:
                    import re
                    m = re.search(r"\{[\s\S]*\}", text)
                    action_obj = json.loads(m.group(0)) if m else {}
                except Exception:
                    action_obj = {}
        except Exception as e:
            print(f"ğŸ” Step {step} è§„åˆ’å¼‚å¸¸: {e}")
            await _send_trace(ws, 'system', f'è§„åˆ’å¤±è´¥: {e}', 'reasoning', None, 'error')
            break

        typ = (action_obj.get('type') or '').lower()
        print(f"ğŸ” Step {step} AIè¿”å›ç±»å‹: {typ}, å†…å®¹: {str(action_obj)[:200]}")
        if typ == 'thought':
            thought_text = action_obj.get('text','')
            await _send_trace(ws, 'assistant', f'ğŸ¤” [{memory["watch_progress"]:.0f}%] {thought_text}', 'reasoning', {
                'step': step, 
                'progress': memory['watch_progress'],
                'streaming_mode': True
            }, 'thought')
            continue
        if typ == 'action':
            tool = (action_obj.get('tool') or '').lower()
            args = action_obj.get('args') or {}
            await _send_trace(ws, 'assistant', f'[{memory["watch_progress"]:.0f}%] æ‰§è¡Œ: {tool}', 'reasoning', {
                'step': step, 
                'tool': tool,
                'args': args,
                'progress': memory['watch_progress']
            }, 'action')
            if tool == 'vision_describe':
                obs = await _vision_describe(ds, buf)
                vision_result = obs.get('text','')
                memory['vision'] = (memory['vision'] + '\n' + vision_result).strip()
                
                # æå–é£é™©ç‰‡æ®µä¿¡æ¯
                risk_segments = obs.get('risk_segments', [])
                segments_info = obs.get('segments', [])
                
                # è®°å½•æµå¼æ ‡æ³¨ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
                memory['stream_annotations'].append({
                    'type': 'vision',
                    'progress': memory['watch_progress'], 
                    'content': vision_result,
                    'timestamp': step,
                    'segments': segments_info,
                    'risk_segments': risk_segments,
                    'window_analyzed': f"{obs.get('window_start', 0):.1f}s-{obs.get('window_end', 0):.1f}s"
                })
                
                # æ„å»ºå¢å¼ºçš„è§‚å¯Ÿæ¶ˆæ¯
                observation_msg = f'è§†è§‰å‘ç°: {vision_result[:200]}'
                if risk_segments:
                    risk_count = len(risk_segments)
                    high_risk = len([r for r in risk_segments if r.get('risk_level') in ['high', 'ban']])
                    observation_msg += f' | å‘ç°{risk_count}ä¸ªé£é™©ç‰‡æ®µ({high_risk}ä¸ªé«˜é£é™©)'
                
                await _send_trace(ws, 'assistant', observation_msg, 'reasoning', {
                    'images': obs.get('images',[]),
                    'progress': memory['watch_progress'],
                    'risk_segments': risk_segments,
                    'total_frames_analyzed': obs.get('total_frames_analyzed', 0)
                }, 'observation')
            elif tool == 'asr_transcribe' and use_asr:
                obs = await _asr_transcribe(ds, buf)
                asr_result = obs.get('text','')
                memory['asr'] = (memory['asr'] + '\n' + asr_result).strip()
                # è®°å½•æµå¼æ ‡æ³¨
                memory['stream_annotations'].append({
                    'type': 'audio',
                    'progress': memory['watch_progress'],
                    'content': asr_result,
                    'timestamp': step
                })
                await _send_trace(ws, 'assistant', f'ğŸµ éŸ³é¢‘å†…å®¹: {asr_result[:200]}', 'reasoning', {
                    'audio': obs.get('audio',''),
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'rules_retrieve':
                rules = _rules_retrieve(memory['vision'], memory['asr'])
                memory['rules'] = rules
                await _send_trace(ws, 'assistant', f"ğŸ“‹ æ£€ç´¢åˆ°{len(rules)}æ¡æ½œåœ¨è§„åˆ™", 'reasoning', {
                    'rules': rules,
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'annotation.update':
                # å¢å¼ºçš„æµå¼æ ‡æ³¨æ›´æ–°
                enhanced_args = {
                    **args,
                    'streaming_progress': memory['watch_progress'],
                    'evidence_count': len(memory['stream_annotations']),
                    'timestamp': step
                }
                memory['stream_annotations'].append({
                    'type': 'annotation',
                    'progress': memory['watch_progress'],
                    'data': enhanced_args,
                    'timestamp': step
                })
                await _send_tool(ws, 'annotation.update', enhanced_args)
                await _send_trace(ws, 'assistant', f'æ ‡æ³¨æ›´æ–°: åŸºäº{memory["watch_progress"]:.0f}%è¿›åº¦', 'reasoning', {
                    'fields': list(args.keys()),
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'ui.highlight':
                enhanced_args = {
                    **args,
                    'progress': memory['watch_progress'],
                    'context': f'{memory["watch_progress"]:.0f}%è§‚çœ‹è¿›åº¦'
                }
                await _send_tool(ws, 'ui.highlight', enhanced_args)
                await _send_trace(ws, 'assistant', f'ç•Œé¢é«˜äº®: {args.get("selector","")}', 'reasoning', {
                    'target': args.get('selector',''),
                    'progress': memory['watch_progress']
                }, 'observation')
            elif tool == 'approval.suggest':
                # åŸºäºç´¯ç§¯è¯æ®çš„å®¡æ‰¹å»ºè®®
                enhanced_args = {
                    **args,
                    'evidence_count': len(memory['stream_annotations']),
                    'watch_progress': memory['watch_progress'],
                    'vision_analyzed': bool(memory['vision']),
                    'audio_analyzed': bool(memory['asr']),
                    'rules_checked': len(memory['rules']) > 0
                }
                memory['approval_signals'].append({
                    'progress': memory['watch_progress'],
                    'recommendation': args.get('recommendation',''),
                    'confidence': args.get('confidence', 0),
                    'reasoning': args.get('reasoning',''),
                    'timestamp': step
                })
                await _send_tool(ws, 'approval.suggest', enhanced_args)
                await _send_trace(ws, 'assistant', f'å®¡æ‰¹å»ºè®®: {args.get("recommendation","")} (ç½®ä¿¡åº¦: {args.get("confidence",0)}%)', 'reasoning', {
                    'recommendation': enhanced_args,
                    'progress': memory['watch_progress']
                }, 'observation')
            else:
                await _send_trace(ws, 'assistant', f'æœªçŸ¥å·¥å…·ï¼š{tool}', 'reasoning', {'tool': tool}, 'error')
            
            # æ·»åŠ æ­¥éª¤é—´å»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®è§‚çœ‹èŠ‚å¥
            await asyncio.sleep(tick_seconds)
            continue
        if typ == 'final':
            print(f"ğŸ” Step {step} AIæå‰è¿”å›finalç»“æœ: {action_obj}")
            res = action_obj.get('result') or {}
            if {'risk_level','counters','summary'} <= set(res.keys()):
                print(f"ğŸ” Finalç»“æœå®Œæ•´ï¼Œç›´æ¥è¿”å›")
                return res
            # malformed final; break to fallback judge
            print(f"ğŸ” Finalç»“æœä¸å®Œæ•´ï¼Œfallbackåˆ°é»˜è®¤åˆ¤å®š")
            break
        # If we didn't get a recognized type, try to make progress with default action selection
        # **å¼ºåˆ¶æ‰§è¡Œè§†è§‰åˆ†æ** - ä¿®å¤LLMä¸è°ƒç”¨å·¥å…·çš„é—®é¢˜
        print(f"ğŸ” Step {step} æ£€æŸ¥å¼ºåˆ¶æ‰§è¡Œ: vision={bool(memory['vision'])}, frames={len(buf.frames)}")
        if not memory['vision'] and len(buf.frames) > 0:
            await _send_trace(ws, 'assistant', f'[æ­¥éª¤{step}] å¼ºåˆ¶æ‰§è¡Œ: vision_describe (LLMæœªä¸»åŠ¨è°ƒç”¨)', 'reasoning', {
                'step': step, 
                'tool': 'vision_describe',
                'args': {},
                'progress': memory['watch_progress']
            }, 'action')
            
            print(f"ğŸ” Step {step} å¼€å§‹å¼ºåˆ¶æ‰§è¡Œvision_describe")
            obs = await _vision_describe(ds, buf)
            vision_result = obs.get('text','')
            memory['vision'] = (memory['vision'] + '\n' + vision_result).strip()
            print(f"ğŸ” Step {step} å¼ºåˆ¶æ‰§è¡Œvision_describeå®Œæˆ: {len(vision_result)}å­—ç¬¦")
            
            # æå–é£é™©ç‰‡æ®µä¿¡æ¯
            risk_segments = obs.get('risk_segments', [])
            segments_info = obs.get('segments', [])
            
            # è®°å½•æµå¼æ ‡æ³¨ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
            memory['stream_annotations'].append({
                'type': 'vision',
                'progress': memory['watch_progress'], 
                'content': vision_result,
                'timestamp': step,
                'segments': segments_info,
                'risk_segments': risk_segments,
                'window_analyzed': f"{obs.get('window_start', 0):.1f}s-{obs.get('window_end', 0):.1f}s"
            })
            
            # æ„å»ºå¢å¼ºçš„è§‚å¯Ÿæ¶ˆæ¯
            observation_msg = f'ğŸ“º è§†è§‰å‘ç°: {vision_result[:200]}'
            if risk_segments:
                risk_count = len(risk_segments)
                high_risk = len([r for r in risk_segments if r.get('risk_level') in ['high', 'ban']])
                observation_msg += f' | âš ï¸ å‘ç°{risk_count}ä¸ªé£é™©ç‰‡æ®µ({high_risk}ä¸ªé«˜é£é™©)'
            
            await _send_trace(ws, 'assistant', observation_msg, 'reasoning', {
                'images': obs.get('images',[]),
                'progress': memory['watch_progress'],
                'risk_segments': risk_segments,
                'total_frames_analyzed': obs.get('total_frames_analyzed', 0)
            }, 'observation')
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯åŠ¨ç‰‡æ®µåˆ†æï¼ˆå½“æœ‰è¶³å¤Ÿå¸§æ•°æ®æ—¶ï¼‰
            # ğŸ¯ è¿›ä¸€æ­¥é™ä½é˜ˆå€¼ï¼šé¦–å¸§åˆ°è¾¾å³è§¦å‘å¹¶è¡Œç‰‡æ®µåˆ†æ
            min_frames_needed = 1
            analysis_started = segment_analysis_cache.get('analysis_started', False)
            frames_count = len(buf.frames)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” é˜ˆå€¼æ£€æŸ¥: frames={frames_count}, é˜ˆå€¼={min_frames_needed}, å·²å¯åŠ¨={analysis_started}, æ€»ç‰‡æ®µ={total_segments}")
            
            # äºŒæ¬¡å¹‚ç­‰ï¼šä¼šè¯çº§ä¸æœ¬åœ°ç¼“å­˜éƒ½æœªå¯åŠ¨æ‰è§¦å‘
            if (not getattr(buf, 'segment_analysis_started', False)) and (not analysis_started) and frames_count >= min_frames_needed:
                print(f"ğŸš€ å¸§æ•°æ®å‡†å¤‡å……è¶³({frames_count}å¸§ï¼Œé˜ˆå€¼{min_frames_needed})ï¼Œç°åœ¨å¯åŠ¨æ™ºèƒ½å¹¶è¡Œç‰‡æ®µåˆ†æï¼ˆAPIåè°ƒå™¨ç®¡ç†ï¼‰")
                segment_analysis_cache['analysis_started'] = True
                buf.segment_analysis_started = True
                # å¯åŠ¨åå°ç‰‡æ®µåˆ†æï¼ˆä¿å­˜ä»»åŠ¡å¥æŸ„ï¼Œé¿å…é‡å¤åˆ›å»ºï¼‰
                if not getattr(buf, 'segment_analysis_task', None) or buf.segment_analysis_task.done():
                    buf.segment_analysis_task = asyncio.create_task(
                        _preload_segment_analysis(time_segments, video_duration, buf, ws, segment_analysis_cache)
                    )
            
            # æ˜¾ç¤ºç‰‡æ®µåˆ†æè¿›åº¦
            if current_segment_index < len(time_segments):
                current_segment = time_segments[current_segment_index]
                segment_progress_threshold = (current_segment['end_time'] / video_duration) * 100 if video_duration > 0 else (current_segment_index + 1) * (100 / total_segments)
                
                # å½“è§‚çœ‹è¿›åº¦è¾¾åˆ°å½“å‰ç‰‡æ®µæ—¶ï¼Œæ˜¾ç¤ºè¿›åº¦
                if memory['watch_progress'] >= segment_progress_threshold - 5:  # ç•™5%ç¼“å†²
                    completed_segments = len(segment_analysis_cache.get('completed_segments', []))
                    await _send_trace(ws, 'system', 
                        f'ğŸ“Š å½“å‰æ’­æ”¾åˆ°ç‰‡æ®µ{current_segment_index + 1}ï¼Œåå°åˆ†æè¿›åº¦: {completed_segments}/{total_segments}', 
                        'playback_progress', {
                            'current_playback_segment': current_segment_index + 1,
                            'analysis_completed': completed_segments,
                            'total_segments': total_segments
                        })
                    
                    current_segment_index += 1
            
            continue
        if getattr(_REASONING_CFG, 'use_asr', False) and (not memory['asr']) and len(buf.audios) > 0:
            obs = await _asr_transcribe(ds, buf)
            memory['asr'] = obs.get('text','')
            await _send_trace(ws, 'assistant', obs.get('text','')[:300], 'reasoning', {'audio': obs.get('audio','')}, 'observation')
            continue
        
        # ğŸ” å¾ªç¯ç»“æŸæ¡ä»¶æ£€æŸ¥
        print(f"ğŸ” å¾ªç¯æ£€æŸ¥: use_asr={getattr(_REASONING_CFG, 'use_asr', False)}, has_asr={bool(memory['asr'])}, audio_count={len(buf.audios)}")
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å®‰å…¨ç»“æŸå¾ªç¯ï¼š
        # 1. è¦ä¹ˆå·²ç»å¯åŠ¨äº†å¹¶è¡Œåˆ†æ
        # 2. è¦ä¹ˆå¸§æ•°æ®ä¸è¶³ä¸”å·²ç»ç­‰å¾…äº†è¶³å¤Ÿæ­¥æ•°
        analysis_started = segment_analysis_cache.get('analysis_started', False)
        frames_available = len(buf.frames)
        
        if analysis_started or getattr(buf, 'segment_analysis_started', False):
            print(f"ğŸ” å¹¶è¡Œåˆ†æå·²å¯åŠ¨ï¼Œå¯ä»¥ç»“æŸå¾ªç¯")
            break
        elif step >= 5 and frames_available == 0:
            print(f"ğŸ” ç­‰å¾…5æ­¥ä»æ— å¸§æ•°æ®ï¼Œç»“æŸå¾ªç¯")
            break
        elif step < step_limit:
            print(f"ğŸ” ç»§ç»­ç­‰å¾…å¸§æ•°æ®æˆ–è§¦å‘å¹¶è¡Œåˆ†æ (step {step}/{step_limit})")
            continue
        else:
            print(f"ğŸ” è¾¾åˆ°æ­¥æ•°é™åˆ¶ï¼Œç»“æŸå¾ªç¯")
            break
        
    # å¤„ç†å‰©ä½™çš„æ—¶é—´ç‰‡æ®µ - ä»…åœ¨æ²¡æœ‰å¯åŠ¨å¹¶è¡Œåˆ†ææ—¶æ‰æ‰§è¡Œ
    if not (segment_analysis_cache.get('analysis_started', False) or getattr(buf, 'segment_analysis_started', False)):
        print(f"ğŸ¬ å¹¶è¡Œåˆ†ææœªå¯åŠ¨ï¼Œå›é€€åˆ°é€ä¸ªç‰‡æ®µåˆ†ææ¨¡å¼")
        while current_segment_index < len(time_segments):
            remaining_segment = time_segments[current_segment_index]
            
            # ç”Ÿæˆå‰©ä½™ç‰‡æ®µçš„æ€»ç»“
            segment_summary = await _generate_time_based_segment_summary(
                memory, remaining_segment, video_duration, buf
            )
            
            if segment_summary:
                segment_summaries.append(segment_summary)
                await _send_trace(ws, 'assistant', 
                    f'ğŸ“¹ æœ€ç»ˆç‰‡æ®µæ€»ç»“ ({remaining_segment["start_time"]:.1f}s-{remaining_segment["end_time"]:.1f}s): {segment_summary["content"][:100]}...', 
                    'segment_summary', segment_summary)
            
            current_segment_index += 1
    else:
        print(f"ğŸ¬ å¹¶è¡Œåˆ†æå·²å¯åŠ¨ï¼Œè·³è¿‡é€ä¸ªç‰‡æ®µåˆ†æï¼Œç­‰å¾…å¹¶è¡Œç»“æœ")
    
    print(f"ğŸ¬ å®Œæˆæ‰€æœ‰ç‰‡æ®µåˆ†æï¼Œæ€»å…±ç”Ÿæˆ {len(segment_summaries)} ä¸ªæ—¶é—´æ®µæ€»ç»“")

    # åŸºäºæµå¼åˆ†æçš„æœ€ç»ˆç»¼åˆåˆ¤å®š
    risk_assessment = await _assess_accumulated_risk(memory['stream_annotations'])
    
    context = {
        'streaming_analysis': {
            'total_annotations': len(memory['stream_annotations']),
            'approval_signals': len(memory['approval_signals']),
            'risk_assessment': risk_assessment,
            'segment_summaries': segment_summaries  # æ·»åŠ ç‰‡æ®µæ€»ç»“
        },
        'content_analysis': {
            'vision': memory['vision'][-500:] if memory['vision'] else '',  # æœ€æ–°è§†è§‰åˆ†æ
            'transcript': memory['asr'][-500:] if memory['asr'] else '',    # æœ€æ–°éŸ³é¢‘è½¬å½•
            'rules_triggered': memory['rules'][:5]                          # è§¦å‘çš„è§„åˆ™
        },
        'evidence_timeline': [
            {
                'progress': ann.get('progress', 0),
                'type': ann.get('type', ''),
                'content': ann.get('content', '')[:100]  # æˆªå–å…³é”®å†…å®¹
            } for ann in memory['stream_annotations'][-5:]  # æœ€è¿‘5ä¸ªå‘ç°
        ]
    }
    
    judge_prompt = (
        'ä½ æ˜¯æµå¼å†…å®¹å®¡æ ¸æ™ºèƒ½ä½“ï¼ŒåŸºäºè¾¹çœ‹è¾¹æ ‡æ³¨è¾¹å®¡æ‰¹çš„å®Œæ•´åˆ†æè¿‡ç¨‹ï¼Œç»™å‡ºæœ€ç»ˆå®¡æ ¸ç»“è®ºã€‚\n'
        'é‡ç‚¹è€ƒè™‘ï¼š\n'
        '1. åˆ†æå®Œæ•´æ€§å’Œè´¨é‡\n'
        '2. æ—¶é—´çº¿ä¸Šçš„é£é™©å‘ç°\n' 
        '3. ç´¯ç§¯è¯æ®çš„ä¸€è‡´æ€§\n'
        '4. å®¡æ‰¹ä¿¡å·çš„ç½®ä¿¡åº¦\n'
        'è¾“å‡ºä¸¥æ ¼JSONæ ¼å¼ï¼š\n'
        '{"risk_level": "low|medium|high|ban", "counters": {"low": n, "medium": n, "high": n, "ban": n}, '
        '"summary": "åŸºäºæµå¼åˆ†æçš„ç»¼åˆæ€»ç»“ï¼Œèšç„¦å†…å®¹åˆ†æç»“æœã€é£é™©è¯†åˆ«å’Œæœ€ç»ˆåˆ¤å®šä¾æ®ï¼Œä¸è¦æåŠè§‚çœ‹è¦†ç›–åº¦ç›¸å…³ä¿¡æ¯"}\n'
        f"æµå¼åˆ†æä¸Šä¸‹æ–‡: {json.dumps(context, ensure_ascii=False)}"
    )
    # ç­‰å¾…æ‰€æœ‰ç‰‡æ®µåˆ†æå®Œæˆ - æ–°çš„ç¼“å­˜æœºåˆ¶
    await _send_trace(ws, 'system', 'â³ ç­‰å¾…æ‰€æœ‰ç‰‡æ®µåˆ†æå®Œæˆ...', 'waiting_analysis')
    
    max_wait_time = 120  # æœ€å¤§ç­‰å¾…2åˆ†é’Ÿ
    wait_time = 0
    check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
    
    while not segment_analysis_cache['analysis_complete'] and wait_time < max_wait_time:
        await asyncio.sleep(check_interval)
        wait_time += check_interval
        
        # å‘é€ç­‰å¾…è¿›åº¦
        progress = segment_analysis_cache.get('analysis_progress', 0)
        completed = len(segment_analysis_cache.get('completed_segments', []))
        total = segment_analysis_cache.get('total_segments_expected', 0)
        
        await _send_trace(ws, 'system', 
            f'â³ ç­‰å¾…ç‰‡æ®µåˆ†æ: {completed}/{total} ({progress:.1f}%) - å·²ç­‰å¾…{wait_time}s', 
            'waiting_progress', {
                'completed': completed,
                'total': total,
                'progress': progress,
                'wait_time': wait_time
            })
        
        print(f"â³ ç­‰å¾…ç‰‡æ®µåˆ†æå®Œæˆ: {completed}/{total} ({progress:.1f}%)")
    
    # è·å–åˆ†æç»“æœ
    if segment_analysis_cache['analysis_complete']:
        segment_summaries = segment_analysis_cache['completed_segments']
        print(f"âœ… ç‰‡æ®µåˆ†æå®Œæˆï¼Œè·å¾— {len(segment_summaries)} ä¸ªç‰‡æ®µæ€»ç»“")
        # ğŸ¯ ç”¨æˆ·è¯·æ±‚çš„å…³é”®æ—¥å¿—ï¼šç¡®è®¤æ‰€æœ‰å®¡æ ¸æ•°æ®å·²å­˜å‚¨åˆ°ä½
        print(f"ğŸ å®¡æ ¸æ•°æ®å·²å…¨éƒ¨åˆ°è¾¾ï¼å…±è®¡{len(segment_summaries)}ä¸ªç‰‡æ®µçš„åˆ†æç»“æœå·²å­˜å‚¨å®Œæ¯•")
    else:
        print(f"âš ï¸ ç‰‡æ®µåˆ†æè¶…æ—¶ï¼Œå·²ç­‰å¾…{wait_time}sï¼Œä½¿ç”¨ç°æœ‰ç»“æœ")
        segment_summaries = segment_analysis_cache.get('completed_segments', [])
    
    print(f"ğŸ¬ æœ€ç»ˆç‰‡æ®µåˆ†æç»Ÿè®¡: {len(segment_summaries)} ä¸ªæ—¶é—´æ®µæ€»ç»“")
    
    try:
        await _send_trace(ws, 'assistant', 'åˆæˆæœ€ç»ˆç»“è®ºâ€¦', 'judge')
        judge = await ds.qwen_text(judge_prompt)
        output = judge.get('output') or {}
        parsed: Dict[str, Any] = {}
        if isinstance(output, dict) and {'risk_level','counters','summary'} <= set(output.keys()):
            parsed = output
        else:
            txt = output.get('text') or judge.get('output_text') or json.dumps(output, ensure_ascii=False)
            import re
            m = re.search(r"\{[\s\S]*\}", txt)
            if m:
                parsed = json.loads(m.group(0))
        if parsed:
            # å°†ç‰‡æ®µæ€»ç»“æ·»åŠ åˆ°è¿”å›ç»“æœä¸­
            parsed['segment_summaries'] = segment_summaries
            return parsed
    except Exception as e:
        await _send_trace(ws, 'system', f'åˆæˆå¤±è´¥: {e}', 'judge', None, 'error')
    # fallback
    return {
        'risk_level':'low',
        'counters':{'low':1,'medium':0,'high':0,'ban':0},
        'summary':'å›é€€ï¼šæ ·æœ¬ä¸è¶³ï¼Œæš‚åˆ¤ä½é£é™©ã€‚',
        'segment_summaries': segment_summaries
    }

# ---- main audit ----
@app.post("/agent/audit")
async def agent_audit(req: AuditRequest):
    task_id = str(uuid.uuid4())
    result: Dict[str, Any] = {"risk_level":"medium","counters":{"low":1,"medium":0,"high":0,"ban":0},"summary":"å›é€€ï¼šæœåŠ¡æš‚ä¸å¯ç”¨ã€‚"}

    if DSClient is None:
        return JSONResponse({"task_id": task_id, "status": "done", "result": result})

    try:
        ds = DSClient()
        frames = _extract_frames(req.video_url) if req.video_url else []
        transcript = await _asr(ds, req.audio_url)
        vl_tags = {}
        context = {"aweme_id": req.aweme_id, "title": req.title, "desc": req.desc, "transcript": transcript, "vision": vl_tags}
        prompt = (
            "ä½ æ˜¯çŸ­è§†é¢‘å†…å®¹å®¡æ ¸åŠ©æ‰‹ã€‚ç»™å®šç»“æ„åŒ–ä¸Šä¸‹æ–‡(ä¸­æ–‡)ï¼Œè¯·è¾“å‡ºä¸¥æ ¼JSON: "
            "{risk_level: one of [low,medium,high,ban], counters:{low,medium,high,ban}, summary:string}.\n"
            f"ä¸Šä¸‹æ–‡: {json.dumps(context, ensure_ascii=False)}"
        )
        judge = await ds.qwen_text(prompt)
        output = judge.get("output") or {}
        if isinstance(output, dict) and {"risk_level","counters","summary"} <= set(output.keys()):
            parsed = output
        else:
            text = output.get("text") or judge.get("output_text") or json.dumps(output, ensure_ascii=False)
            try:
                import re
                m = re.search(r"\{[\s\S]*\}", text)
                parsed = json.loads(m.group(0)) if m else {}
            except Exception:
                parsed = {}
        if parsed:
            result = {
                "risk_level": parsed.get("risk_level", result["risk_level"]),
                "counters": parsed.get("counters", result["counters"]),
                "summary": parsed.get("summary", result["summary"]),
            }
    except Exception as e:
        result = {**result, "error": str(e)}

    return JSONResponse({"task_id": task_id, "status": "done", "result": result})


# ---- Comment Analysis API ----
async def _analyze_comment_content(ds: 'DSClient', comment_text: str) -> Dict[str, Any]:
    """ä½¿ç”¨qwen2.5-flashåˆ†æå•æ¡è¯„è®ºå†…å®¹çš„é£é™©"""
    
    enhanced_prompt = f"""
åˆ†æä»¥ä¸‹ç”¨æˆ·è¯„è®ºçš„å†…å®¹å®‰å…¨æ€§ï¼š

è¯„è®ºå†…å®¹ï¼š"{comment_text}"

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. **è¿è§„ç±»å‹**ï¼šè‰²æƒ…ä½ä¿—ã€æš´åŠ›è¡€è…¥ã€æ”¿æ²»æ•æ„Ÿã€è™šå‡ä¿¡æ¯ã€äººèº«æ”»å‡»ã€è¿æ³•å¹¿å‘Šã€å…¶ä»–
2. **é£é™©ç­‰çº§**ï¼šæ— é£é™©/ä½é£é™©/ä¸­é£é™©/é«˜é£é™©/ç¦æ­¢å‘å¸ƒ
3. **å…·ä½“åŸå› **ï¼šè¯¦ç»†è¯´æ˜åˆ¤å®šä¾æ®

è¦æ±‚ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼ï¼š
{{"risk_level": "low|medium|high|ban", "violation_type": "ç±»å‹æˆ–null", "reason": "è¯¦ç»†åˆ†æåŸå› ", "confidence": 0.95}}
"""
    
    try:
        response = await ds.qwen_text(enhanced_prompt)
        logger.info(f"ğŸ§  qwen2.5-flashè¯„è®ºåˆ†æå“åº”: {type(response)}")
        
        # è§£æå“åº”
        output = response.get('output') if isinstance(response, dict) else {}
        
        if isinstance(output, dict) and {'risk_level', 'reason'} <= set(output.keys()):
            # ç›´æ¥æ˜¯ç»“æ„åŒ–è¾“å‡º
            result = output
        else:
            # ä»æ–‡æœ¬ä¸­æå–JSON
            text = output.get('text') or response.get('output_text') or json.dumps(output, ensure_ascii=False)
            try:
                import re
                m = re.search(r'\{[\s\S]*\}', text)
                result = json.loads(m.group(0)) if m else {}
            except Exception:
                result = {}
        
        # è®¾ç½®é»˜è®¤å€¼
        risk_level = result.get('risk_level', 'low')
        violation_type = result.get('violation_type')
        reason = result.get('reason', 'æ— æ˜æ˜¾è¿è§„å†…å®¹')
        confidence = float(result.get('confidence', 0.8))
        
        logger.info(f"âœ… è¯„è®ºåˆ†æå®Œæˆ: {risk_level} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        return {
            'risk_level': risk_level,
            'violation_type': violation_type,
            'reason': reason,
            'confidence': confidence
        }
        
    except Exception as e:
        logger.error(f"âŒ è¯„è®ºåˆ†æå¤±è´¥: {e}")
        return {
            'risk_level': 'low',
            'violation_type': None,
            'reason': f'åˆ†æå¤±è´¥: {str(e)}',
            'confidence': 0.0
        }


@app.post("/agent/analyze_comments")
async def analyze_comments(req: CommentAnalysisRequest):
    """åˆ†æè¯„è®ºå†…å®¹çš„è¿è§„é£é™©"""
    task_id = str(uuid.uuid4())
    
    if DSClient is None:
        return JSONResponse({
            "task_id": task_id, 
            "status": "error", 
            "message": "AIæœåŠ¡ä¸å¯ç”¨",
            "results": []
        })
    
    if not req.comments:
        return JSONResponse({
            "task_id": task_id, 
            "status": "done", 
            "results": [],
            "counters": {"low": 0, "medium": 0, "high": 0, "ban": 0}
        })
    
    try:
        ds = DSClient()
        results = []
        counters = {"low": 0, "medium": 0, "high": 0, "ban": 0}
        
        logger.info(f"ğŸ” å¼€å§‹åˆ†æ {len(req.comments)} æ¡è¯„è®º")
        
        # æ‰¹é‡åˆ†æè¯„è®º
        for i, comment in enumerate(req.comments):
            comment_text = comment.get('detail', comment.get('content', comment.get('text', '')))
            comment_id = comment.get('comment_id', comment.get('id', f'comment_{i}'))
            
            if not comment_text or len(comment_text.strip()) == 0:
                # ç©ºè¯„è®ºè·³è¿‡
                continue
                
            logger.info(f"ğŸ“ åˆ†æè¯„è®º {i+1}/{len(req.comments)}: {comment_text[:50]}...")
            
            # è°ƒç”¨AIåˆ†æ
            analysis = await _analyze_comment_content(ds, comment_text)
            
            # ç»Ÿè®¡é£é™©ç­‰çº§
            risk_level = analysis['risk_level']
            if risk_level in counters:
                counters[risk_level] += 1
            else:
                counters['low'] += 1  # é»˜è®¤å½’ä¸ºä½é£é™©
            
            # æ·»åŠ åˆ°ç»“æœ
            results.append({
                'comment_id': comment_id,
                'comment_text': comment_text,
                'analysis': analysis,
                'timestamp': time.time()
            })
            
            # é¿å…APIé™æµï¼Œç¨å¾®å»¶è¿Ÿ
            if i < len(req.comments) - 1:
                await asyncio.sleep(0.1)
        
        logger.info(f"âœ… è¯„è®ºåˆ†æå®Œæˆ: {counters}")
        
        return JSONResponse({
            "task_id": task_id,
            "status": "done", 
            "aweme_id": req.aweme_id,
            "results": results,
            "counters": counters,
            "summary": f"å·²åˆ†æ {len(results)} æ¡è¯„è®ºï¼Œå‘ç° {counters['high'] + counters['ban']} æ¡é«˜é£é™©å†…å®¹"
        })
        
    except Exception as e:
        logger.error(f"âŒ è¯„è®ºæ‰¹é‡åˆ†æå¤±è´¥: {e}")
        return JSONResponse({
            "task_id": task_id,
            "status": "error",
            "message": str(e),
            "results": [],
            "counters": {"low": 0, "medium": 0, "high": 0, "ban": 0}
        })


# ---- realtime WebSocket stream ----

class SessionBuf:
    def __init__(self, sid: str):
        self.sid: str = sid
        self.meta: Dict[str, Any] = {}
        self.frames: List[str] = []  # absolute file paths
        self.audios: List[str] = []  # absolute file paths
        self.last_emit: float = 0.0
        self.dir_path: str = os.path.join(STATIC_ROOT, sid)
        os.makedirs(self.dir_path, exist_ok=True)
        self.total_frames: int = 0
        self.total_audios: int = 0
        # æ§åˆ¶ä½ï¼šæ˜¯å¦å·²è§¦å‘åç«¯è‡ªåŠ¨æå–å¸§ï¼Œé¿å…é‡å¤
        self.auto_extract_started: bool = False
        self.auto_extract_done: bool = False
        # ä¼šè¯çº§å¹¶è¡Œåˆ†æå¹‚ç­‰æ§åˆ¶ï¼ˆé¿å…é‡å¤å¯åŠ¨å¤šè½®ï¼‰
        self.segment_analysis_started: bool = False
        self.segment_analysis_completed: bool = False
        self.segment_analysis_cache: Optional[Dict[str, Any]] = None
        self.segment_analysis_task: Optional[asyncio.Task] = None
        # ğŸš¨ å…³é”®ï¼šæ™ºèƒ½ä½“åˆ†æå®Œæˆæ ‡å¿—ï¼Œé¿å…é‡å¤åˆ†æ
        self.cot_react_completed: bool = False
        self.final_result: Optional[Dict[str, Any]] = None

    def _rel_url(self, abs_path: str) -> str:
        rel = os.path.relpath(abs_path, STATIC_ROOT).replace(os.sep, "/")
        return f"/static/{rel}"

    def public_url(self, abs_path: str) -> str:
        rel_url = self._rel_url(abs_path)
        if PUBLIC_BASE_URL:
            return f"{PUBLIC_BASE_URL}{rel_url}"
        return f"http://127.0.0.1:8799{rel_url}"


def _ext_from_mime(mime: str) -> str:
    if "jpeg" in mime:
        return "jpg"
    if "png" in mime:
        return "png"
    if "webm" in mime:
        return "webm"
    if "ogg" in mime:
        return "ogg"
    if "mp4" in mime:
        return "mp4"
    return "bin"


def _save_data_url(data_url: str, dir_path: str, prefix: str) -> Optional[str]:
    try:
        if not data_url or "," not in data_url:
            return None
        header, b64 = data_url.split(",", 1)
        mime = ""
        if header.startswith("data:") and ";base64" in header:
            mime = header[5: header.find(";")]
        ext = _ext_from_mime(mime)
        ts = int(time.time() * 1000)
        filename = f"{prefix}_{ts}.{ext}"
        abs_path = os.path.join(dir_path, filename)
        with open(abs_path, "wb") as f:
            f.write(base64.b64decode(b64))
        return abs_path
    except Exception:
        return None

sessions = {}

from typing import Any
import json, time

async def _auto_extract_frames_for_session(buf: 'SessionBuf', ws: WebSocket):
    """åœ¨æ”¶åˆ°metaåç«¯è‡ªåŠ¨æå–30å¸§å¹¶æ³¨å…¥åˆ°å½“å‰ä¼šè¯ç¼“å†²åŒºï¼Œé¿å…ä¾èµ–å‰ç«¯é€å¸§æ¨é€ã€‚"""
    if buf.auto_extract_started or buf.auto_extract_done:
        return
    video_url = (buf.meta or {}).get('src') or ''
    if not video_url:
        return
    buf.auto_extract_started = True
    try:
        try:
            await ws.send_text(json.dumps({'type': 'trace', 'data': {
                'role': 'system',
                'text': f'ğŸš€ åç«¯è‡ªåŠ¨æå–å¸§å¯åŠ¨: ç›®æ ‡30å¸§',
                'stage': 'auto_extract_start'
            }}, ensure_ascii=False))
        except Exception:
            pass

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œé˜»å¡çš„æå–ä»»åŠ¡
        frame_paths = await asyncio.to_thread(_extract_frames, video_url, 0, 30)
        if not frame_paths:
            return

        # ç§»åŠ¨åˆ°é™æ€ç›®å½•å¹¶ç”ŸæˆURL
        injected = 0
        for path in frame_paths:
            try:
                filename = os.path.basename(path)
                static_path = os.path.join(STATIC_ROOT, 'extracted_frames', filename)
                os.makedirs(os.path.dirname(static_path), exist_ok=True)
                if os.path.exists(path):
                    import shutil
                    shutil.move(path, static_path)
                rel_url = f"/static/extracted_frames/{filename}"
                public_url = f"{PUBLIC_BASE_URL}{rel_url}" if PUBLIC_BASE_URL else f"http://127.0.0.1:8799{rel_url}"
                # æ³¨å…¥åˆ°ä¼šè¯ç¼“å†²åŒºï¼ˆå»é‡ï¼‰
                if public_url not in buf.frames:
                    buf.frames.append(public_url)
                    if len(buf.frames) > 30:
                        buf.frames = buf.frames[-30:]
                    buf.total_frames += 1
                    injected += 1
                    logger.info(f"frame_url sid={buf.sid} url={public_url} count_batch={len(buf.frames)} total={buf.total_frames}")
            except Exception:
                continue

        buf.auto_extract_done = True
        try:
            await ws.send_text(json.dumps({'type': 'trace', 'data': {
                'role': 'system',
                'text': f'âœ… åç«¯è‡ªåŠ¨æ³¨å…¥å¸§å®Œæˆ: {injected}å¸§',
                'stage': 'auto_extract_done',
                'payload': {'injected': injected}
            }}, ensure_ascii=False))
        except Exception:
            pass
    except Exception:
        buf.auto_extract_done = True
        try:
            await ws.send_text(json.dumps({'type': 'trace', 'data': {
                'role': 'system',
                'text': 'âŒ åç«¯è‡ªåŠ¨æå–å¸§å¤±è´¥',
                'stage': 'auto_extract_error'
            }}, ensure_ascii=False))
        except Exception:
            pass

@app.websocket("/ws/stream")
async def ws_stream(ws: WebSocket):
    # æ¥å—è¿æ¥ï¼Œç¦ç”¨è‡ªåŠ¨è¶…æ—¶æœºåˆ¶
    await ws.accept()
    sid = str(uuid.uuid4())
    
    # åˆ›å»ºå·¥ä½œæµä¼šè¯
    session = WorkflowSession(session_id=sid, websocket=ws)
    workflow_sessions[sid] = session
    
    # ä¿æŒæ—§çš„session bufå…¼å®¹æ€§
    buf = SessionBuf(sid)
    sessions[sid] = buf
    
    try:
        ds = DSClient() if DSClient else None
        ds_status = "å¯ç”¨" if ds else "ä¸å¯ç”¨"
        logger.info(f"ğŸ”— WebSocket connected: {sid}, DSClient={ds_status}")
        
        # å‘é€åˆå§‹åŒ–çŠ¶æ€
        await emit_event(sid, 'system_ready', {
            'ds_available': bool(ds),
            'public_url_set': bool(PUBLIC_BASE_URL),
            'message': f'AIæœåŠ¡çŠ¶æ€: DSClient={ds_status}'
        })
        while True:
            msg = await ws.receive_text()
            try:
                data = json.loads(msg)
                
                # å¤„ç†äº‹ä»¶é©±åŠ¨çš„æ¶ˆæ¯
                if data.get('type') == 'start_workflow':
                    await handle_start_workflow(sid, data.get('data', {}))
                elif data.get('type') == 'agent_audit':
                    await handle_agent_audit(sid, data.get('data', {}))
                elif data.get('type') == 'request_step_data':
                    await handle_step_data_request(sid, data.get('data', {}))
                else:
                    # ä¿æŒåŸæœ‰çš„æ¶ˆæ¯å¤„ç†é€»è¾‘ä½œä¸ºå…¼å®¹
                    await handle_legacy_message(sid, data, buf, ds)
                    
            except Exception as e:
                logger.error(f"âŒ WebSocket message error: {e}")
                continue
    
    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket disconnected: {sid}")
    except Exception as e:
        logger.error(f"âŒ WebSocket error: {e}")
    finally:
        # æ¸…ç†èµ„æº
        if sid in workflow_sessions:
            del workflow_sessions[sid]
        if sid in sessions:
            del sessions[sid]

# ========== äº‹ä»¶å¤„ç†å‡½æ•° ==========

async def handle_start_workflow(session_id: str, data: Dict[Any, Any]):
    """å¤„ç†å·¥ä½œæµå¯åŠ¨è¯·æ±‚"""
    aweme_id = data.get('aweme_id')
    session = workflow_sessions.get(session_id)
    if session:
        session.aweme_id = aweme_id
    
    logger.info(f"ğŸš€ Starting workflow for video: {aweme_id}")
    
    # å¹¶è¡Œå¯åŠ¨å¤šä¸ªåˆ†æä»»åŠ¡
    tasks = []
    if aweme_id:
        tasks.append(TaskManager.start_task(session_id, TaskType.VIDEO_ANALYSIS, aweme_id=aweme_id))
        tasks.append(TaskManager.start_task(session_id, TaskType.AUDIO_ANALYSIS, aweme_id=aweme_id))
    
    comments = data.get('comments', [])
    if comments:
        tasks.append(TaskManager.start_task(session_id, TaskType.COMMENT_ANALYSIS, comments=comments))
    
    await asyncio.gather(*tasks)

async def handle_agent_audit(session_id: str, data: Dict[Any, Any]):
    """å¤„ç†æ™ºèƒ½ä½“å®¡æ ¸è¯·æ±‚"""
    aweme_id = data.get('aweme_id')
    logger.info(f"ğŸ¤– Agent audit started for: {aweme_id}")
    
    # å¯åŠ¨å·¥ä½œæµ
    await handle_start_workflow(session_id, data)

async def handle_step_data_request(session_id: str, data: Dict[Any, Any]):
    """å¤„ç†æ­¥éª¤æ•°æ®è¯·æ±‚"""
    step_name = data.get('step_name')
    session = workflow_sessions.get(session_id)
    
    if not session:
        return
    
    # æ£€æŸ¥ç›¸å…³ä»»åŠ¡æ˜¯å¦å®Œæˆ
    available_data = {}
    for task in session.tasks.values():
        if task.status == TaskStatus.COMPLETED and task.result:
            available_data[task.type.value] = task.result
    
    # å‘é€å¯ç”¨æ•°æ®
    await emit_event(session_id, 'step_data_ready', {
        'step_name': step_name,
        'available_data': available_data,
        'ready': len(available_data) > 0
    })

async def handle_legacy_message(session_id: str, data: Dict[Any, Any], buf, ds):
    """å¤„ç†æ—§ç‰ˆæ¶ˆæ¯æ ¼å¼ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰"""
    # æš‚æ—¶ç®€åŒ–ï¼Œä»…å¤„ç†åŸºæœ¬æ¶ˆæ¯ç±»å‹
    mtype = data.get('type')
    logger.info(f"ğŸ“¨ Legacy message: {mtype} for session {session_id}")
    
    # åŸºæœ¬å…¼å®¹æ€§å¤„ç†ï¼Œè¯¦ç»†å®ç°åç»­è¡¥å……
    if mtype == 'meta':
        payload = data.get('data', {})
        aweme_id = payload.get('aweme_id')
        if aweme_id:
            buf.meta.update({
                'aweme_id': aweme_id,
                'title': payload.get('title', ''),
                'duration': payload.get('duration', 0)
            })
            logger.info(f"ğŸ“ Updated meta for {aweme_id}")
            
    elif mtype == 'agent_audit':
        # è½¬å‘åˆ°æ–°çš„äº‹ä»¶ç³»ç»Ÿ
        await handle_agent_audit(session_id, data.get('data', {}))
        
    # å…¶ä»–legacyæ¶ˆæ¯ç±»å‹çš„å¤„ç†å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
    pass  # ä¸´æ—¶ç®€åŒ–ï¼Œç¡®ä¿è¯­æ³•æ­£ç¡®
                duration_str = f"{duration_sec:.1f}ç§’" if duration_sec > 0 else "æœªçŸ¥"
                resolution_str = f"{buf.meta.get('width', 0)}x{buf.meta.get('height', 0)}"
                
                try:
                    await ws.send_text(json.dumps({
                        'type': 'trace',
                        'data': {
                            'role': 'system',
                            'text': f"æ”¶åˆ°å®Œæ•´å…ƒä¿¡æ¯ aweme_id={buf.meta.get('aweme_id')}, æ ‡é¢˜={buf.meta.get('title') or ''}, æ—¶é•¿={duration_str}, åˆ†è¾¨ç‡={resolution_str}",
                            'ts': int(time.time() * 1000)
                        }
                    }, ensure_ascii=False))
                except Exception:
                    pass
                logger.info(f"meta sid={sid} aweme_id={buf.meta.get('aweme_id')} title={buf.meta.get('title')} duration={duration_sec}s resolution={resolution_str}")
                # åœ¨åå°è‡ªåŠ¨æå–å¹¶æ³¨å…¥å¸§ï¼Œé¿å…ä¾èµ–å‰ç«¯é€å¸§æ¨é€
                if not buf.auto_extract_started and duration_sec > 0 and buf.meta.get('src'):
                    asyncio.create_task(_auto_extract_frames_for_session(buf, ws))
                
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šå¯åŠ¨ä¸€æ¬¡æ€§æ™ºèƒ½ä½“åˆ†æï¼Œé¿å…é‡å¤
                if not buf.cot_react_completed and duration_sec > 0:
                    print(f"ğŸš€ å¯åŠ¨æ™ºèƒ½ä½“åˆ†æä¼šè¯: {sid}")
                    buf.cot_react_completed = True  # æ ‡è®°ä¸ºå·²å¯åŠ¨ï¼Œé¿å…é‡å¤
                    
                    async def run_analysis():
                        try:
                            result = await run_cot_react(ds, buf, ws)
                            buf.final_result = result
                            
                            # å‘é€æœ€ç»ˆç»“æœå‰å…ˆæ£€æŸ¥è¿æ¥çŠ¶æ€ï¼Œå¹¶å¢åŠ è°ƒè¯•ä¿¡æ¯
                            result_data = json.dumps({'type': 'result', 'data': result}, ensure_ascii=False)
                            print(f"ğŸ¯ å‡†å¤‡å‘é€æœ€ç»ˆç»“æœ: risk_level={result.get('risk_level', 'unknown')}, segment_count={len(result.get('segment_summaries', []))}")
                            
                            try:
                                if hasattr(ws, 'client_state') and ws.client_state.value == 1:  # WebSocketState.CONNECTED = 1
                                    await ws.send_text(result_data)
                                    print(f"âœ… æ™ºèƒ½ä½“åˆ†æå®Œæˆï¼Œæœ€ç»ˆç»“æœå·²å‘é€ï¼Œä¼šè¯: {sid}")
                                else:
                                    print(f"âš ï¸ WebSocketå·²æ–­å¼€(çŠ¶æ€: {getattr(ws, 'client_state', 'unknown')})ï¼Œæ— æ³•å‘é€æœ€ç»ˆç»“æœï¼Œä¼šè¯: {sid}")
                            except Exception as send_e:
                                print(f"âŒ å‘é€æœ€ç»ˆç»“æœå¤±è´¥: {send_e}")
                        except Exception as e:
                            print(f"âŒ æ™ºèƒ½ä½“åˆ†æå¤±è´¥: {e}")
                            error_result = {"error": str(e), "risk_level": "unknown"}
                            
                            # æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€åå‘é€é”™è¯¯ç»“æœ
                            try:
                                if hasattr(ws, 'client_state') and ws.client_state.value == 1:
                                    await ws.send_text(json.dumps({'type': 'result', 'data': error_result}, ensure_ascii=False))
                                else:
                                    print(f"âš ï¸ WebSocketå·²æ–­å¼€ï¼Œæ— æ³•å‘é€é”™è¯¯ç»“æœ")
                            except Exception as send_error:
                                print(f"âš ï¸ å‘é€é”™è¯¯ç»“æœå¤±è´¥: {send_error}")
                    
                    # åœ¨åå°å¯åŠ¨åˆ†æä»»åŠ¡
                    asyncio.create_task(run_analysis())
            elif mtype == 'frame':
                durl = data.get('data', '')
                p = _save_data_url(durl, buf.dir_path, 'frame')
                if p:
                    buf.frames.append(p)
                    if len(buf.frames) > 30:
                        buf.frames = buf.frames[-30:]
                    buf.total_frames += 1
                    if buf.total_frames % 10 == 1:
                        logger.info(f"frames sid={sid} last={p} count_batch={len(buf.frames)} total={buf.total_frames}")
            elif mtype == 'frame_url':
                # ç›´æ¥ä½¿ç”¨åç«¯æå–çš„å¸§URL
                frame_url = data.get('data', '')
                if frame_url:
                    # å°†URLè½¬æ¢ä¸ºæœ¬åœ°è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰æˆ–ç›´æ¥ä½¿ç”¨URL
                    buf.frames.append(frame_url)
                    # å¢åŠ å¸§ç¼“å†²åŒºé™åˆ¶åˆ°30å¸§ï¼Œæ”¯æŒå®Œæ•´è§†é¢‘åˆ†æ
                    if len(buf.frames) > 30:
                        buf.frames = buf.frames[-30:]
                    buf.total_frames += 1
                    logger.info(f"frame_url sid={sid} url={frame_url} count_batch={len(buf.frames)} total={buf.total_frames}")
                    try:
                        await ws.send_text(json.dumps({
                            'type': 'trace',
                            'data': {
                                'role': 'system',
                                'text': f"âœ“ æ¥æ”¶åç«¯æå–å¸§: {os.path.basename(frame_url)}",
                                'ts': int(time.time() * 1000)
                            }
                        }, ensure_ascii=False))
                    except Exception:
                        pass
            elif mtype == 'audio':
                durl = data.get('data', '')
                p = _save_data_url(durl, buf.dir_path, 'audio')
                if p:
                    buf.audios.append(p)
                    if len(buf.audios) > 6:
                        buf.audios = buf.audios[-6:]
                    buf.total_audios += 1
                    if buf.total_audios % 5 == 1:
                        logger.info(f"audios sid={sid} last={p} count_batch={len(buf.audios)} total={buf.total_audios}")
            elif mtype == 'progress':
                # å‰ç«¯æ’­æ”¾è¿›åº¦ä¸ŠæŠ¥ï¼š{ type: 'progress', current_time, playback_rate, duration? }
                payload = data.get('data') if isinstance(data.get('data'), dict) else data
                try:
                    current_time = float(payload.get('current_time') or payload.get('currentTime') or 0.0)
                except Exception:
                    current_time = 0.0
                try:
                    playback_rate = float(payload.get('playback_rate') or payload.get('playbackRate') or 1.0)
                except Exception:
                    playback_rate = 1.0
                try:
                    duration_sec = float(payload.get('duration') or buf.meta.get('duration') or 0.0)
                except Exception:
                    duration_sec = 0.0

                progress_pct = 0.0
                if duration_sec > 0:
                    progress_pct = max(0.0, min(100.0, (current_time * playback_rate) / duration_sec * 100.0))

                # å†™å…¥å…ƒä¿¡æ¯ï¼Œä¾›æ¨ç†å¾ªç¯è¯»å–
                buf.meta['current_time'] = current_time
                buf.meta['playback_rate'] = playback_rate
                buf.meta['watch_progress'] = progress_pct

                logger.info(
                    f"progress sid={sid} current_time={current_time:.2f}s rate={playback_rate:.2f} "
                    f"duration={duration_sec:.2f}s progress={progress_pct:.1f}%"
                )
                try:
                    await ws.send_text(json.dumps({
                        'type': 'trace',
                        'data': {
                            'role': 'system',
                            'text': f"âœ“ æ’­æ”¾è¿›åº¦ä¸ŠæŠ¥: {progress_pct:.1f}% (t={current_time:.2f}s, x{playback_rate:.2f})",
                            'stage': 'progress',
                            'payload': {
                                'current_time': current_time,
                                'playback_rate': playback_rate,
                                'duration': duration_sec,
                                'progress': progress_pct,
                            },
                            'ts': int(time.time() * 1000)
                        }
                    }, ensure_ascii=False))
                except Exception:
                    pass

            # ğŸš¨ ç§»é™¤é‡å¤çš„tickåˆ†æé€»è¾‘ - æ™ºèƒ½ä½“åˆ†æç°åœ¨åªåœ¨æ”¶åˆ°metaæ—¶å¯åŠ¨ä¸€æ¬¡
            # ç®€å•çš„å¿ƒè·³ä¿æŒè¿æ¥æ´»è·ƒ
            heartbeat_ok = await _send_heartbeat(ws)
            if not heartbeat_ok:
                print("ğŸ’” å¿ƒè·³å¤±è´¥ï¼ŒWebSocketè¿æ¥å·²æ–­å¼€ï¼Œé€€å‡ºå¾ªç¯")
                break
            
            # 5ç§’å¿ƒè·³é—´éš”ï¼Œé¿å…é¢‘ç¹å¤„ç†
            await asyncio.sleep(5.0)
    except WebSocketDisconnect:
        pass
    finally:
        sessions.pop(sid, None)
